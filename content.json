{"meta":{"title":"Yitao's Blog","subtitle":"","description":"","author":"Wang Yitao","url":"https://ZjuYTW.github.io","root":"/"},"pages":[{"title":"About me","date":"2021-08-09T06:12:37.000Z","updated":"2021-08-09T11:54:25.960Z","comments":true,"path":"about/index.html","permalink":"https://zjuytw.github.io/about/index.html","excerpt":"","text":"Hi there, I am Wang Yitao, a graduate student in the Master of Computing at the National University of Singapore. I got my Bachelor of Science in physics degree at Zhejiang University. I am familiar with c, c++, and golang, I want to dig deeper into systems especially large-scale distributed systems. I have completed many projects, from courses’ MiniSQL, c-like compiler to my last year project – A binary similarity analysis tool. I am focusing on graduate courses and MIT6.s081, and recently I finished my Raft based Shard Key/Value storage system. Please feel free to contact me if you have any academic or career questions!"},{"title":"categories","date":"2021-08-09T06:35:31.000Z","updated":"2021-08-09T12:08:20.443Z","comments":true,"path":"categories/index.html","permalink":"https://zjuytw.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-08-09T10:49:33.000Z","updated":"2021-08-09T10:49:33.340Z","comments":true,"path":"tags/index.html","permalink":"https://zjuytw.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MIT6.S081 Lecture14 Ext3fs crash recovery","slug":"Lec13-- Ex3 Recovery","date":"2022-01-30T09:02:37.100Z","updated":"2022-01-30T09:10:32.014Z","comments":true,"path":"2022/01/30/Lec13-- Ex3 Recovery/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec13--%20Ex3%20Recovery/","excerpt":"","text":"Linux ext3fs crash recovery systemxv6 Design Defects Every block needs to be written twice(one for log and another for fs) Syscall needs wait for committing disk I/O is synchronized ext3 Journal Designext3 could track on multiple transactions’ status at one time to get more parallelism. Similar to xv6, ext3 has write-back block cache and maintains each transaction a transaction info, includes Every transaction has a sequence number Revised block number by this tnx handles On disk circular log has: log super block: recording offset of transaction with the lowest sequence number and its sequence number descriptor block: Every transaction’s head block, recording seq# and home block#, and magic# data block commit block: Every transaction’s tail block, has magic#. When log is full or elapse times out, ext3 will write log block into home disk starts at the smallest seq# transaction. Commit Transaction Temporarily block new syscalls Wait for outstanding syscall ends, because one transaction has a rather long time window, we need to wait for all syscalls in the window to finish. start a new transaction, unblock syscalls write block numbers into descriptor block write corresponding data block write commit block, after it is written, commit finishes. write to home location release log block Recovery Steps After rebooting, system first looks at super block and seeks for smallest valid seq#’s transaction Find the log’s tail, if it missed a commit flag( by magic #) or encounter a false seq #, we just skip this. Write all valid commit log Performance Analysis Asynchronous disk update syscall don’t have to wait for disk I/O, instead it just modify buffer cache and different syscall’s log could be absorbed for group commit But we need to be careful with this may not flushed syscall. Could use fsync(fd) to force flush Batching Group Commit Amortize block seeking time write absorption disk scheduling: Write block in a ordered sequence instead of random I/O Concurrency Log enables multiple transaction, each transaction may in different stage: Open : Able to accept new syscall’s write Committing Committed Old: waiting to be freed Collision HandlingAssume a scenario that when committing a transaction, because ext3 doesn’t block syscall, if a new transaction needs to do modification basing on previous transaction’s blocks. And we need to make sure current buffer cache won’t be modified while committing, so we could grep a buffer cache’s copy to the new transaction.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture13 Crash Recovery","slug":"Lec12-- Crash Recovery","date":"2022-01-30T09:02:37.098Z","updated":"2022-01-30T08:58:33.393Z","comments":true,"path":"2022/01/30/Lec12-- Crash Recovery/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec12--%20Crash%20Recovery/","excerpt":"","text":"Crash RecoveryLoggingTo achieve a atomic transaction, xv6 use logging to avoid data inconsistence if crash happens while writing. XV6’s syscall won’t write through the inode’s block, instead, it writes ops into log, after the transaction is committed, then xv6 itself writes the log into disk. Log designDisk has a continuous space for logging storage, and consists of a header block foe meta info and a bunch of block copy. header block records block index and block number. In xv6, just one transaction is doing at one time. group commit, xv6 could wrap many syscall()s and pack them into one transaction to increase parallelism. Also, because of limited log block, XV6 will split one large write into many little transactions to fit log. Write Ahead: Only modified blocks are written into log blocks then system starts to write into home location. Freeing: Till all log blocks written into home location and header block is wiped, then we free log block. Code Analysis: Start with begin_op(), to tell OS I’m gonna start a safe atomic transaction. log.outstanding is the number of syscall that queues at the current transaction. MAXBLOCKS is the threshold one syscall could use. 1234567891011121314151617voidbegin_op(void)&#123; acquire(&amp;log.lock); while(1)&#123; if(log.committing)&#123; sleep(&amp;log, &amp;log.lock); &#125; else if(log.lh.n + (log.outstanding+1)*MAXOPBLOCKS &gt; LOGSIZE)&#123; // this op might exhaust log space; wait for commit. sleep(&amp;log, &amp;log.lock); &#125; else &#123; log.outstanding += 1; release(&amp;log.lock); break; &#125; &#125;&#125; log_write(struct buf* b) . Write the modified block index in the header. This function will reserve a slot for this buf by increasing header-&gt;n , then pin this buf in the buffer cache (to meet the requirement of Write Ahead Rule). 12345678910111213141516171819202122232425262728293031// Caller has modified b-&gt;data and is done with the buffer.// Record the block number and pin in the cache by increasing refcnt.// commit()/write_log() will do the disk write.//// log_write() replaces bwrite(); a typical use is:// bp = bread(...)// modify bp-&gt;data[]// log_write(bp)// brelse(bp)voidlog_write(struct buf *b)&#123; int i; if (log.lh.n &gt;= LOGSIZE || log.lh.n &gt;= log.size - 1) panic(&quot;too big a transaction&quot;); if (log.outstanding &lt; 1) panic(&quot;log_write outside of trans&quot;); acquire(&amp;log.lock); for (i = 0; i &lt; log.lh.n; i++) &#123; if (log.lh.block[i] == b-&gt;blockno) // log absorbtion break; &#125; log.lh.block[i] = b-&gt;blockno; if (i == log.lh.n) &#123; // Add new block to log? bpin(b); log.lh.n++; &#125; release(&amp;log.lock);&#125; end_op(), decrease outstanding, and do commit if outstanding becomes zero. Note wakeup(&amp;log) is to wake up other process blocked on channel log. Because in end_up(), current process don’t need such reserved space as it claimed at begin_op() 1234567891011121314151617181920212223242526272829303132// called at the end of each FS system call.// commits if this was the last outstanding operation.voidend_op(void)&#123; int do_commit = 0; acquire(&amp;log.lock); log.outstanding -= 1; if(log.committing) panic(&quot;log.committing&quot;); if(log.outstanding == 0)&#123; do_commit = 1; log.committing = 1; &#125; else &#123; // begin_op() may be waiting for log space, // and decrementing log.outstanding has decreased // the amount of reserved space. wakeup(&amp;log); &#125; release(&amp;log.lock); if(do_commit)&#123; // call commit w/o holding locks, since not allowed // to sleep with locks. commit(); acquire(&amp;log.lock); log.committing = 0; wakeup(&amp;log); release(&amp;log.lock); &#125;&#125; commit() 1234567891011static voidcommit()&#123; if (log.lh.n &gt; 0) &#123; write_log(); // Write modified blocks from cache to log write_head(); // Write header to disk -- the real commit install_trans(0); // Now install writes to home locations log.lh.n = 0; write_head(); // Erase the transaction from the log &#125;&#125; write_log() , write all modified buf into log block. 123456789101112131415// Copy modified blocks from cache to log.static voidwrite_log(void)&#123; int tail; for (tail = 0; tail &lt; log.lh.n; tail++) &#123; struct buf *to = bread(log.dev, log.start+tail+1); // log block struct buf *from = bread(log.dev, log.lh.block[tail]); // cache block memmove(to-&gt;data, from-&gt;data, BSIZE); bwrite(to); // write the log brelse(from); brelse(to); &#125;&#125; write_head(), write header block into disk, which is real a commit starts 12345678910111213141516// Write in-memory log header to disk.// This is the true point at which the// current transaction commits.static voidwrite_head(void)&#123; struct buf *buf = bread(log.dev, log.start); struct logheader *hb = (struct logheader *) (buf-&gt;data); int i; hb-&gt;n = log.lh.n; for (i = 0; i &lt; log.lh.n; i++) &#123; hb-&gt;block[i] = log.lh.block[i]; &#125; bwrite(buf); brelse(buf);&#125; And left two functions is easy to understand their functionality from their name. install_trans, write log block into home data block. 12345678910111213141516static voidinstall_trans(int recovering)&#123; int tail; for (tail = 0; tail &lt; log.lh.n; tail++) &#123; struct buf *lbuf = bread(log.dev, log.start+tail+1); // read log block struct buf *dbuf = bread(log.dev, log.lh.block[tail]); // read dst memmove(dbuf-&gt;data, lbuf-&gt;data, BSIZE); // copy block to dst bwrite(dbuf); // write dst to disk if(recovering == 0) bunpin(dbuf); brelse(lbuf); brelse(dbuf); &#125;&#125;","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture12 File system on xv6","slug":"Lec11-- File System","date":"2022-01-30T09:02:37.096Z","updated":"2022-01-30T09:07:58.685Z","comments":true,"path":"2022/01/30/Lec11-- File System/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec11--%20File%20System/","excerpt":"","text":"File system on xv6File system features Abstraction Crash Safety Disk Layout Performance -&gt; Because storage are slow File system structures1234567struct inode&#123; file_info; name; inode_num; link_count; open_fd_count;//File can only be deleted, if above two are 0&#125;; 12345inode cache -&gt; mostly for synchronization ↑logging ｜buffer cache ｜-------- ｜disk ｜ Start with storage devicesCPU communicates to disk by PCIe, once the read/write is done, the driver will yield an interrupt. And thank to driver, in fs’s perspective, disk is like a long array![](Lec11– File System/Lec11-1.png)inode structure on xv6:![](Lec11– File System/Lec11-2.png) DirectoryIn the file system, directory &lt;=&gt; file.In xv6, directory entry is like: 1234struct dirent&#123; inum; filename char[15]&#125; To find a file in the directory, xv6 needs to scan over the block to match the filename. Then pickup inum as the inode block index. Practically, we could use more efficient data structure to get better performance. Crash SafetyOn multi-step operation system, if crash happens during inside the transaction, we need to make sure on-disk data.General solution – logging. Risks: fs operations are multi-step disk operation Crash may leave fs invariants violated. -&gt; need to be atomic After reboot, fs may immediately crash agian or no crash, but r/w incorrect data. General solution – Logging: Atomic fs calls fast recovery high performance Logging process: Log writes Commit op Note disk have a presumption that a single block or sector write should be atomic. Namely the sector will never be written partially. Install &lt;- the installation should be idempotent Clean log The advantage in logging is to make the transaction atomic, either we install all of operations or install nothing. API of xv6 123void log_write()// write the log.lh.block[i] as the modified block number index, namely marked the blocknumbervoid write_log()// copy modified blocks from cache to disk log, void write_head()// write header to disk -- the real commit timing If the crash happens after logheader is write, then when rebooting, xv6 will find the header block and check the log.lh.n, if it’s not zero, then we will do the recoverey to install log block into actual block Challenges Evict If bcache is full and needs to do eviction, we shouldn’t do eviction od a dirty block page Because some pages may still inside of a transaction, so we shouldn’t evict these pages. The way xv6 uses, is to pin the block by manually incrementing the page reference. And decreasing while commiting FS op must fit in log xv6’s log is 30 blocks, which fs operation must fit in 30 blocks before committing. The solution is to split a big size of writing transaction into many small writes. A question: Why we don’t require a huge atomic transaction, what if the system crashes during many small writing transaction? Concurrent fs calls If many fs calls happen at the same time, we have to make sure all concurrent ops must fit into log blocks The way xv6 solves it is to limit the number of concurrent fs call. If the transaction number exceeds limit, it falls into sleep until other transactions are done. And all the other concurrent fs calls maybe commit together, called group commit as a single big transaction commit A more general way maybe before adding one more fs transaction, do block number size check first.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture11 Machinery about synchronize","slug":"Lec10-- synchronize","date":"2022-01-30T09:02:37.095Z","updated":"2022-01-30T09:07:44.835Z","comments":true,"path":"2022/01/30/Lec10-- synchronize/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec10--%20synchronize/","excerpt":"","text":"Lec10 Machinery about synchronizeToday’s lecture talks about some synchronize mechanism, from lock, condition to wait to give a clear concept of what these mechanisms really effect. Diagram about switchTo avoid deadlock and repeat processes while doing switch, kernel needs a right order to lock and unlock. We need to make sure no other locks during swtch. Assume we have just 1 CPU and once p1 switch with 1 lock to p2, if p2 also tring to acquire the lock-&gt; deadlock And acquire() turns off interrupt to avoid another deadlock…(because in interrupt handler, it also needs lock) Coordination – wake and sleepTo make thread wait on specific condition or event.Given a simple example synchronize code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static int tx_done; // has the UART finished sending?static int tx_chan; // &amp;tx_chan is the &quot;wait channel&quot;// transmit buf[].voiduartwrite(char buf[], int n)&#123; acquire(&amp;uart_tx_lock); int i = 0; while(i &lt; n)&#123; while(tx_done == 0)&#123; // UART is busy sending a character. // wait for it to interrupt. sleep(&amp;tx_chan, &amp;uart_tx_lock); &#125; WriteReg(THR, buf[i]); i += 1; tx_done = 0; &#125; release(&amp;uart_tx_lock);&#125;// handle a uart interrupt, raised because input has// arrived, or the uart is ready for more output, or// both. called from trap.c.voiduartintr(void)&#123; acquire(&amp;uart_tx_lock); if(ReadReg(LSR) &amp; LSR_TX_IDLE)&#123; // UART finished transmitting; wake up any sending thread. tx_done = 1; wakeup(&amp;tx_chan); &#125; release(&amp;uart_tx_lock); // read and process incoming characters. while(1)&#123; int c = uartgetc(); if(c == -1) break; consoleintr(c); &#125;&#125; UART driver use uartwrite() to actually write character, we could find in code that they proceed 1 character 1 time so it needs to yield cpu instead of spin. UART hardware will raise interrupt to uartintr then wakeup uartwrite() to consume character. lost wakeup is situation that one process sends wakeup signal but missed somehow by receiver. It is caused by mistakes on adding lock. If we replace sleep() by broken_sleep() which just takes one parameter indicating the sleep channel. 12345678910111213141516171819voidbroken_sleep(void *chan)&#123; struct proc *p = myproc(); // Must acquire p-&gt;lock in order to // change p-&gt;state and then call sched. acquire(&amp;p-&gt;lock); // Go to sleep. p-&gt;chan = chan; p-&gt;state = SLEEPING; sched(); // Tidy up. p-&gt;chan = 0; release(&amp;p-&gt;lock);&#125; Previous snippet will like: 12345678while(tx_done == 0)&#123; //sleep(&amp;tx_chan, &amp;uart_tx_lock); release(&amp;uart_tx_lock); //lose wakeup window here!! broken_sleep(&amp;tx_chan); acquire(&amp;uart_tx_lock); &#125; So we need to do this three line atomically in sleep(). 123456789101112131415161718192021222324252627282930313233343536373839404142434445voidsleep(void *chan, struct spinlock *lk)&#123; struct proc *p = myproc(); // Must acquire p-&gt;lock in order to // change p-&gt;state and then call sched. // Once we hold p-&gt;lock, we can be // guaranteed that we won&#x27;t miss any wakeup // (wakeup locks p-&gt;lock), // so it&#x27;s okay to release lk. if(lk != &amp;p-&gt;lock)&#123; //DOC: sleeplock0 acquire(&amp;p-&gt;lock); //DOC: sleeplock1 release(lk); &#125; // Go to sleep. p-&gt;chan = chan; p-&gt;state = SLEEPING; sched(); // Tidy up. p-&gt;chan = 0; // Reacquire original lock. if(lk != &amp;p-&gt;lock)&#123; release(&amp;p-&gt;lock); acquire(lk); &#125;&#125;voidwakeup(void *chan)&#123; struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) &#123; acquire(&amp;p-&gt;lock); if(p-&gt;state == SLEEPING &amp;&amp; p-&gt;chan == chan) &#123; p-&gt;state = RUNNABLE; &#125; release(&amp;p-&gt;lock); &#125;&#125; In the wakeup, we have to check proc table preceding with acquiring p’s lock. So sleep with firstly get p’s lock then release lk to make sure all steps are atomic. Actually, semaphore is a more easier understaning way to use. Because caller have no worry about lost wakeups. (But internal semaphore, it takes good care about it) exit and killAs a process exits, we have to free memory, free pagetable and trapframe, clean up states, free stack… We cannot kill another thread directly, because it may in some critical area. In exit(), the process should reparent its children and set its state into ZOMBIE Parent should explicitly use wait() to reap zombie children.123456789101112131415161718192021222324252627282930313233wait(uint64 addr)&#123; ... for(;;)&#123; // Scan through table looking for exited children. havekids = 0; for(np = proc; np &lt; &amp;proc[NPROC]; np++)&#123; // this code uses np-&gt;parent without holding np-&gt;lock. // acquiring the lock first would cause a deadlock, // since np might be an ancestor, and we already hold p-&gt;lock. if(np-&gt;parent == p)&#123; // np-&gt;parent can&#x27;t change between the check and the acquire() // because only the parent changes it, and we&#x27;re the parent. acquire(&amp;np-&gt;lock); havekids = 1; if(np-&gt;state == ZOMBIE)&#123; // Found one. if(addr != 0 &amp;&amp; copyout(p-&gt;pagetable, addr, (char *)&amp;np-&gt;xstate, sizeof(np-&gt;xstate)) &lt; 0) &#123; release(&amp;np-&gt;lock); release(&amp;p-&gt;lock); return -1; &#125; freeproc(np); release(&amp;np-&gt;lock); release(&amp;p-&gt;lock); return pid; &#125; release(&amp;np-&gt;lock); &#125; &#125; &#125; ...&#125;","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture10 Thread Switch","slug":"Lec9-- Thread Switch","date":"2022-01-30T09:02:37.093Z","updated":"2022-01-30T09:07:51.271Z","comments":true,"path":"2022/01/30/Lec9-- Thread Switch/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec9--%20Thread%20Switch/","excerpt":"","text":"Thread SwitchThis lecture talks about xv6’s mechanism of thread switching. Background knowledgeThread : one serial execution, it should have its own pc, registers and stack. The scheduling system focus on the interleave multiple threads. There are two main methods to get this done, the first is using multi-cores and the second is to switch. To deal with a computation-bound program which takes a long run to finish the job, the scheduling system uses timer interrupt to pre-empt the kernel then switch to another process. In xv6, the scheduling does is first pre-empt the kernel then voluntarily yields cpu to other process.![](Lec9– Thread Switch/Lec9-pic1.png) Recall the workflow of interrupt. Trampoline.S stores all registers and pc in trapframe. Sometimes, in kernel, kernel thread just does a simple syscall and returns back to user thread by restore pc. But sometimes, kernel decides to swtich to other thread. The kernel thread should save its own state, we call it kernel context, includes kstack and kernel registers. Two time to make context switch – time interrupt and IO waiting. What xv6 doesActually, xv6’s the kernel context switch is conducted by scheduler thread, means kernel thread first switch to a middle thread then it chooses which process to run next.The stored states includes kstack pointer and pc. Once the scheduler switch next process, it also has its previously stored states to be reloaded. The scheduler is pin to each CPU, so it exactly chooses which runs on the CPU Kernel context is stored in p-&gt;context. Scheduler’s context is stored on the structure CPU for that core. Important, one core could just run one thread at one time and one thread can only run on one core at one time. schedulerswtch function store the current thread’s context, includes ra, sp... etc. then load the target thread context.one process kernel thread -&gt; sched() -&gt; swtch to scheduler() -&gt; find a runable thread() -&gt; swtch() -&gt; other process kernel thread Some thoughts Each child process are set a fake ra in allocproc(), because it needs a ra &amp; sp to be switch to and execute to set p-&gt;trapframe-&gt;epc = 0 in forkret()12345// Set up new context to start executing at forkret,// which returns to user space.memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));p-&gt;context.ra = (uint64)forkret;p-&gt;context.sp = p-&gt;kstack + PGSIZE; In xv6, even in the scheduler, the kernel turns on the interrupt to provent kernel from deadlock.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture9 Lock","slug":"Lec8-- Lock","date":"2022-01-30T09:02:37.091Z","updated":"2022-01-30T09:06:45.845Z","comments":true,"path":"2022/01/30/Lec8-- Lock/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec8--%20Lock/","excerpt":"","text":"LocksThis lecture talks about locks, I believe many people already have the concept of locks. So I just skip the very beginning of the lecture. Basic lock guidelineA consecuative rule: 2 processes accessing a shared data structure.If one is a writer=&gt; lock data structure is needed. Too strict: there is a style called lock-free programming. Isn’t all situation needed lock Too loose: Some situation are no shared memory but still need lock Some problems Deadlock When two process trying to acquire the lock holded by other, deadlock may happen (Not strict definition) Lock vs Modularity Lock ordering needes the lock are global. If exists m1.g() calls m2.f() which uses lock. Then f()’s lock need to be visible to m1. Violates abstract principle. Lock vs performance Need to split up data structure Best split is a challenge A better way to find the practical lock granularity. Start with coarse-grained locks Meassure the performance If multiple thread are trying to get lock -&gt; serialized -&gt; need redesign The implementation of lockSpinlockNeed hw support, test and set instructiontest_and_set(addr, r1, r2):lock()&ensp;&ensp;&ensp;tmp &lt;- [addr]&ensp;&ensp;&ensp;[arr] &lt;- r1&ensp;&ensp;&ensp;r2 &lt;- tmpunlock()return r2c std function -&gt; __sync_lock_test_and_set(void*, int) Memory layoutDue to compiler optimzation, some instructions could be resorted and exectued in different sequential than original written one.The spinlock could use __sync_synchronize() function to denote between two barrier, compiler shouldn’t rearrange any instruction order.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture8 Interrupt","slug":"Lec7-- Interrupt","date":"2022-01-30T09:02:37.090Z","updated":"2022-01-30T09:06:41.353Z","comments":true,"path":"2022/01/30/Lec7-- Interrupt/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec7--%20Interrupt/","excerpt":"","text":"InterruptRISCV interrupt-related registersSIE – supervisor interrupt enabled register, 3 bits for software int, external int and timer int.SSTATUS – supervior status register, one bit to enable interrupts.SIP – supervisor interrupt pending registerSCAUSE – supervisor cause registerSTVEC – supervisor trap vector registerMDELEG – machine delegate register Use of PLICPLIC, platform-level interrupt controller, passes interrupt on to a CPU. It is the handler of interrupts, that distributes interrupts among cores. If no CPU claims the interrupt, the interrupt stays pending till eventually be delivered to some core. Concurrency external deviceIn the RISCV xv6, external devices are running parallelly with kernel and controlled by driver. The way device used to communicate with kernel, is interrupt which has three properties: Asynchronous interrupts running process interrupt handler may not run in context of process who caused interrupt. Concurrency devices and process run in parallel Programming devices device can be difficult to program Refer to xv6-book, we have the definition of driver: Many device drivers execute code in two contexts: a top half that runs in a process’s kernelthread, and a bottom half that executes at interrupt time. The top half is called via system callssuch as read and write that want the device to perform I/O. This code may ask the hardwareto start an operation (e.g., ask the disk to read a block); then the code waits for the operationto complete. Eventually the device completes the operation and raises an interrupt. The driver’sinterrupt handler, acting as the bottom half, figures out what operation has completed, wakes up awaiting process if appropriate, and tells the hardware to start work on any waiting next operation. In the lecture, the professor uses one case to walk through the workflow of UART, and the xv6-book also writes the detailed explanation of how kernel interacts with devices.I just want to write down some ideas attracts me most during the lecture. Each device is mapped to a physical memory address. And there are handful of control register on it, likeRHR(receive holding register) and THR(transmit holding register)… Both user type a byte input and UART completes sending a byte both raise a interrupt. To display a character, driver puts character into UART’s send FIFO then interrupt when character has been sent To receive a keyboard hit, user hits key then returns in UART interrupt. Driver gets character from UART’s receive FIFO pollingConsider the fact that nowadays some devices generate events faster than one per microsecond, eg. gigabit ethernet can deliver 1.5 million small packets / second. The way to deal with those huge amount of interrupts is polling – processor spins until device wants attention. Wastes processor cycles if device is slow But inexpensive if device is fast No saving of regiser, etc","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lec7 Page Fault","slug":"Lec6-- Page Fault","date":"2022-01-30T09:02:37.088Z","updated":"2022-01-30T09:06:36.216Z","comments":true,"path":"2022/01/30/Lec6-- Page Fault/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec6--%20Page%20Fault/","excerpt":"","text":"Page FaultVirtual MemoryTwo advantages: Isolations: Because of the exist of satp, two different processes can’t visit other’s physical memory Memory Indirection: The mapping from va -&gt; pa, provides us many interesting features like, page fault, demanding, lazy allocation… sbrk()Grow(or shrink) the heap from lower to higher place(or h -&gt; l)Two allocations methods: Eager Allocation: Allocate the memory immediately once sbrk() is called. Lazy Allocation: Allocate the memory only when the memory is used(writed). But the situation is that many programmer don’t know the exact space they need, so they tend to allocate the maximum space. -&gt; lazy allocation is better. In xv6, lazy allocation should just bump up the p-&gt;sz and only alloc() space when the page is needed. zero-fill on demandIn the convention of c language, bss which stands for block starting symbol is the portion of an object file that contains statically allocated variables that are declared but have not been assigned value yet. So the lazy allocation could do is that, in the virtual address there might be many BSS pages, and we could page them to one same page on physical memory(one zero page). Once a bss page requries to write something on the page, the kernel yields a page fault and allocate a new physical all-zero page then remap the va to this page then return to user.![](Lec6– Page Fault/Lec6-2.png)Pros: Similar to lazy allocation(space saving) Quick execute because don’t have to initialize many pages at beginning. copy-on-write forkThe basic idea is the child process and parent process are sharing the same physical address at beginning. At somepoint once child/parent wants to do some modification on one page(let’s assume child). The kernel will detect the access to the physical page and try to allocate a new page copy for the child, (because in fork() all pages’ PTE are set to READ_ONLY, the write acess will cause trap). After the allocation, this specific va of child and parent’s PTE will be READ &amp; WRITE as normal. ![](Lec6– Page Fault/Lec6-1.png) Demaning pageIn exec(), we could load text and data not so eagerly that we can just set the virtual address but leave PTE_V as 0. So once the page is visited, it will yields a page fault then the kernel finally load the page from disk. Set page table, PTE_V = 0 After page fault read block/page from file into memory map the memory into pgtbl restart instruction Then we may also get into out-of-memory situation, so LRU and other eviction policies may be involved. Memory-mapped filesmmap(va, len, protection, flags, fd, off)unmap(va, len) do this lazily by store the mmap in vma (virtual memory area) maintains fd, prot, va, off... .","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lecture6 Isolation and syscall","slug":"Lec5-- Trap","date":"2022-01-30T09:02:37.086Z","updated":"2022-01-30T09:06:26.148Z","comments":true,"path":"2022/01/30/Lec5-- Trap/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lec5--%20Trap/","excerpt":"","text":"Lec6- Isolation and syscallSupervisor registers stap – Store the page table’s base address stvec – Store the address of trap program – trampolines, note that this address is mapped on user’s page table but without PTE_U which means the user can’t modify it. sepc – Store the address in the user mode when ecall happens sstrach – Store the address of trapframe which stores a frame useds to temporarily keep the user’s registers. Also used as swap “transfer station” register. See the usage of csrrw a0, sstrach, a0 in the trampoline.S for some examples. Work Flow12345678910 user_syscall() ecall------------------------------↓---------------------------------- uservec-trampoline userret() ↓ ↑ usertrap() usertrapret() ↓ ↑ syscall() -------------- ↓ ↑ specific SYS_call() Some interesting features: When user functions use ecall trying to enter kernel mode, what the RISCV actually does is just fetch the address at stvec and jump to that address and execute. Ecall fetches the value from stvec and saves the pc in the sepc. You shall see the page table haven’t been changed after ecall. stvec register keep the address of trampoline The last two line in the page table are exactly the kernel mode’s code, but mapped at user’s page table. Note PTE_U are not set, so user mode can’t access them. ![image-20211223103538097](Lec5– Trap/lec5-1.png) trampoline are the two-direction bridge for both user and kernel, because its physical address for user and kernel are both map to the same virtual address. Based on above handy design, we could do satp change and save 32 register into trapframe. Note that sstrach initially store the address of trapframe then swap the content with a0. Finally load kernel stack pointer and usertrap address then jump to kernel c code. trap.c checks the reason of the trap and redirect the following trap to jump tp kernelvec instead of trampoline. Then it analysis the cause number (in lecture’s example, we use syscall, so # is 8) For syscall, what usertrap() does is jump to syscall() function and syscall() will change the trapframe-&gt;a0’s value to make it received by user as the return value.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab11","slug":"Lab11 NIC","date":"2022-01-30T09:02:37.084Z","updated":"2022-01-30T09:04:33.560Z","comments":true,"path":"2022/01/30/Lab11 NIC/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab11%20NIC/","excerpt":"","text":"NetworkingIn this lab, we will program on NIC driver to control packet receive and transmit process. Because the lab has a detailed description of how to do the lab, I’ll just put on our code and explain some key points in the lab. Code Part1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253inte1000_transmit(struct mbuf *m)&#123; // // Your code here. // // the mbuf contains an ethernet frame; program it into // the TX descriptor ring so that the e1000 sends it. Stash // a pointer so that it can be freed after sending. // acquire(&amp;e1000_lock); int txport = regs[E1000_TDT]; if(tx_ring[txport].status != E1000_TXD_STAT_DD)&#123; printf(&quot;haven&#x27;t found a packet\\n&quot;); release(&amp;e1000_lock); return -1; &#125; if(tx_mbufs[txport])&#123; mbuffree(tx_mbufs[txport]); &#125; tx_mbufs[txport] = m; tx_ring[txport].addr = (uint64)m-&gt;head; tx_ring[txport].length = m-&gt;len; tx_ring[txport].cmd = E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS; regs[E1000_TDT] = (txport + 1) % TX_RING_SIZE; release(&amp;e1000_lock); return 0;&#125;static voide1000_recv(void)&#123; // // Your code here. // // Check for packets that have arrived from the e1000 // Create and deliver an mbuf for each packet (using net_rx()). // while(1)&#123; int next_idx = (regs[E1000_RDT] + 1) % RX_RING_SIZE; if(0 == (rx_ring[next_idx].status &amp; E1000_RXD_STAT_DD))&#123; break; &#125; rx_mbufs[next_idx]-&gt;len = rx_ring[next_idx].length; net_rx(rx_mbufs[next_idx]); struct mbuf *new = mbufalloc(0); rx_ring[next_idx].addr = (uint64)new-&gt;head; rx_ring[next_idx].status = 0; rx_mbufs[next_idx] = new; regs[E1000_RDT] = next_idx; &#125;&#125; Network ArchitectureEthernet![image-20220130143403111](Lab11 NIC/lab11-1.png) Ethernet frame struct: start flag + 48 bits target eth address + 48bits source eth address + 16bits ether type + payload + end flag 12345struct eth&#123; uint8 dhost[ETHADDR_LEN]; uint8 shost[ETHADDR_LEN]; uint64 type;&#125; __attribute__((packed)); ARPTo transmit packet to remote Host, we need IP address and ARP protocol to translate IP address into eth address. ARP header is nested included in ethernet packet. 12345678910111213141516171819struct arp &#123; uint16 hrd; // format of hardware address uint16 pro; // format of protocol address uint8 hln; // length of hardware address uint8 pln; // length of protocol address uint16 op; // operation char sha[ETHADDR_LEN]; // sender hardware address uint32 sip; // sender IP address char tha[ETHADDR_LEN]; // target hardware address uint32 tip; // target IP address&#125; __attribute__((packed));#define ARP_HRD_ETHER 1 // Ethernetenum &#123; ARP_OP_REQUEST = 1, // requests hw addr given protocol addr ARP_OP_REPLY = 2, // replies a hw addr given protocol addr&#125;; IP &amp; UDP1234567891011121314151617181920// an IP packet header (comes after an Ethernet header).struct ip &#123; uint8 ip_vhl; // version &lt;&lt; 4 | header length &gt;&gt; 2 uint8 ip_tos; // type of service uint16 ip_len; // total length uint16 ip_id; // identification uint16 ip_off; // fragment offset field uint8 ip_ttl; // time to live uint8 ip_p; // protocol uint16 ip_sum; // checksum uint32 ip_src, ip_dst;&#125;;// a UDP packet header (comes after an IP header).struct udp &#123; uint16 sport; // source port uint16 dport; // destination port uint16 ulen; // length, including udp header, not including IP header uint16 sum; // checksum&#125;; Kernel Network Stack![image-20220130150540694](Lab11 NIC/Lab11-2.png) Each layer will stripe out and check the header according to the its own protocol from mbuf ‘s cached packet to achieve nesting. MAC chip![image-20220130151743600](Lab11 NIC/lab11-3.png) DMA could directly visit memory without interact with CPU, DMA Engine controls PCI bus to transmit between memory and FIFO data buffer. Transmit steps: CPU put IP packet into memory and ask DMA Engine to do DMA transmit into FIFO buffer. Then MAC chip splits IP packet into Data frame whose size in range[64KB, 1518KB]. Each frame includes Target MAC Source MAC Protocol type CRC checksum.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab10","slug":"Lab10 Mmap","date":"2022-01-30T09:02:37.082Z","updated":"2022-01-30T09:04:20.193Z","comments":true,"path":"2022/01/30/Lab10 Mmap/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab10%20Mmap/","excerpt":"","text":"Lab10 MmapIn this lab, we need to develop a weak mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset), which have no designated addr and prot and flags are also limited to READ, WRITE and both and SHARED and PRIVATE. Also, we have to implement munmap(void *addr, size_t length), which won’t punch a hole in the middle of a region. To make mmap fast return, we won’t allocate any physical pages for a mmap call, and instead, we just put the call into a vma slot contains its meta information. 123456789struct vma&#123; struct file* f; //file handler pointer uint64 vstart; //start location in virtual memory uint64 length; //File size uint64 offset; //start location&#x27;s offset int valid; //Is this slot valid? int perm; //Permission : WRITE / READ int flags; //MAP_SHARED / MAP_PRIVATE&#125; In the lab website, lecturer has given us detailed information about how to write the code. And I want to introduce my design method which may be helpful to understand how to actually implement mmap. I will throw some questions to help (you or me later) to understand why I do this Where to put vma in the memory? 12At first I want to let vma increase with proc-&gt;sz, which means each time a mmap is called we need to reserve some `complete 4k size` in user memory to be physically allcoated. So I decided to put vma slots in the high space of heap ![image-20220116135201384](Lab10 Mmap/lab10-1.png) When to allocate the physical page 123In the mmap() call, we just select an empty vma slot and put this information into the slot then return.When a page_fault is captured by usertrap(), if the accessing va is inside some vma. Then allocate a 4k page at va&#x27;s page.We should have a do_mmap() function like following: 123456789101112131415161718int do_mmap(struct vma* mmap, uint64 va)&#123; struct proc * p = myproc(); printf(&quot;Current va :%p, perm : %x\\n&quot;, va, mmap-&gt;perm); //Need to do the alloc first uint64 pa = (uint64)kalloc(); memset((void*)pa, 0, PGSIZE); ilock(mmap-&gt;f-&gt;ip); if(readi(mmap-&gt;f-&gt;ip, 0, pa, mmap-&gt;offset + PGROUNDDOWN(va - mmap-&gt;vstart), PGSIZE) == 0) panic(&quot;do_mmap failed!\\n&quot;); iunlock(mmap-&gt;f-&gt;ip); if(mappages(p-&gt;pagetable, va, PGSIZE, pa, (mmap-&gt;perm &lt;&lt; 1) | PTE_U) &lt; 0) panic(&quot;dp_mmap(): mappages()\\n&quot;); printf(&quot;do_mmap() finished\\n&quot;); return 0;&#125; When allocate a physical page, we need to implement our own uvmalloc function to set the permission flags. How to deal with munmap? In this lab, we just need to deal with 3 situation: free from beginning to some point before end free from some point after start to the end free all What should we do while unmaping? free whole 4k page if the entire 4k range is unmaped. If the 4k is being freed, we have to write back the content if flag set as MAP_SHARED If the beginning is free, we have to redirect vma-&gt;offset , so when read from file, the true file offset should be va - vma-&gt;vstart + vma-&gt;offset 123456789101112131415161718192021222324252627282930sys_munmap()&#123; ... uint64 addr_aligned = ip; if(ip &gt; v-&gt;vstart)&#123; addr_aligned = PGROUNDUP(ip); length -= addr_aligned - ip; //free not at head uvmunmap2(p-&gt;pagetable,addr_aligned, PGROUNDUP(length) / PGSIZE, v); &#125;else if(ip + length &gt;= v-&gt;vstart + v-&gt;length)&#123; //free all uvmunmap2(p-&gt;pagetable, PGROUNDDOWN(ip), PGROUNDUP(length) / PGSIZE, v); &#125;else&#123; //free at beginning, but not to the end if(PGROUNDDOWN(ip + length) &gt; PGROUNDDOWN(ip))&#123; uvmunmap2(p-&gt;pagetable, PGROUNDDOWN(ip), PGROUNDUP(length) / PGSIZE, v); &#125; &#125; if(ip &lt;= v-&gt;vstart &amp;&amp; ip + length &gt; v-&gt;vstart)&#123; //modify offset v-&gt;offset += ip + length - v-&gt;offset; v-&gt;vstart = ip +length; &#125; v-&gt;length -= length; if(v-&gt;length &lt;= 0)&#123; fileclose(v-&gt;f); v-&gt;valid = 0; &#125; return 0;&#125; To deal with fork, although we copy vma from old to new, new pagetable won’t have to the corresponding pte on it. Because it just copy the pte range from [0, p-&gt;sz]. Don’t forget to wipe out valid when proc is freed.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab9","slug":"Lab9 Multithreading","date":"2022-01-30T09:02:37.080Z","updated":"2022-01-30T08:52:02.855Z","comments":true,"path":"2022/01/30/Lab9 Multithreading/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab9%20Multithreading/","excerpt":"","text":"Lab9 – MultithreadingUser thread implementationIn this section, we will implement a user-level thread. Like many user-level thread libraries do, it should have its ownpc, reregister and stack. For each thread, lab has already written the storage area in the struct thread. But because we still needs to save / restore the register through thread_switch, we also need a struct thread_context to store register status. 123456789101112131415161718struct thread_context&#123; uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11;&#125;; Like what kernel does in kernel/swtch.S(), we copy the context switch assembly code to save ra, sp and callee saved registers. In our implementation, ra is used to store the return address of thread_switch.S namely the last switch out point’s address. Cooperates with ra, sp provides stack pointer points to stack which stores more variables on stack. Finally, we have to define where ra and sp starts.D note sp grows from high to low, so we need to set sp = &amp;state and ra as the address of func Using threadLast two sections require us to do coding on pthread. Some main API are following: 123456pthread_mutex_t lock; // declare a lockpthread_mutex_init(&amp;lock, NULL); // initialize the lockpthread_mutex_lock(&amp;lock); // acquire lockpthread_mutex_unlock(&amp;lock); // release lockpthread_cond_wait(&amp;cond, &amp;mutex); // go to sleep on cond, releasing lock mutex, acquiring upon wake uppthread_cond_broadcast(&amp;cond); // wake up every thread sleeping on cond Actually I don’t want talk much about these because they are so easy for me? Maybe Barrier is worthy a concise description. To make all threads block till all of them synchronize at one point, we need pthread_cond_wait() and pthread_cond_broadcase(). In each round, if reached thread number are not enough, then they call cond_wait() to release the lock and sleep. Till the last thread reaches, it increment round and set 0 the thread counter then cond_broadcast(). Note, don’t forget to unlock properly.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab8","slug":"Lab8-- File System","date":"2022-01-30T09:02:37.078Z","updated":"2022-01-30T08:51:28.145Z","comments":true,"path":"2022/01/30/Lab8-- File System/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab8--%20File%20System/","excerpt":"","text":"Lab8 file systemLarge filesImplement “doubly-indirect” block in the inode, to make each inode be able to contain 256*256+256+11 blocks. Recall the definition of inode and how direct and indirect block works. This lab is much easy to accomplish. Just follow the hints and modify the dinode and inode for the new double-indirect block. Symbolic linksThe following sentence refers to manual page in linux of symlink. man symlink symlink() creates a symbolic link named linkpath which contains the string target. Symbolic links are interpreted at run time as if the contents of the link had been substituted into the path being followed to find a file or directory. Symbolic links may contain .. path components, which (if used at the start of the link) refer to the parent directories of that in which the link resides. A symbolic link (also known as a soft link) may point to an existing file or to a nonexistent one; the latter case is known as a dangling link. The permissions of a symbolic link are irrelevant; the ownership is ignored when following the link, but is checked when removal or renaming of the link is requested and the link is in a directory with the sticky bit (S_ISVTX) set. If linkpath exists, it will not be overwritten. man open (about O_NOFOLLOW) If pathname is a symbolic link, then the open fails, with the error ELOOP. Symbolic links in earlier components of the pathname will still be followed. (Note that the ELOOP error that can occur in this case is indistinguishable from the case where an open fails because there are too many symbolic links found while resolving components in the prefix part of the pathname.) So if open() calls for some file with O_NOFOLLOW just ignore the symbolic link flag and directly return the block. If without O_NOFOLLOW , we need do search recursively till find the first non-symlink inode or exceed 10-depth limit. In order to do so, firstly implement sys_symlink(): I put the symlink information into the first block of the inode. 123456789101112131415161718192021222324uint64 sys_symlink(void)&#123; char target[MAXPATH], path[MAXPATH]; struct inode *ip; if(argstr(0, target, MAXPATH) &lt; 0 || argstr(1, path, MAXPATH) &lt; 0)&#123; return -1; &#125; begin_op(); //To create a symlink in path ip = create(path, T_SYMLINK, 0, 0); if(ip == 0)&#123; end_op(); return -1; &#125; if(writei(ip, 0, (uint64)target, 0, MAXPATH) &lt; 0)&#123; end_op(); iunlockput(ip); return -1; &#125; iunlockput(ip); end_op(); return 0;&#125; Then to open a path which may be a symbolic link on it: 12345678910111213141516171819202122232425262728293031323334353637if(omode &amp; O_CREATE)&#123; ip = create(path, T_FILE, 0, 0); if(ip == 0)&#123; end_op(); return -1; &#125;&#125; else &#123; if((ip = namei(path)) == 0)&#123; end_op(); return -1; &#125; ilock(ip); while(ip-&gt;type == T_SYMLINK)&#123; if((omode &amp; O_NOFOLLOW) == 0)&#123; //follow sym link if(++depth &gt; 10)&#123; iunlockput(ip); end_op(); return -1; &#125; if(readi(ip, 0, (uint64)path, 0, MAXPATH) &lt; 0)&#123; iunlockput(ip); end_op(); return -1; &#125; iunlockput(ip); if((ip = namei(path)) == 0)&#123; end_op(); return -1; &#125; ilock(ip); &#125;else&#123; break; &#125; &#125; ... &#125;","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab7","slug":"Lab7 Lock","date":"2022-01-30T09:02:37.076Z","updated":"2022-01-30T09:04:05.912Z","comments":true,"path":"2022/01/30/Lab7 Lock/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab7%20Lock/","excerpt":"","text":"Lab7 LockMemory allocatorThis section is to make kalloc and kfree parallelly performed. The main idea is the free-list is shared among all CPUs so all CPUs need to serialize the allocation that we could improve this process by maintaining multiple freelist on different CPU. Threads need to steal freepage from other CPU’s if its freelist is null. Actually we could let process steal more pages to reduces the frequency of starve for freelist. But I just do the lazy programing and make process steal one page per time. If you add lock properly, this lab won’t be a big problem. Buffer cacheBefore starting the lab, xv6 book 8.2 to 8.3 section is definitely worthy reading. Namely, buffer cache is a layer between disk and logging and its exposed API is bwrite() and bread(). Because not like kalloc after allocation the page is in charge of single process, bcache’s buffer will be shared among all CPU and we can’t split them. So we should use finer-grain lock to reduce the frequency of contention. According to the suggestion in the lab website, we could use a hash table to mapping &lt;dev, blockno&gt; to buf. The new struct bcache should like following: 12345678910struct &#123; struct spinlock lock; struct buf buf[NBUF]; // Linked list of all buffers, through prev/next. // Sorted by how recently the buffer was used. // head.next is most recent, head.prev is least. //struct buf head; struct buf bucket[NBUCK]; struct spinlock hashlock[NBUCK];&#125; bcache; We need to modify two main functions, bget and brelse to acquire more parallelism . There are two tricky point to write the correct code. Ver1Firstly, give a naive scheme: 12345value := get_hash(dev, blockno);acquire(hash_table[value]&#x27;s lock);if no cache found acquire other hashtable&#x27;s lock iterate other hash_table to grap idol buffer If we acquired lock in the line2 and want to do iteration in line 4-5, it may cause deadlock. 123456789101112131415161718192021222324252627Assume block b1 hashs to 2, b2 hashs to 5They all not be cached----------------------------------------CPU1 CPU2----------------------------------------bget(dev, b1) bget(dev,b2) | | V VAcquire 2&#x27;s lock Acquire 5&#x27;s lock | | V Viterate all buckets iterate all buckets | | V V ...... | trying to acquire bucket2&#x27;s lock | | V V held by CPU1, wait...trying to acquire bucket5&#x27;s lock | Vheld by CPU2, wait.,.!Dead lock! To solve this problem, recall 4 conditions of deadlock: Mutual exclusion Hold and wait No preemption Circular wait We can’t solve this deadlock by destroying mutual exclusion, no preemption and circular wait . Here gives an example of circular wait, because we have to iterate through all buckets to find an empty buffer, we can’t give a perfect order of visiting to avoid deadlock. Ver2So the only option is before acquiring other bucket’s lock, release current lock first. But it comes with new problem, the window between the release and acquire is unsafe. It will cause two different threads seek for the same &lt;dev, blockno&gt; in two different empty buffer which violates rules. So we still have to lock. Given the following pseudo-code: 12345678value := get_hash(dev, blockno);acquire(hash_table[value]&#x27;s lock);if no cache found release(hash_table[value]&#x27;s lock) //dangerous window acquire(bcache&#x27;s lock)// Note the sequence of release and acuquire acquire other hashtable&#x27;s lock iterate other hash_table to grap idol buffer Note we should release() then acquire whole bcache&#39;s lock. If not may cause deadlock, for the similar reason that maybe exits one scenario that one process holds hash_table[value].lock and waits for bcache.lock and another process holds bcache.lock and waits for hashtable[value].lock in the later iteration. Ver3The window between release() and acquire() still have race condition, for the same reason and consequence mentioned in previous version. But since we lock the whole critical area from line. 7, no two threads will in line7-8 simultaneously, so we just need to check the hash_table[value] if a block is used at the beginning of acquire bcache&#39;s lock to keep synchronized. 12345678910value := get_hash(dev, blockno);acquire(hash_table[value]&#x27;s lock);if no cache found release(hash_table[value]&#x27;s lock) //dangerous window acquire(bcache&#x27;s lock)// Note the sequence of release and acuquire //Check another round check if cache found acquire other hashtable&#x27;s lock iterate other hash_table to grap idol buffer Some hint In multithreading programming, we could start with a coarse grain lock then reduce granularity step by step to meet the performance requirement. Once we want to hold two lock at one time, think carefully about ordering. (If somewhere exists a opposite acquiring sequence) Do transaction without lock, and before submitting we check the data consistency. If have a conflict, then we need handle this situation – Our design used this scheme which called Optimistic locking. ![image-20220102155708798](Lab7 Lock/lab7-1.png)","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab6","slug":"Lab6 COW","date":"2022-01-30T09:02:37.012Z","updated":"2022-01-30T09:03:41.941Z","comments":true,"path":"2022/01/30/Lab6 COW/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab6%20COW/","excerpt":"","text":"Lab6 COWCopy-on-write on xv6In this lab, we need to implement COW on xv6. The idea of the lab is quite straight forward but there are some subtle detailsneeds to be treated carefully. Main idea of the lab, is to lazily allocate the physical page to child process. This lab takes almost 15h to debug (what fk), so I will give a detailed description of how I code and hope to give a rather clear idea. Firstly, define some utils functions to manipulate refrence count table int get_ref(uint64 pa) // return reference count int dec_ref(uint64 pa) // decrease reference count int safy_inc_ref(uint64 pa) // do increment with lock uint64 split_COW(uint64 pa) // return a new page according to the origin physical page Define a reference counting table, because physical page used for allocation starts from KERNBASE(not so accurate) to PHYSTOP. so declear a array with ((PHYSTOP - KERNBASE) / PGSIZE) elements. The reference counting scheme: Decrease reference count in kfree(), once counting number &lt;= 0 (may have negative number because in kinit() kernel will kfree() all pages first) Set reference count = 1 in kalloc() In the fork()::uvmcopy(), we should do reference increase When actually split the COW-page, decrease reference of origin page and alloc a new page. Once we decide the scheme, we could modify the uvmcopy() to let it map the new_pagetable to old pa. 1234567891011121314151617181920212223242526272829303132intuvmcopy(pagetable_t old, pagetable_t new, uint64 sz)&#123; pte_t *pte; uint64 pa, i; uint flags; for(i = 0; i &lt; sz; i += PGSIZE)&#123; if((pte = walk(old, i, 0)) == 0) panic(&quot;uvmcopy: pte should exist&quot;); if((*pte &amp; PTE_V) == 0) panic(&quot;uvmcopy: page not present&quot;); *pte = ((*pte) | PTE_COW) &amp; (~PTE_W);//modify the flags, add COW bit and remove W bit pa = PTE2PA(*pte); flags = PTE_FLAGS(*pte); //if((mem = kalloc()) == 0) //goto err; //memmove(mem, (char*)pa, PGSIZE); if(mappages(new, i, PGSIZE, pa, flags) != 0)&#123;//map old pa to new goto err; &#125; safe_inc_ref(pa);//safely increase reference count &#125; return 0; err: uvmunmap(new, 0, i / PGSIZE, 1); panic(&quot;uvmcopy goes wrong&quot;); return -1;&#125; In the trap.c:usertrap(), we should handle the page fault like previous lazy allocation lab. So I just skip this part.Note the check condition should be:va &lt; p-&gt;sz &amp;&amp; ((pte = walk(pagetable, va, 0)) != 0) &amp;&amp; (*pte &amp; PTE_COW) &amp;&amp; (*pte &amp; PTE_V) Then we do the COW split 1234567891011121314151617int do_COW(pagetable_t pagetable, uint64 va)&#123; pte_t *pte = walk(pagetable, va, 0); uint64 pa = PTE2PA(*pte); int flags = (PTE_FLAGS(*pte) | PTE_W) &amp; (~PTE_COW); uint64 newpage = cow_split(pa);//get new allocate page, maybe the origin page if(newpage == 0)&#123; //if out of memory return -1; &#125; //unmap the origin physical page uvmunmap(pagetable, PGROUNDDOWN(va), 1, 0); //map the new page with COW remoed and W set if(mappages(pagetable, va, 1, newpage, flags) &lt; 0)&#123; panic(&quot;do_cow(): mappages&quot;); &#125; return 0;&#125; Note we do the reference reduce in cow_split() and the new page’s reference is set to 1 in kfree() Finally let’s check the cow_split() 123456789101112131415161718192021uint64cow_split(uint64 pa)&#123; acquire(&amp;reflock); if(get_ref(pa) &lt;= 1)&#123; //If the page just have 1 reference, just return the origin page release(&amp;reflock); return pa; &#125; uint64 new = (uint64)kalloc(); if(new == 0)&#123; //Out of memory release(&amp;reflock); return 0; &#125; memmove((void*)new, (const void*)pa, PGSIZE); dec_ref(pa); // reduce origin page refer release(&amp;reflock); return new;&#125; Just add some glue functions like safe_inc_ref, dec_ref… don’t forget to modify kfree() and kalloc(). Then we are done!![](Lab6 COW/lab6-pic1.png) Some hints Do get pa by PTE2PA macro and not use addrwalk() because it may return 0 if PTE_U not set. Use panic to decide some condition shouldn’t happen Add locks to reference table, maybe you could try smaller granularity like give each index a lock…","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab5","slug":"Lab5 Lazy Allocation","date":"2022-01-30T09:02:37.010Z","updated":"2022-01-30T09:03:47.966Z","comments":true,"path":"2022/01/30/Lab5 Lazy Allocation/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab5%20Lazy%20Allocation/","excerpt":"","text":"Lab 5 Lazy AllocationIn this lab, we gonna implement lazy allocation which means delay the true memory allocation till we actually needs it. lazy sbrk()To start with, we should modify the sbrk() from eager allocation to lazy one.But we should note that the parameter n can be arbitary number, either + or - so once the number is positve do the lazy allocation, but if the number is negative, we should do the deallocation immediately. Lazy AllocationThe time to truely allocate a page, is when kernel receives a No.13 or 15 exception, which tells the kernel a non-PTE_V page is being accessed. If the page is lazy allocated but not been truely allocated yet, we should do the allocation and return to the same instruction in the user mode. We should check the boundary case, that if va $\\in$ [0, p-&gt;sz) (Exclusively contain! Important) va $\\notin$ guard page range Then the virtual address is valid to allocate a new physical page for it. In this part, we could refer to the implementation of uvmalloc 1234567891011121314151617181920void allocate_page(uint64 va)&#123; pagetable_t pagetable = myproc()-&gt;pagetable; va = PGROUNDDOWN(va); void* mem = kalloc(); if(mem == 0)&#123; printf(&quot;usertrap(): scause %p pid=%d\\n&quot;, r_scause(), myproc()-&gt;pid); printf(&quot;Out of memory!\\n&quot;); myproc()-&gt;killed = 1; exit(-1); &#125; memset(mem, 0, PGSIZE); if(mappages(pagetable, va, PGSIZE, (uint64)mem, PTE_W|PTE_R|PTE_U) != 0)&#123; printf(&quot;usertrap(): scause %p pid=%d\\n&quot;, r_scause(), myproc()-&gt;pid); printf(&quot;Can&#x27;t allocate the page table\\n&quot;); kfree(mem); uvmdealloc(pagetable, PGROUNDUP(va), PGROUNDDOWN(va)); myproc()-&gt;killed = 1; exit(-1); &#125;&#125; Note that in the original implementation of xv6, we do the eager allocation, which means whenever we visit a virtual address, the physical page is mapped. So there are many panic check in the uvmunmap, walk, uvmcopy... should be canceled, because now many ptes are lazy allocated but not been mapped yet. So just leave to usertrap() to decide whether page should be accessed. Last, in the sbrkarg test, it tests the copyin and copyout functions.Because in the kernel mode, kernel simulates the dereference process by walkaddr, it won’t cause a exception. So we should manually modify the function and add a allocation to it. 1234va0 = PGROUNDDOWN(dstva);if(check_valid(va0) &amp;&amp; ((pte = walk(pagetable, va0, 0)) == 0 || (*pte &amp; PTE_V) == 0))&#123; allocate_page(va0);&#125; Some hints When encounter a bug, check the backtrace in the gdb. The way to decide whether a va is in the guard page, I use if(va &lt; PGROUNDDOWN(p-&gt;trapframe-&gt;sp)). I saw some other’s blog says could use r_sp(), but it just return the kernel stack pointer… Don’t forget to add codes on copyin, copyout and copyinstr.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab4","slug":"Lab4 Traps","date":"2022-01-30T09:02:37.008Z","updated":"2022-01-30T08:48:51.962Z","comments":true,"path":"2022/01/30/Lab4 Traps/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab4%20Traps/","excerpt":"","text":"Lab4Part2 –Backtracebacktrace is the method that prints the address of call stack. To implement backtrace, we should know some key points : In RISC-V, stack grows from high to low. fp points to the start of a function(highest address), then Return Address (offset by -8), then previous frame pointer address(offset by -16) We should print the address of Return Address(means the address of code) Stack size are 1 PGSIZE and aligned. So we just need to fetch the frame pointer by the follower assembly code: 1234567static inline uint64r_fp()&#123; uint64 x; asm volatile(&quot;mv %0, s0&quot; : &quot;=r&quot; (x) ); return x;&#125; Then recursively fetch the previous frame pointer, note we should use check the boundary of one page. Part3 – AlarmIn this part, the alarm are like a callback function but trigged by timer(Event driven).So sys_sigalarm are the setter of this scheme, first paramter is the count down number and second is the hanlder of callback function. ‘sys_sigreturn’ is the return function that reloads context of origin function(we will see in the lab)Firstly, we should register two functions in /user and make a syscall reference for them, then we go to /kernel to complete these two syscalls. In the sys_sigalarm, we should keep the tick intervals and the function pointer in the struct proc for later call. Then sys_sigreturn, for now it just return 0 is ok. Note that in the /kernel/trap.c:usertrap(), it handles the all exceptions (syscall, timer interupt…). Once it is called by an interupt of timer, we should increase the tick number in the struct proc and once ticks == interval, go to handler. By modifing the address of pc, we could jump to the handler. But the way jump back to the origin code should be considered carefully – The lab hints provide us a process to return, which is the sys_sigreturn. We should reload all the origin(as many as possible to keep the context safy) in it then jump back to origin place(by pc register) Hints p-&gt;trapframe-&gt;epc points to the return address once the process jumps from kernel Record as many as possible register in the proc especially pc, sp, ra and so on. add backtrace() in panic() so that whenever a panic happens, it will print a backtrace information.","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab3","slug":"Lab3 Page Table","date":"2022-01-30T09:02:37.006Z","updated":"2022-01-30T09:03:27.155Z","comments":true,"path":"2022/01/30/Lab3 Page Table/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab3%20Page%20Table/","excerpt":"","text":"Lab3 pagetable In this lab, we will modify the pagetable, and finally be able to dereference pointers in the kernel mode. Lab1–Print page table In this lab, it’s much easier than later two lab that we just need to write a DFS recursive function to walk down the 3-level pagetable and print out the path. Check vm.c/freewalk() and dfs the pagetable, note the format of a virtual memory address.![](Lab3 Page Table/lab3-pic1.png)We should notice that different from intel’s pagetable, xv6 store the PPN at high 44-bit.So normally we need the PTE2PA marcos to convert this pagetable content into physic address by shifting over bits. Once we get to the lowest-level, we should know that non-leaf nodes have non-setted PTE_W, PTE_R, PTE_X flags (We could use them to detect wheather leaf nodes) lab2–Kernel page table per processThis lab is used to prepare us for lab3, which needs make user mode’s pointers deferencable in kernel mode.We should not just keep a pointer of global kernel_pagetable in each process because xv6 support multi-process concurrently run in kernel mode. Thus we need a real copy of kernel page table per process. So we firstly need add a new member variable in the struct proc to record its own kernel page table pointer. Then follow vm.c/kvminit() to initialize the this knpagetbl. Modify the vm.c/kvmmap() function to make it accept one more arguement pagetbl, this function is used to map a va into a pa on one page table. Modify the vm.c/kvmpa() function to make it accept one more argument pagetbl, used to walk down the page table and find the va’s corresponding pa. And we also need mapping kernel stack for each process, note that originally xv6 just keep one kernel page table, so it need to record NPROC‘s kstack mapping to be accessed by NPROC‘s processes. But as we implement the kernel page table for each process, the private kernel page table just need record one kernel stack‘s virtual address points to different physical address. Delete the kernel stack initialization code on proc.c/procinit and do the kstack init on proc.c/allocproc. Note that we could map kstack va on the place because the va is private to each process. Modify the vm.c/schedular() to load the private kernel, (see vm.c/kvminithart ), don’t forget change the satp register back and clean the TLB. Free the kernel page table and kstack (Important!), we could imitate vm.c/freewalk() but remember not do free on the real physic pages. And we need to do free kstack first before we free the kernel page table. ![](Lab3 Page Table/lab3-pic2.png) Lab3–Simplify copyin/copyinstrIn the original xv6’s implementation, if we want to dereferen a user’s pointer, the kernel needs simulate the walk down process which should be done by MMU and TLB. (see vm.c/walk()). If we could directly dereference the pointer, this process could be accelarated by the hardware. The main idea is to make every modification on user’s page table reflect on kernel page table. So we firstly need two functions –kvmcopy(pagetable_t src , pagetable_t dst, uint64 va, uint64 len)kvmdealloc(pagetable_t pgtbl, uint64 oldsize, uint64 newsize) Note that in the user mode, virtual memory always grow from 0, (see exec.c/exec() for how va grows), which means if we need to free the memory, we should free from [0, p-&gt;sz]. Then for every user page table modification, do mapping to private kernel page table in (exec(), fork(), growproc(), userinit()). Note that in the growproc, the function does not only handle the grow but also shrink of mem, so we need use the kvmdealloc to shrink the kernel page table as well.. Some Hints After xv6 is booted, the address is at 0xC000000, which is the address of the PLIC register, so user’s page table should not exceed this address. Add a p-&gt;sz check statement in exec(). For the same reason, note that CLINT address is under 0xC000000, so do not map this address on the private kernel page table, but we should do so on the global page table. Don’t forget free kstack pointer in the freeproc()","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab2","slug":"Lab2 Syscalls","date":"2022-01-30T09:02:37.004Z","updated":"2022-01-30T09:03:11.354Z","comments":true,"path":"2022/01/30/Lab2 Syscalls/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab2%20Syscalls/","excerpt":"","text":"System Calls(pending the challenge) In the lab, we will get deeper into OS than the previous one. We are about to implement the ‘bridge’ between user and kernel mode, then implement two specific syscall to be called by user’s program. Lab The two labs are symmetry overall, so I just describe how to do a system call. To make our own syscalls,we should know how the syscall works between user &amp; kernel mode. 1234567 user function ↓ wrapped interface-----------------------------↓(ecall)-------------------------------------- syscall() ↓ kernel sys_(syscall&#x27;s name) In this framework, there are some points: How to use ecall? We first declare a wrapped function in user/user.h, then implement it in user/usys.S which are assembly code generated by user/usys.pl, the assembly code are used to load the syscall number into a7 register. In kernel mode how to fetch argument? Refer to other functions in kernel/sysproc.c, we can use argint() in kernel/syscall.c to fetch argument from stack syscall() in kernel/syscall.c , what’s its function? It precedes after ecall, fetches the a7 then executes corresponding syscall, then put the return value into a0 Trace Remember to put your new syscall number into every part a syscall can involve with, especially don’t forget set the function point entry in syscall.c‘s array. The function uses mask to mark all system call it wants to trace, so each bit on mask is a syscall you should check. Use mask &amp; 1 &lt;&lt; syscallnum to check it. ![Lab2-1](Lab2 Syscalls/Lab2-1.png) Sysinfo The way kernel mode gives back argument to user mode is to call copyout which maps return args’ virtual memory back to physical memory then revises it to target value. The collections of free memory and processes is not too hard, we can just iterate the freemem linklist and process array. ![lab2-2](Lab2 Syscalls/lab2-2.png) Conclusion In this lab, we breakthrough the barrier between u/k mode, the whole detailed system call process is in front of us. But there are still many information we need to get into, mmap, pages management , process management, etc. Also, I have not started challenges, because I am about to begin my graduate life in NUS, hopefully I can go back here and finish them someday!","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"MIT6.S081 Lab1","slug":"Lab1 Unix utilities","date":"2022-01-30T09:02:37.002Z","updated":"2022-01-30T09:02:59.979Z","comments":true,"path":"2022/01/30/Lab1 Unix utilities/","link":"","permalink":"https://zjuytw.github.io/2022/01/30/Lab1%20Unix%20utilities/","excerpt":"","text":"Xv6 and Unix utilities In this lab, we gonna implement many interesting and useful programs like, sleep, pingpong, primes, find, and xargs . There are some points I want to emphasize, though this lab is not so hard. Before Start My experiment environment: 12VM: VMware workstationLinux ubuntu 20.04 I can not find corresponding software in apt-get when my kernel was at 16.04 or 18.04, so I have to update to 20.04. Lab The structure we should know before programming is that, there are kernel’s and user’s code, when I need to do something on system level, we should call kernel’s function. Gracefully, we have many wrapped interface on users’ functions that we can directly call them. Check them in user/user.h sleep Skip pingpong Note that in pipe[2], pipe[0] is for receiving data and pipe[1] is for writing into. primes The brief of this algorithm is used in the situation that, assume you have a bunch of machines, to find primes given a list of numbers which continuously +1 one after another. And each stage selects one minimum number and it is exactly prime, then verify other numbers do not have the prime as their factor. Then send left numbers into next stage… ![lab1-1](Lab1 Unix utilities/lab1-1.png) Just use recursion to find next stage’s number and send to the child’s process find Refer to user/ls.c, that is a good template. What I want to mention is some points of File System struct state is the information a file descriptor refers to, stored in inode and can be fetched by fstat(fd, &amp;st) 12345678910#define T_DIR 1 // Directory#define T_FILE 2 // File#define T_DEVICE 3 // Devicestruct stat &#123; int dev; // File system’s disk device uint ino; // Inode number short type; // Type of file short nlink; // Number of links to file uint64 size; // Size of file in bytes&#125;; struct dirent serves the same a file descriptor’s information, but it mainly provides file’s name 12345678struct dirent&#123; long d_ino; /* inode number */ off_t d_off; /* offset to this dirent */ unsigned short d_reclen; /* length of this d_name */ unsigned char d_type; /* the type of d_name */ char d_name [NAME_MAX+1]; /* file name (null-terminated) */&#125; xargs This program helps me to understand xargs a lot, thanks gosh. To implement xargs, we need first process stdin because pipe will redirect xargs’s stdin to last program’s stdout. When this done, we can userexec() to execute the command after xargs. Note that when processing stdin, we should read or gets byte by byte and when once encounter ‘\\n’, do command. Conclusion This programs helps me to review the usage of them and help me dabble into fork(), exec(), pipe(), and file systems Note: when programming for a child process, just use exit","categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"}]},{"title":"484. Find Permutation","slug":"484. Find Permutation","date":"2021-12-14T08:27:10.099Z","updated":"2021-12-14T08:26:48.249Z","comments":true,"path":"2021/12/14/484. Find Permutation/","link":"","permalink":"https://zjuytw.github.io/2021/12/14/484.%20Find%20Permutation/","excerpt":"","text":"484. Find PermutationDescription Solution Recall how to generate a next_permutation, the way we do to keep the permutation small is just reverse the left-most reverse pair. In this question, we just keep a ‘123456… n’ basic permutation then reverse the substr that contiguous ‘D’ point at. eg. Code 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;int&gt; findPermutation(string s) &#123; int n = s.size() + 1; vector&lt;int&gt; res; for(int i = 1; i &lt;= n; i++)&#123; res.push_back(i); &#125; for(int i = 0; i &lt; n-1; i++)&#123; if(s[i] == &#x27;D&#x27;)&#123; int j; for(j = i + 1; j &lt; n-1; j++)&#123; if(s[j]== &#x27;I&#x27;) break; &#125; //reverse from res[i] to res[j] reverse(res.begin() + i, res.begin() + j + 1); i = j; &#125; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Permutation","slug":"Permutation","permalink":"https://zjuytw.github.io/tags/Permutation/"}]},{"title":"668. Kth Smallest Number in Multiplication Table","slug":"668. Kth Smallest Number in Multiplication Table","date":"2021-12-06T07:51:11.036Z","updated":"2021-12-06T07:34:39.438Z","comments":true,"path":"2021/12/06/668. Kth Smallest Number in Multiplication Table/","link":"","permalink":"https://zjuytw.github.io/2021/12/06/668.%20Kth%20Smallest%20Number%20in%20Multiplication%20Table/","excerpt":"","text":"668. Kth Smallest Number in Multiplication Table Description Solution Generally, k-th related problem could be solved by binary search to guess the right answer and verify. Once we enumerate a number, we could calculate its rank. Another important thing we should notice is that we calculate the elements number that less equal than the target one. Code 123456789101112131415161718192021222324class Solution &#123;public: int findKthNumber(int m, int n, int k) &#123; int l = 1, r = m * n; while(l &lt; r)&#123; int mid = l + (r - l)/2; //Analyze mid&#x27;s property, factorization if(count_le(mid, m, n) &lt; k)&#123; l = mid + 1; &#125;else&#123; r = mid; &#125; &#125; return l; &#125; int count_le(int val, int m, int n)&#123; int cnt = 0; for(int i = 1; i &lt;= m; i++)&#123; cnt += min(n, val / i); &#125; return cnt; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Binary Search","slug":"Binary-Search","permalink":"https://zjuytw.github.io/tags/Binary-Search/"}]},{"title":"757. Set Intersection Size At Least Two","slug":"757. Set Intersection Size At Least Two","date":"2021-12-06T07:51:11.034Z","updated":"2021-12-06T07:50:26.738Z","comments":true,"path":"2021/12/06/757. Set Intersection Size At Least Two/","link":"","permalink":"https://zjuytw.github.io/2021/12/06/757.%20Set%20Intersection%20Size%20At%20Least%20Two/","excerpt":"","text":"757. Set Intersection Size At Least TwoDescription Solution Refer to 452 452. Minimum Number of Arrows to Burst Balloons. These two questions are very similar. We need to greedily find the maximum non-overlapping intervals. And the template should always sort the intervals by endpoints and see if we could pick elements greedily to fit the requirement. Code 12345678910111213141516171819202122232425262728class Solution &#123;public: int intersectionSizeTwo(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) &#123; sort(intervals.begin(), intervals.end(), [](vector&lt;int&gt; &amp; a, vector&lt;int&gt; &amp;b)&#123; if(a[1] == b[1])&#123; return a[0] &lt; b[0]; &#125; return a[1] &lt; b[1]; &#125;); vector&lt;int&gt; res = &#123;intervals.front()[1] -1 , intervals.front()[1]&#125;; for(int i = 1; i &lt; intervals.size(); i++)&#123; if(intervals[i][0] == res.back())&#123; //need to add one element to satisfy the requirement res.push_back(intervals[i][1]); &#125;else if(intervals[i][0] &lt; res.back())&#123; if(intervals[i][0] &gt; res[res.size() - 2])&#123; //need to add one element to satisfy the requirement res.push_back(intervals[i][1]); &#125; &#125;else&#123; //need to add two elements to satisfy the requirement res.push_back(intervals[i][1] - 1); res.push_back(intervals[i][1]); &#125; &#125; return res.size(); &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"},{"name":"Interval","slug":"Interval","permalink":"https://zjuytw.github.io/tags/Interval/"}]},{"title":"1235. Maximum Profit in Job Scheduling","slug":"1235. Maximum Profit in Job Scheduling","date":"2021-11-17T07:41:52.466Z","updated":"2021-11-17T07:41:33.356Z","comments":true,"path":"2021/11/17/1235. Maximum Profit in Job Scheduling/","link":"","permalink":"https://zjuytw.github.io/2021/11/17/1235.%20Maximum%20Profit%20in%20Job%20Scheduling/","excerpt":"","text":"1235. Maximum Profit in Job Scheduling Description Solution Time interval question. An simple intuition should be, if we find a best solution for a previous time, then we could use this information to calculate the later one with startTime[i] &gt; endTime[i-1]. So we could use binary search to find the endTime suitable for current startTime. To use bs, we need sort by endTime. Code 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: int jobScheduling(vector&lt;int&gt;&amp; startTime, vector&lt;int&gt;&amp; endTime, vector&lt;int&gt;&amp; profit) &#123; int n = startTime.size(); vector&lt;vector&lt;int&gt;&gt; jobs(n); for(int i = 0; i &lt; n; i++) jobs[i] = &#123;startTime[i], endTime[i], profit[i]&#125;; sort(jobs.begin(), jobs.end(), [](vector&lt;int&gt; &amp;a, vector&lt;int&gt; &amp;b)&#123; if(a[1] == b[1]) return a[0] &lt; b[0]; return a[1] &lt; b[1]; &#125;); vector&lt;int&gt; dp(n); vector&lt;int&gt; before; //dp[i] -&gt; includesively previous i&#x27;s jobs&#x27; maximum profits, dp[i] = max(dp[i-1], dp[bs(starttime)] + jobs[i].profit) int res = 0; dp[0] = jobs[0][2]; before.push_back(jobs[0][1]); for(int i = 1 ; i &lt; n; i++)&#123; dp[i] = dp[i-1]; auto iter = upper_bound(before.begin(), before.end(), jobs[i][0]); if(iter != before.begin() &amp;&amp; *prev(iter) &lt;= jobs[i][0])&#123; dp[i] = max(dp[i], dp[prev(iter) - before.begin()] + jobs[i][2]); &#125;else&#123; dp[i] = max(dp[i], jobs[i][2]); &#125; before.push_back(jobs[i][1]); res = max(res, dp[i]); &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Binary Search","slug":"Binary-Search","permalink":"https://zjuytw.github.io/tags/Binary-Search/"}]},{"title":"1627. Graph Connectivity With Threshold","slug":"1627. Graph Connectivity With Threshold","date":"2021-11-15T16:53:17.255Z","updated":"2021-11-15T16:53:04.381Z","comments":true,"path":"2021/11/16/1627. Graph Connectivity With Threshold/","link":"","permalink":"https://zjuytw.github.io/2021/11/16/1627.%20Graph%20Connectivity%20With%20Threshold/","excerpt":"","text":"1627. Graph Connectivity With Threshold Description Solution Obviously we need to use UF set. The problem here is how to enumerate the gcd of two number. I firstly just iterate n^2 numbers pairs and try to find their common factors and got TLE. –&gt; We could start from the factor and to enumerate its multiples. Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class UF&#123; public: vector&lt;int&gt; uf, size; UF(int n):uf(n), size(n)&#123; for(int i = 0; i &lt; n; i++)&#123; uf[i] = i; size[i] = 1; &#125; &#125; void Union(int x, int y)&#123; int fx = find(x), fy = find(y); if(fx == fy) return; uf[fx] = fy; size[fy] += size[fx]; &#125; int find(int x)&#123; if(uf[x] != x)&#123; uf[x] = find(uf[x]); &#125; return uf[x]; &#125; int get_size(int x)&#123; int fx = find(x); return size[fx]; &#125;&#125;;class Solution &#123;public: vector&lt;bool&gt; areConnected(int n, int threshold, vector&lt;vector&lt;int&gt;&gt;&amp; queries) &#123; //factorization + UF vector&lt;bool&gt; res(queries.size(), true); if(threshold == 0)&#123; return res; &#125; UF uf(n+1); for(int i = threshold + 1; i &lt; n; i++)&#123; for(int p = i, q = 2 * i; q &lt;= n; p += i, q += i)&#123; uf.Union(p,q); &#125; &#125; for(int i =0 ; i &lt; queries.size(); i++)&#123; res[i] = uf.find(queries[i][0]) == uf.find(queries[i][1]); &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Union-Find","slug":"Union-Find","permalink":"https://zjuytw.github.io/tags/Union-Find/"}]},{"title":"1944. Number of Visible People in a Queue","slug":"1944. Number of Visible People in a Queue","date":"2021-09-23T15:03:16.859Z","updated":"2021-09-23T15:02:55.955Z","comments":true,"path":"2021/09/23/1944. Number of Visible People in a Queue/","link":"","permalink":"https://zjuytw.github.io/2021/09/23/1944.%20Number%20of%20Visible%20People%20in%20a%20Queue/","excerpt":"","text":"1944. Number of Visible People in a Queue Description Solution Using monotone stack, look into preceding first number larger than current one. Code 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; canSeePersonsCount(vector&lt;int&gt;&amp; heights) &#123; int n = heights.size(); vector&lt;int&gt; res(n, 0); stack&lt;int&gt; stk; for(int i = n-1; i &gt;= 0; i--)&#123; while(!stk.empty() &amp;&amp; stk.top() &lt; heights[i])&#123; res[i]++; stk.pop(); &#125; if(!stk.empty()) res[i]++; stk.push(heights[i]); &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Monotone Stack","slug":"Monotone-Stack","permalink":"https://zjuytw.github.io/tags/Monotone-Stack/"}]},{"title":"1998. GCD Sort of an Array","slug":"1998. GCD Sort of an Array","date":"2021-09-15T16:17:28.049Z","updated":"2021-09-15T16:13:41.500Z","comments":true,"path":"2021/09/16/1998. GCD Sort of an Array/","link":"","permalink":"https://zjuytw.github.io/2021/09/16/1998.%20GCD%20Sort%20of%20an%20Array/","excerpt":"","text":"1998. GCD Sort of an Array Description Solution Because we are using gcd to transfer numbers, so the number which shares the same factor should in the same set. So we could use Union-Find to mark numbers. There is also a tricky point that how to get the prime factor of one number. https://www.geeksforgeeks.org/print-all-prime-factors-of-a-given-number/ Code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546const int N = 1E5+1;class Solution &#123; int p[N]; static bool cmp(int&amp; a, int &amp;b)&#123;return a &lt; b;&#125;public: void merge(int a, int b)&#123; int x = find(a), y = find(b); if(x != y)&#123; p[x] = y; &#125; &#125; int find(int a)&#123; if(a != p[a])&#123; p[a] = find(p[a]); &#125; return p[a]; &#125; bool gcdSort(vector&lt;int&gt;&amp; nums) &#123; for(int i = 1; i &lt; N; i++) p[i] = i; vector&lt;int&gt; nums2 = nums; for(int i = 0; i &lt; nums.size(); i++)&#123; int tmp = nums[i]; for(int j = 2; j &lt;= tmp/j ; j++)&#123; bool flag = false; while(tmp % j == 0)&#123; tmp /= j; flag = true; &#125; if(flag) merge(nums[i], j); &#125; if(tmp &gt; 1) merge(nums[i], tmp); &#125; sort(nums.begin(), nums.end(),cmp); for(int i = 0; i &lt; nums.size(); i++)&#123; if(nums[i] == nums2[i]) continue; if(find(nums[i]) != find(nums2[i])) return false; &#125; return true; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Union Find","slug":"Union-Find","permalink":"https://zjuytw.github.io/tags/Union-Find/"}]},{"title":"2002. Maximum Product of the Length of Two Palindromic Subsequences","slug":"2002. Maximum Product of the Length of Two Palindromic Subsequences","date":"2021-09-15T16:17:28.046Z","updated":"2021-09-15T16:13:55.626Z","comments":true,"path":"2021/09/16/2002. Maximum Product of the Length of Two Palindromic Subsequences/","link":"","permalink":"https://zjuytw.github.io/2021/09/16/2002.%20Maximum%20Product%20of%20the%20Length%20of%20Two%20Palindromic%20Subsequences/","excerpt":"","text":"2002. Maximum Product of the Length of Two Palindromic Subsequences Description Solution We could enumerate all the potential substring then check if they are palindromic by using state compression. Then we iterate the subset of the inverse state to check if two substring are compatible. Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: int maxProduct(string s) &#123; int n = s.size(); vector&lt;bool&gt; dp(1 &lt;&lt; n); dp[0] = true; int res = 0; for(int i = 1; i &lt; 1 &lt;&lt; n; i++)&#123; auto [h,t] = getHT(i, n); if(h == t)&#123; dp[i] = true; &#125;else&#123; dp[i] = (s[h] == s[t]) &amp;&amp; dp[i - (1 &lt;&lt; h) - (1 &lt;&lt; t)]; &#125; &#125; for(int i = 1; i &lt; (1 &lt;&lt; n); i++)&#123; if(!dp[i]) continue; int mask = (1&lt;&lt;n) -1 - i; int len = __builtin_popcount(i); for(int j = mask; j &gt; 0; j = (j-1) &amp; mask)&#123; if(dp[j])&#123; res = max(res, len * __builtin_popcount(j)); &#125; &#125; &#125; return res; &#125; pair&lt;int,int&gt; getHT(int num, int n)&#123; int l = n, r = 0; while(true)&#123; if(num &amp; (1&lt;&lt;l)) break; l--; &#125; while(true)&#123; if(num &amp; (1 &lt;&lt; r)) break; r++; &#125; return make_pair(l,r); &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"}]},{"title":"1894. Find the Student that Will Replace the Chalk","slug":"1894. Find the Student that Will Replace the Chalk","date":"2021-09-10T17:11:51.276Z","updated":"2021-09-10T17:11:30.920Z","comments":true,"path":"2021/09/11/1894. Find the Student that Will Replace the Chalk/","link":"","permalink":"https://zjuytw.github.io/2021/09/11/1894.%20Find%20the%20Student%20that%20Will%20Replace%20the%20Chalk/","excerpt":"","text":"1894. Find the Student that Will Replace the Chalk Description Solution presum + binary search Code 12345678910111213class Solution &#123;public: int chalkReplacer(vector&lt;int&gt;&amp; chalk, int k) &#123; if(chalk[0] &gt; k) return 0; for(int i = 1; i &lt; chalk.size(); i++)&#123; chalk[i] += chalk[i-1]; if(chalk[i] &gt; k) return i; &#125; k %= chalk.back(); int pos = upper_bound(chalk.begin(), chalk.end(), k) - chalk.begin(); return pos; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Prefix Sum","slug":"Prefix-Sum","permalink":"https://zjuytw.github.io/tags/Prefix-Sum/"}]},{"title":"808. Soup Servings","slug":"808. Soup Servings","date":"2021-09-10T17:11:51.257Z","updated":"2021-09-15T16:16:26.419Z","comments":true,"path":"2021/09/11/808. Soup Servings/","link":"","permalink":"https://zjuytw.github.io/2021/09/11/808.%20Soup%20Servings/","excerpt":"","text":"808. Soup Servings Description Solution In this problem, because all soup are decresed in multiple 25, so we could divid N by 25 then do dp on each one step. dp[i] [j] -&gt; the desired value with i ml and j ml soup. 1dp[i][j] = 0.25 * (dp[i-4][j] + dp[i-3][j-1] + dp[i-2][j-2] + dp[i-1][j-3]) And we note the corner case are: 123dp[i][j] = 0.5 (for i &lt;= 0 and j &lt;= 0)dp[i][j] = 1 (for i = 0, j &gt;= 1)dp[i][j] = 0 (for i &gt;= 1, j = 0) Code 12345678910111213141516171819202122class Solution &#123;public: double soupServings(int n) &#123; n = ceil(1.0 * n / 25); if(n &gt;= 500) return 1; vector&lt;vector&lt;float&gt;&gt; dp(n+1, vector&lt;float&gt;(n+1)); //dp[i][j] = 0.25 * (dp[i-4][j] + dp[i-3][j-1] + dp[i-2][j-2] + dp[i-1][j-3]) dp[0][0] = 0.5; for(int i = 1; i &lt;= n; i++)&#123; dp[0][i] = 1; dp[i][0] = 0; &#125; for(int i = 1; i &lt;=n ;i++)&#123; for(int j = 1; j &lt;= i; j++)&#123; dp[i][j] = 0.25 * (dp[max(0, i - 4)][j] + dp[max(0, i - 3)][j-1] + dp[max(0, i - 2)][max(0, j-2)] + dp[i-1][max(0, j-3)]); dp[j][i] = 0.25 * (dp[max(0, j - 4)][i] + dp[max(0, j - 3)][i-1] + dp[max(0, j - 2)][max(0, i-2)] + dp[j-1][max(0, i-3)]); &#125; &#125; return dp[n][n]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"798. Smallest Rotation with Highest Score","slug":"798. Smallest Rotation with Highest Score","date":"2021-09-08T12:34:08.824Z","updated":"2021-09-15T16:16:47.702Z","comments":true,"path":"2021/09/08/798. Smallest Rotation with Highest Score/","link":"","permalink":"https://zjuytw.github.io/2021/09/08/798.%20Smallest%20Rotation%20with%20Highest%20Score/","excerpt":"","text":"798. Smallest Rotation with Highest Score Description Solution Let’s first check how many times we need take to move ith element to nums[i] position where is the first index that gets point. Take nums = [2,3,1,4, 0] as example: 12345A[0] = 2 move to 2&#x27;s index, k = 3 = (0 - A[0] + 5) % 5 A[1] = 3 move to 3&#x27;s index, k = 3 = (1 - A[1] + 5) % 5A[2] = 1 move to 1&#x27;s index, k = 1 = (2 - A[2] + 5) % 5A[3] = 4 move to 4&#x27;s index, k = 4 = (3 - A[3] + 5) % 5A[4] = 0 move to 0&#x27;s index, k = 4 = (4 - A[4] + 5) % 5 For one element, after move k times, it have reached to the point that one more step move will make it lose point. So we define a array to store the index that all element firstly lose point. And we could find that when K = k, A[i] is happened to lost point, then k = k+1, A[i] still can’t get point, but the first element on the head of the array rotate back to the tail will get new point. So we have the recurrence relation: 1dp[k+1] += dp[k] - 1 (Note we are counting the numer of losing point&#x27;s element) Code 12345678910111213141516class Solution &#123;public: int bestRotation(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; dp(n); int res = 0; for(int i = 0; i &lt; n; i++)&#123; dp[(i - nums[i] + 1 + n) % n] += 1; &#125; for(int i = 1; i &lt; n; i++)&#123; dp[i] += dp[i-1] - 1; res = dp[res] &gt; dp[i] ? i : res; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"502. IPO","slug":"502. IPO","date":"2021-09-08T12:34:08.822Z","updated":"2021-09-08T12:31:56.855Z","comments":true,"path":"2021/09/08/502. IPO/","link":"","permalink":"https://zjuytw.github.io/2021/09/08/502.%20IPO/","excerpt":"","text":"502. IPO Description Solution Fix capital then find maximal profit by priority_queue Code 1234567891011121314151617181920212223242526class Solution &#123; static bool cmp(pair&lt;int,int&gt;a, pair&lt;int,int&gt;b)&#123; return a.second &lt; b.second; &#125;public: int findMaximizedCapital(int k, int w, vector&lt;int&gt;&amp; profits, vector&lt;int&gt;&amp; capital) &#123; //find the maximal profit under current capital priority_queue&lt;int, vector&lt;int&gt;, less&lt;&gt;&gt; pq; vector&lt;pair&lt;int,int&gt;&gt; projs; for(int i = 0; i &lt; profits.size(); i++) projs.push_back(&#123;profits[i], capital[i]&#125;); sort(projs.begin(), projs.end(), cmp); int start = 0, i; while(k--)&#123; for(i = start; i &lt; projs.size() &amp;&amp; projs[i].second &lt;= w; i++) pq.push(projs[i].first); start = i; if(pq.empty())&#123; return w; &#125; w += pq.top(); pq.pop(); &#125; return w; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Priority Queue","slug":"Priority-Queue","permalink":"https://zjuytw.github.io/tags/Priority-Queue/"},{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"}]},{"title":"678. Valid Parenthesis String","slug":"678. Valid Parenthesis String","date":"2021-09-08T12:34:08.797Z","updated":"2021-09-08T08:04:23.715Z","comments":true,"path":"2021/09/08/678. Valid Parenthesis String/","link":"","permalink":"https://zjuytw.github.io/2021/09/08/678.%20Valid%20Parenthesis%20String/","excerpt":"","text":"678. Valid Parenthesis String Description Solution Using a list to store the availiable number of * scaned forward. If we meet a ‘)’ and there is no ‘(‘ in the stack, then we gonna use * to match. As for mismatched ‘(‘, we should use * following to match it. Code 1234567891011121314151617181920212223242526272829class Solution &#123;public: bool checkValidString(string s) &#123; stack&lt;int&gt; stk; vector&lt;int&gt; count(s.size()+1, 0); for(int i = 0; i &lt; s.size(); i++)&#123; count[i+1] = count[i]; if(s[i] == &#x27;(&#x27;) stk.push(i); else if(s[i] == &#x27;*&#x27;) count[i+1]+=1; else&#123; if(stk.empty() &amp;&amp; !count[i+1]) return false; if(!stk.empty()) stk.pop(); else count[i+1]-=1; &#125; &#125; while(!stk.empty())&#123; auto top = stk.top(); stk.pop(); if(count[s.size()] - count[top + 1] &lt;= 0) return false; count[s.size()]--; &#125; return true; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Stack","slug":"Stack","permalink":"https://zjuytw.github.io/tags/Stack/"}]},{"title":"1681. Minimum incompatibility","slug":"1681. Minimum Incompatibility","date":"2021-09-04T05:44:13.953Z","updated":"2021-09-04T05:42:29.746Z","comments":true,"path":"2021/09/04/1681. Minimum Incompatibility/","link":"","permalink":"https://zjuytw.github.io/2021/09/04/1681.%20Minimum%20Incompatibility/","excerpt":"","text":"1681. Minimum incompatibility Description Solution We firstly compute the cost[i] , which i should be the mask of the elements in one set. Then we compute dp[mask] , and the recurrence relation is : 1dp[mask] = min(dp[mask ^ subset] + cost[subset]) Code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public: int minimumIncompatibility(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); if(n % k) return -1; if(n == k) return 0; vector&lt;int&gt; cost((1 &lt;&lt; n)); vector&lt;int&gt; freq(n+1); for(int i = 0; i &lt; 1 &lt;&lt; n; i++)&#123; if(__builtin_popcount(i) != n /k) continue; fill(freq.begin(), freq.end(), 0); int flag = 1; for(int j = 0; j &lt; n; j++)&#123; if(i &amp; (1&lt;&lt;j))&#123; freq[nums[j]]++; if(freq[nums[j]] &gt; 1)&#123; flag = 0; break; &#125; &#125; &#125; if(flag)&#123; int l = 1, r = n; while(!freq[l]) l++; while(!freq[r]) r--; cost[i] = r-l; &#125; &#125; vector&lt;int&gt; dp((1 &lt;&lt; n), 1E6); dp[0] = 0; for(int mask = 0; mask &lt; 1 &lt;&lt; n; mask++)&#123; if(__builtin_popcount(mask) %(n/k)) continue; //enum subset for(int subset = mask; subset &gt; 0; subset = (subset-1)&amp;mask)&#123; if(__builtin_popcount(subset) != n/k) continue; if(cost[subset])&#123; dp[mask] = min(dp[mask], dp[mask^subset] + cost[subset]); &#125; &#125; &#125; return dp[(1 &lt;&lt; n)-1] == 1E6 ? -1 : dp[(1 &lt;&lt; n) -1]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"}]},{"title":"链表中倒数第k个节点","slug":"剑指 Offer 22. 链表中倒数第k个节点","date":"2021-09-04T05:44:13.951Z","updated":"2021-09-04T05:43:20.314Z","comments":true,"path":"2021/09/04/剑指 Offer 22. 链表中倒数第k个节点/","link":"","permalink":"https://zjuytw.github.io/2021/09/04/%E5%89%91%E6%8C%87%20Offer%2022.%20%E9%93%BE%E8%A1%A8%E4%B8%AD%E5%80%92%E6%95%B0%E7%AC%ACk%E4%B8%AA%E8%8A%82%E7%82%B9/","excerpt":"","text":"链表中倒数第k个节点 Description Solution Using fast-slow pointers, let fast pointer firstly walk k step then slow and fast walk togerther. Code 123456789101112131415161718192021/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* getKthFromEnd(ListNode* head, int k) &#123; ListNode *fast = head, *slow = head; for(int i = 0; i &lt; k; i++) fast = fast-&gt;next; while(fast != nullptr)&#123; fast = fast-&gt;next; slow = slow-&gt;next; &#125; return slow; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Two Pointers","slug":"Two-Pointers","permalink":"https://zjuytw.github.io/tags/Two-Pointers/"}]},{"title":"629. K Inverse Pairs Array","slug":"629. K Inverse Pairs Array","date":"2021-09-04T05:44:13.945Z","updated":"2021-09-04T05:43:59.507Z","comments":true,"path":"2021/09/04/629. K Inverse Pairs Array/","link":"","permalink":"https://zjuytw.github.io/2021/09/04/629.%20K%20Inverse%20Pairs%20Array/","excerpt":"","text":"629. K Inverse Pairs Array Description Solution The tricky point is how to get the recurrence relation. We could ituitively give dp[i][j] as for i length array, the number of k’s inverse pairs. Then let’s figure out the recurrence relation Assume we already have dp[n][k], then we add one item afterwards. We have 12[1 2 3 4 5] 6↑ ↑ ↑ ↑ ↑ ↑ We can insert 6 into 6 slot to get more 5,4,3,2,1,0 more inverse pairs. so dp[n][k] = dp[n-1][k] + dp[n-1][k-1] + ... + dp[n-1][k - (n-1)] Then we could use dp[n][k-1] = dp[n-1]][k-1] + dp[n-1][k-2] + ... + dp[n-1][k-1 - (n-1)] to replace some terms in previous formula. dp[n][k] = dp[n-1][k] + dp[n][k-1] - dp[n-1][k-n] Code 12345678910111213141516171819202122class Solution &#123; const int MOD = 1E9 + 7;public: int kInversePairs(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; dp(n+1, vector&lt;int&gt;(k+1)); //dp[n][k] = dp[n-1][k] + dp[n-1][k-1] + dp[n-1][k-2] ... + dp[n-1][k-(n-1)] //dp[n][k-1] = dp[n-1][k-1] + dp[n-1][k-2] + ... + dp[n-1][k-1 - (n-1)] //dp[n][k] = dp[n][k-1] + dp[n-1][k] - dp[n-1][k-n] dp[1][0] = 1; for(int i = 2; i &lt;= n; i++)&#123; for(int j = 0; j &lt;= k &amp;&amp; j &lt;= (i-1)*i/2; j++)&#123; if(j == 0)&#123; dp[i][j] = 1; continue; &#125; int val = (dp[i-1][j] - (j &gt;= i ? dp[i-1][j-i] : 0) + MOD) % MOD; dp[i][j] = (dp[i][j-1] + val) % MOD; &#125; &#125; return dp[n][k]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"1987. Number of Unique Good Subsequences","slug":"1987. Number of Unique Good Subsequences","date":"2021-08-30T17:30:23.110Z","updated":"2021-08-30T17:30:13.320Z","comments":true,"path":"2021/08/31/1987. Number of Unique Good Subsequences/","link":"","permalink":"https://zjuytw.github.io/2021/08/31/1987.%20Number%20of%20Unique%20Good%20Subsequences/","excerpt":"","text":"1987. Number of Unique Good Subsequences Description Solution Refer to Distinct Subsequences We calculate the different subsequence end with ith index. 12345678dp0[i] -&gt; stands for from begin to ith index, subsequence number end with 0dp1[i] -&gt; stands for from begin to ith index, subsequence number end with 1dp1[i] = dp1[i-1] + dp0[i-1] + 1 (for ith is 1)dp1[i] = dp1[i-1] (for ith is 0)dp0[i] = dp1[i-1] + dp0[i-1] (for ith is 0)dp0[i] = dp0[i-1] (for ith is 1) Code 12345678910111213141516171819202122class Solution &#123; const int MOD = 1E9 + 7;public: int numberOfUniqueGoodSubsequences(string binary) &#123; int n = binary.size(); vector&lt;int&gt; dp1(n), dp2(n); dp1[0] = binary[0]-&#x27;0&#x27;; bool flag= binary[0] == &#x27;0&#x27;; for(int i = 1; i &lt; n; i++)&#123; if(binary[i] == &#x27;1&#x27;)&#123; dp1[i] = (dp1[i-1] + dp2[i-1] + 1)%MOD; dp2[i] = dp2[i-1]; &#125;else&#123; dp1[i] = dp1[i-1]; dp2[i] = (dp2[i-1] + dp1[i-1])%MOD; flag= true; &#125; //cout &lt;&lt; dp1[i] &lt;&lt; &quot; &quot;&lt;&lt;dp2[i] &lt;&lt;endl; &#125; return (dp1[n-1]+dp2[n-1] + flag)%MOD; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"1986. Minimum Number of Work Sessions to Finish the Tasks","slug":"1986. Minimum Number of Work Sessions to Finish the Tasks","date":"2021-08-30T17:30:23.090Z","updated":"2021-08-30T17:22:57.665Z","comments":true,"path":"2021/08/31/1986. Minimum Number of Work Sessions to Finish the Tasks/","link":"","permalink":"https://zjuytw.github.io/2021/08/31/1986.%20Minimum%20Number%20of%20Work%20Sessions%20to%20Finish%20the%20Tasks/","excerpt":"","text":"1986. Minimum Number of Work Sessions to Finish the Tasks Description Solution State Compress + DP 12firstly compute cost[mask].dp[mask] = min(dp[subset] + cost[mask ^ subset] &lt;= TimeSession ? 1 : 0) Code 12345678910111213141516171819202122class Solution &#123;public: int minSessions(vector&lt;int&gt;&amp; tasks, int sessionTime) &#123; int n = tasks.size(); vector&lt;int&gt; dp(1 &lt;&lt; n, 15); vector&lt;int&gt; cost(1 &lt;&lt; n); for(int i = 0; i &lt; n; i++)&#123; for(int mask = 0; mask &lt; (1&lt;&lt;i); mask++)&#123; cost[mask|(1&lt;&lt;i)] = cost[mask] + tasks[i]; &#125; &#125; dp[0] = 0; //dp[mask] = min(dp[mask ^ i] + dp[i]) for(int mask = 0; mask &lt; (1 &lt;&lt; n); mask++)&#123; for(int i = mask; i &gt; 0; i = (i-1) &amp; mask)&#123; if(cost[i] &lt;= sessionTime) dp[mask] = min(dp[mask^i] + 1, dp[mask]); &#125; &#125; return dp[(1&lt;&lt;n)-1]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"}]},{"title":"295. Find Median from Data Stream","slug":"295. Find Median from Data Stream","date":"2021-08-27T15:43:53.678Z","updated":"2021-08-27T15:41:35.849Z","comments":true,"path":"2021/08/27/295. Find Median from Data Stream/","link":"","permalink":"https://zjuytw.github.io/2021/08/27/295.%20Find%20Median%20from%20Data%20Stream/","excerpt":"","text":"295. Find Median from Data Stream Description Solution Because we are handling a stream problem, if we need resort the array each time it is a costy solution. So if we could have a self-balance binary search tree, we could use the top of the tree as the answer, but just writing a AVL or RBT is not very troublesome. A better solution is to use two priority queue, one is min heap and other is max heap. Code 123456789101112131415161718192021222324252627282930class MedianFinder &#123;public: /** initialize your data structure here. */ priority_queue&lt;int,vector&lt;int&gt;, greater&lt;&gt;&gt; heapMin; priority_queue&lt;int,vector&lt;int&gt;, less&lt;&gt;&gt; heapMax; MedianFinder() &#123; &#125; void addNum(int num) &#123; if(heapMin.empty() || heapMin.top() &lt;= num)&#123; heapMin.push(num); if(heapMin.size() &gt; heapMax.size() + 1)&#123; heapMax.push(heapMin.top()); heapMin.pop(); &#125; &#125;else&#123; heapMax.push(num); if(heapMax.size() &gt;= heapMin.size() + 1)&#123; heapMin.push(heapMax.top()); heapMax.pop(); &#125; &#125; &#125; double findMedian() &#123; if(heapMax.size() == heapMin.size()) return 1.0 * (heapMax.top() + heapMin.top()) /2; return heapMin.top(); &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Priority Queue","slug":"Priority-Queue","permalink":"https://zjuytw.github.io/tags/Priority-Queue/"}]},{"title":"1000. Minimum Cost to Merge Stones","slug":"1000. Minimum Cost to Merge Stones","date":"2021-08-27T15:43:53.669Z","updated":"2021-08-27T15:42:41.226Z","comments":true,"path":"2021/08/27/1000. Minimum Cost to Merge Stones/","link":"","permalink":"https://zjuytw.github.io/2021/08/27/1000.%20Minimum%20Cost%20to%20Merge%20Stones/","excerpt":"","text":"1000. Minimum Cost to Merge Stones Description Solution Using DP to solve the problem, we have 1dp[i][j][k] = from ith to jth, the cost to form k&#x27;s piles So we have 1dp[i][j][k] = min(dp[i][p][1] + dp[p+1][j][k-1]) (p from i to j-1, step is k-1) Code 123456789101112131415161718192021222324252627282930class Solution &#123;public: int mergeStones(vector&lt;int&gt;&amp; stones, int k) &#123; if((stones.size()-1) % (k-1) != 0) return -1; int n = stones.size(); vector&lt;int&gt; prefix(n+1); vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(n+1,vector&lt;vector&lt;int&gt;&gt;(n+1, vector&lt;int&gt;(k+1, 9999999))); for(int i = 1; i &lt;= n; i ++)&#123; prefix[i] = prefix[i-1] + stones[i-1]; &#125; //initializing... for(int i = 1; i &lt;= n; i++)&#123; dp[i][i][1] = 0; &#125; //DP for(int len = 2; len &lt;= n; len++)&#123; for(int i = 1; i + len - 1 &lt;= n; i++)&#123; int j = i + len - 1; for(int m = 2; m &lt;= k; m++)&#123; for(int p = i; p &lt; j; p+=k-1)&#123; dp[i][j][m] = min(dp[i][j][m], dp[i][p][1] + dp[p+1][j][m-1]); &#125; &#125; dp[i][j][1] = dp[i][j][k] + prefix[j] - prefix[i-1]; &#125; &#125; return dp[1][n][1]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"881. Boats to Save People","slug":"881. Boats to Save People","date":"2021-08-27T15:43:53.666Z","updated":"2021-08-27T15:43:34.946Z","comments":true,"path":"2021/08/27/881. Boats to Save People/","link":"","permalink":"https://zjuytw.github.io/2021/08/27/881.%20Boats%20to%20Save%20People/","excerpt":"","text":"881. Boats to Save People Description Solution Greedy, because every boat is required to save most 2 people, so we could greedily let every boat loads 2 people. But a tricky point is, intuitively we should let each boat takes as heavier as possible, but actually, if we could putpeople[-1] with people[1] instead of people[-1] with people[0], we still could let people[-2] with people[1], so just let first and last together and we will get the correct answer. Code 123456789101112131415161718class Solution &#123;public: int numRescueBoats(vector&lt;int&gt; &amp;people, int limit) &#123; int ans = 0; sort(people.begin(), people.end()); int light = 0, heavy = people.size() - 1; while (light &lt;= heavy) &#123; if (people[light] + people[heavy] &gt; limit) &#123; --heavy; &#125; else &#123; ++light; --heavy; &#125; ++ans; &#125; return ans; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"}]},{"title":"479. Largest Palindrome Product","slug":"479. Largest Palindrome Product","date":"2021-08-25T06:04:07.642Z","updated":"2021-08-25T05:18:30.669Z","comments":true,"path":"2021/08/25/479. Largest Palindrome Product/","link":"","permalink":"https://zjuytw.github.io/2021/08/25/479.%20Largest%20Palindrome%20Product/","excerpt":"","text":"479. Largest Palindrome Product Description Solution Because two n-digits intergers’ product are range from 2n-1 digits to 2n digits. Our strategy is constructing palindrome by str + reverse(str) . Then we detect from highest n-digits interger to sqrt(palin) to see if it can be divided into 2 n digits numbers. Code 12345678910111213141516class Solution: def largestPalindrome(self, n: int) -&gt; int: def getPalin(i): s = str(i) s += s[::-1] return int(s) if n==1: return 9 low = pow(10,n-1) high = pow(10,n)-1 for i in range(high,low-1,-1): p = getPalin(i) for j in range(high, int(sqrt(p)), -1): if p % j == 0 and p / j &gt;= low: return p % 1337 return -1","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"787. Cheapest Flights Within K Stops","slug":"787. Cheapest Flights Within K Stops","date":"2021-08-25T06:04:07.640Z","updated":"2021-08-25T05:51:16.119Z","comments":true,"path":"2021/08/25/787. Cheapest Flights Within K Stops/","link":"","permalink":"https://zjuytw.github.io/2021/08/25/787.%20Cheapest%20Flights%20Within%20K%20Stops/","excerpt":"","text":"787. Cheapest Flights Within K Stops Description Solution BFS+cost[] array Ignore the vertex with more step &amp;&amp; more cost, just to prune Code 1234567891011121314151617181920212223class Solution: def findCheapestPrice(self, n: int, flights: List[List[int]], src: int, dst: int, k: int) -&gt; int: adjacent = defaultdict(list) cost = [sys.maxsize] * n queue = [src] cost[src] = 0 step = 0 for f in flights: adjacent[f[0]].append((f[1],f[2])) while len(queue) &gt; 0 and step &lt;= k: size = len(queue) tmp = cost.copy() for i in range(size): top = queue[0] queue.pop(0) for (v,e) in adjacent[top]: if(cost[top] + e &lt; tmp[v]): queue.append(v) tmp[v] = cost[top] + e for i in range(len(cost)): cost[i] = tmp[i] step += 1 return -1 if cost[dst] is sys.maxsize else cost[dst]","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"BFS","slug":"BFS","permalink":"https://zjuytw.github.io/tags/BFS/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"790. Domino and Tromino Tiling","slug":"790. Domino and Tromino Tiling","date":"2021-08-25T06:04:07.639Z","updated":"2021-08-25T06:03:51.012Z","comments":true,"path":"2021/08/25/790. Domino and Tromino Tiling/","link":"","permalink":"https://zjuytw.github.io/2021/08/25/790.%20Domino%20and%20Tromino%20Tiling/","excerpt":"","text":"790. Domino and Tromino Tiling Description Solution Check the dp state illustrated in picture Code 1234567891011121314151617class Solution &#123; static const int MOD = 1E9 + 7;public: int numTilings(int n) &#123; if(n == 1) return 1; vector&lt;vector&lt;long long&gt;&gt; dp(2, vector&lt;long long&gt;(1+n,0)); dp[0][1] = 1; dp[1][2] = 2; dp[0][2] = 2; for(int i = 3; i &lt;= n; i++)&#123; dp[0][i] = (dp[0][i-1] + dp[1][i-1] + dp[0][i-2])%MOD; dp[1][i] = (dp[0][i-2] * 2 + dp[1][i-1])%MOD; &#125; return dp[0][n] % MOD; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"5852. Minimize the Difference Between Target and Chosen Elements","slug":"5852. Minimize the Difference Between Target and Chosen Elements","date":"2021-08-22T15:36:07.532Z","updated":"2021-08-22T15:35:52.846Z","comments":true,"path":"2021/08/22/5852. Minimize the Difference Between Target and Chosen Elements/","link":"","permalink":"https://zjuytw.github.io/2021/08/22/5852.%20Minimize%20the%20Difference%20Between%20Target%20and%20Chosen%20Elements/","excerpt":"","text":"5852. Minimize the Difference Between Target and Chosen Elements Description Solution DFS + memorize visited + pruning Code 1234567891011121314151617181920212223242526272829303132class Solution &#123; vector&lt;vector&lt;int&gt;&gt; visited; int res = INT_MAX;public: int minimizeTheDifference(vector&lt;vector&lt;int&gt;&gt;&amp; mat, int target) &#123; int m = mat.size(), n = mat[0].size(); for(int i = 0; i &lt; m; i++) sort(mat[i].begin(), mat[i].end()); visited.resize(m, vector&lt;int&gt;(4901,0)); stack&lt;pair&lt;int, int&gt;&gt; stk; stk.push(&#123;0,0&#125;); while(!stk.empty())&#123; auto [level, sum] = stk.top(); stk.pop(); if(level == mat.size())&#123; res = min(res, abs(sum - target)); continue; &#125; for(int i = 0; i &lt; mat[0].size();i++)&#123; if(visited[level][sum + mat[level][i]]) continue; visited[level][sum + mat[level][i]] = 1; stk.push(&#123;level+1, sum + mat[level][i]&#125;); //important pruning situation if(sum + mat[level][i] &gt; target) break; &#125; &#125; return res; &#125; &#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Pruning","slug":"Pruning","permalink":"https://zjuytw.github.io/tags/Pruning/"}]},{"title":"5853. Find Array Given Subset Sums","slug":"5853. Find Array Given Subset Sums","date":"2021-08-22T15:36:07.515Z","updated":"2021-08-22T15:24:37.139Z","comments":true,"path":"2021/08/22/5853. Find Array Given Subset Sums/","link":"","permalink":"https://zjuytw.github.io/2021/08/22/5853.%20Find%20Array%20Given%20Subset%20Sums/","excerpt":"","text":"5853. Find Array Given Subset Sums Description Solution Firstly, let’s think about a easier question—If sums‘s elements are all positive, how would you solve this? Obviously, the minimum one m is the front one in the ans array. How to find the next answers? Delete all subset in sums from ans array, which should be $2^{ans.size()-1}$ elements to be deleted How to do this in programming? In each iteration, use a mask to mark the combination of ans‘s numbers, note that we just need to delete the combination of new found number and other’s Use multiset Then how to apply this to this problem? We can add up a positive number to convert the array into with all positive one. Especially, we add the number of -(sum of all negative number) . Then we apply the algorithm described above into new one, then we could get a temp ans array. How to convert the ans into what we want? We notice that after round up, sums array always starts with 0, then the next value is the largest negative value (Because the next value should be like (a + b + c - a- b- c -d), d is exactly the largest negative value) So in the ans array, if we could find a serial of numbers which sum up to m, which means we could negate them them to make whole array sum up to 0. Then we negate them. Code 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: vector&lt;int&gt; recoverArray(int n, vector&lt;int&gt;&amp; sums) &#123; sort(sums.begin(), sums.end()); int front = -sums[0]; multiset&lt;int&gt; st; for(auto sum : sums)&#123; st.insert(sum + front); &#125; st.erase(st.begin()); vector&lt;int&gt; ans; ans.push_back(*st.begin()); for(int i = 1; i &lt; n; i++)&#123; for(int mask = 1; mask &lt; (1&lt;&lt;i); mask++)&#123; if((mask &gt;&gt; (i-1)) &amp; 1)&#123; int sm = 0; for(int j = 0; j &lt; ans.size(); j++) if(mask &gt;&gt; j &amp; 1) sm += ans[j]; st.erase(st.find(sm)); &#125; &#125; ans.push_back(*st.begin()); &#125; for (int i = 0; i &lt; (1 &lt;&lt; n); i++) &#123; int sm = 0; for (int j = 0; j &lt; n; j++) if (i &gt;&gt; j &amp; 1) sm += ans[j]; if (sm == front) &#123; for (int j = 0; j &lt; n; j++) if (i &gt;&gt; j &amp; 1) ans[j] = -ans[j]; break; &#125; &#125; return ans; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Math","slug":"Math","permalink":"https://zjuytw.github.io/tags/Math/"}]},{"title":"212. Word Search II","slug":"212. Word Search II","date":"2021-08-21T17:02:24.607Z","updated":"2021-08-21T15:03:03.983Z","comments":true,"path":"2021/08/22/212. Word Search II/","link":"","permalink":"https://zjuytw.github.io/2021/08/22/212.%20Word%20Search%20II/","excerpt":"","text":"212. Word Search II Description Solution A classic usage of Trie Tree(prefix tree). Template: 123456789class Trie&#123; Trie *next[26]; bool isEnd; Trie()&#123; for(int i = 0; i&lt; 26; i++) next[i] = nullptr; isEnd = false; &#125;&#125;; Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Trie&#123;public: Trie* next[26]; bool isEnd; Trie()&#123; for(int i = 0; i &lt; 26; i++) next[i] = nullptr; isEnd = false; &#125;&#125;;class Solution &#123; vector&lt;string&gt; res; vector&lt;int&gt; dir = &#123;-1, 0, 1, 0, -1&#125;;public: vector&lt;string&gt; findWords(vector&lt;vector&lt;char&gt;&gt;&amp; board, vector&lt;string&gt;&amp; words) &#123; Trie *root = new Trie(); for(auto word: words)&#123; buildTree(root, word); &#125; for(int i = 0; i &lt; board.size(); i++)&#123; for(int j = 0; j &lt; board[0].size();j++)&#123; string cur = &quot;&quot;; dfs(board,i,j,root, cur); &#125; &#125; return res; &#125; void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; board, int r, int c, Trie* root, string&amp; curStr)&#123; if(!root-&gt;next[board[r][c]-&#x27;a&#x27;]) return; Trie *cur = root-&gt;next[board[r][c]-&#x27;a&#x27;]; curStr += board[r][c]; board[r][c] = &#x27;#&#x27;; if(cur-&gt;isEnd)&#123; res.push_back(curStr); cur-&gt;isEnd = false; &#125; for(int i = 0; i &lt; 4; i++)&#123; int x = r + dir[i], y = c + dir[i+1]; if(x &lt; 0 || x &gt;= board.size() || y &lt; 0 || y &gt;= board[0].size() || board[x][y] == &#x27;#&#x27;) continue; dfs(board,x,y,cur,curStr); &#125; board[r][c] = curStr.back(); curStr.pop_back(); &#125; void buildTree(Trie *root, string word)&#123; Trie *cur = root; for(int i = 0; i &lt; word.size(); i++)&#123; char c = word[i]; if(!cur-&gt;next[c-&#x27;a&#x27;])&#123; cur-&gt;next[c-&#x27;a&#x27;] = new Trie(); &#125; cur = cur-&gt;next[c-&#x27;a&#x27;]; if(i == word.size()-1) cur-&gt;isEnd = true; &#125; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Trie Tree","slug":"Trie-Tree","permalink":"https://zjuytw.github.io/tags/Trie-Tree/"}]},{"title":"650. 2 Keys Keyboard","slug":"650. 2 Keys Keyboard","date":"2021-08-21T17:02:24.581Z","updated":"2021-08-21T17:02:11.504Z","comments":true,"path":"2021/08/22/650. 2 Keys Keyboard/","link":"","permalink":"https://zjuytw.github.io/2021/08/22/650.%202%20Keys%20Keyboard/","excerpt":"","text":"650. 2 Keys Keyboard Description Solution O(n^2), search from 1 to i-1 to find the smallest operation number for dp[i] O(sqrt(n)), all the operations sequences are like : CPPPCPPPPCP..., can be divided into groups (CPPP)(CPP)(CP)…. .If we have each group’s length like g1, g2,g3..., so after first group, there are g1 A’s, after second group g1 * g2 A’s… We want have N = g1 * g2 * g3...*gn A’s, if gi can be divided into product of other two numbers, denote as gi = p * q, so it can be divided into 2 group, first contains 1C and p-1P, second one contains 1C and q-1P. It is easy to prove that after dividing, we need fewer steps. Code 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int minSteps(int n) &#123; if(n==1) return 0; int f = getFactors(n); if(f == 1) return n; vector&lt;int&gt; dp(f+1,INT_MAX); dp[1] = 0; int res = INT_MAX; for(int i = 2; i &lt;= f; i++)&#123; int sf = getFactors(i); for(int j = 1; j &lt;= sf; j++)&#123; if(i % j == 0)&#123; dp[i] = min(dp[i], dp[j] + i/j); &#125; &#125; if(n % i == 0)&#123; res = min(res, dp[i] + n/i); &#125; &#125; return res; &#125; int getFactors(int n)&#123; for(int i = n-1; i &gt;= 1; i--)&#123; if(n%i==0) return i; &#125; return 0; &#125;&#125;; 1234567891011class Solution(object): def minSteps(self, n): ans = 0 d = 2 while n &gt; 1: while n % d == 0: ans += d n /= d d += 1 return ans","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Math","slug":"Math","permalink":"https://zjuytw.github.io/tags/Math/"}]},{"title":"CS5234--Lecture1 Sampling Algorithm of Array","slug":"Lec1","date":"2021-08-20T14:07:30.229Z","updated":"2021-08-20T14:07:11.046Z","comments":true,"path":"2021/08/20/Lec1/","link":"","permalink":"https://zjuytw.github.io/2021/08/20/Lec1/","excerpt":"","text":"CS5234 --Algorithm at Scale Lec1 mainly talked about two toy problem solving by sampling. Array all 0's ? Given the algorithm, 1234Repeat s times: Choose random i in [1,n] if A[i] = 1 then return Falsereturn True We’d like to guarantee the following statement: if all 0’s : return true if $\\ge \\epsilon n$ 1’s : return false (We can promise that &gt;= 2/3 probability to return false and we can adjust the probability by adjusting the sampling times) otherwise: return true or false Proof: if there are more than $\\epsilon n$ 1’s, we can get $Pr(A[i]=1) \\ge \\epsilon$$$\\begin{aligned}Pr(all\\ samples\\ are\\ 0)&amp;\\le\\ (1-\\epsilon)^s\\&amp;\\le\\ (1-\\epsilon)^{2/\\epsilon}\\ (let\\ s\\ =\\ 2/\\epsilon)\\&amp;\\le\\ e^{-2}\\&amp;\\le\\ 1/3\\end{aligned}$$So this is the error rate, if we want correct rate, it’s &gt;= 2/3, as desired. A useful Lemma:$$e^{-x}\\ =\\ 1 -x + x^2/2-… \\ \\ \\ \\ \\ \\ \\ for(0&lt;x&lt;1)—————-(1)\\1/e^2\\le(1-1/x)^x\\le1/e\\ \\ \\ \\ \\ \\ \\ for(x&gt;2)—————–(2)$$ Follow up What if we want the algorithm to be correct with probability ≥ 1 – δ? Just let error rate inequality right hand be δ Fraction of 1's? Definition of $\\epsilon-close$, the answer of fraction within the $\\pm\\epsilon$ . And like above, we give the algorithm: 12345sum = 0Repeat s times: Choose random i in [1,n] sum = sum + A[i]Return sum/s Then, same with the former question, we want to give the guarantee that: if all 0’s : return 0 if $\\ge \\epsilon n$ 1’s : return the true fraction (We can promise that &gt;= 2/3 probability to return true fraction and we can adjust the probability by adjusting the sampling times) otherwise: return arbitrary fraction. To give a proof, we introduce Hoeffding Bound, it mainly describes a set of variables which satisfy independent, random variable, bounded, denoted as X_i$$Let\\ Z = X_1+X_2+X_3+…X_i\\Pr(|Z-Z[E]|\\ge\\delta)\\le2^{-\\delta^2/s}$$In the problem case, we have$$\\begin{aligned}Pr(|V-E[V]|\\ge\\epsilon)=&amp;Pr(|sV-sE[V]|\\ge\\epsilon s)\\&amp;(We\\ need\\ to\\ do\\ this\\ beacuse\\ nV\\ is\\ the\\ sum\\ of\\ sampling\\ values)\\&amp;\\le Pr(|sum - sf|\\ge \\epsilon s)\\&amp;\\le 2e^{-(\\epsilon s)^2/s}=2e^{-\\epsilon^2 s}\\ (let\\ s=\\ 1/\\epsilon^2)\\&amp;\\le1/3\\end{aligned}$$","categories":[{"name":"Algorithm at Scale","slug":"Algorithm-at-Scale","permalink":"https://zjuytw.github.io/categories/Algorithm-at-Scale/"}],"tags":[{"name":"Sampling Algorithm","slug":"Sampling-Algorithm","permalink":"https://zjuytw.github.io/tags/Sampling-Algorithm/"}]},{"title":"481. Magical String","slug":"481. Magical String","date":"2021-08-20T14:05:20.659Z","updated":"2021-08-20T14:04:37.179Z","comments":true,"path":"2021/08/20/481. Magical String/","link":"","permalink":"https://zjuytw.github.io/2021/08/20/481.%20Magical%20String/","excerpt":"","text":"481. Magical String Description Solution Use a pointer to record current occurrence of next segment of s. The new added segment’s consecutive number should be different from back of s. Code 1234567891011121314151617181920class Solution: def magicalString(self, n: int) -&gt; int: if n &lt;= 3: return 1 s = &quot;122&quot; freq,size,res = 2, 3, 1 #freq postion pointer while size &lt; n: f = int(s[freq]) c = 1 if s[len(s)-1] is &quot;2&quot; else 2 s += str(c) * f if size + f &gt;= n: if c == 1: res += n - size else: if c == 1: res += f size += f freq += 1 return res","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"String","slug":"String","permalink":"https://zjuytw.github.io/tags/String/"}]},{"title":"553. Optimal Division","slug":"553. Optimal Division","date":"2021-08-20T14:05:20.643Z","updated":"2021-08-20T13:58:11.286Z","comments":true,"path":"2021/08/20/553. Optimal Division/","link":"","permalink":"https://zjuytw.github.io/2021/08/20/553.%20Optimal%20Division/","excerpt":"","text":"553. Optimal Division Description Solution To get the maxium value in the nums, we can fix the numerator and get minium denominator in the lefted numbers. So just let each number divided by later to generate a minium denominator. Code 1234567891011121314151617class Solution: def optimalDivision(self, nums: List[int]) -&gt; str: res = &quot;&quot; if len(nums) == 1: res = str(nums[0]) return res elif len(nums) == 2: res = str(nums[0]) + &quot;/&quot; + str(nums[1]) return res for i in range(len(nums)): if i == 0: res += str(nums[i]) + &quot;/(&quot; continue res += str(nums[i]) + &quot;/&quot; res = res[:-1] res += &quot;)&quot; return res","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"992. Subarrays with K Different Integers","slug":"992. Subarrays with K Different Integers","date":"2021-08-19T14:54:31.948Z","updated":"2021-08-19T14:54:17.309Z","comments":true,"path":"2021/08/19/992. Subarrays with K Different Integers/","link":"","permalink":"https://zjuytw.github.io/2021/08/19/992.%20Subarrays%20with%20K%20Different%20Integers/","excerpt":"","text":"992. Subarrays with K Different Integers Description Solution Quite tricky solution using two pointers, that we can fix the right pointer then move the left pointer to check the subarrays with less equals k elements. Then we can get subarray number by number of array with less equals k+1 elemens - number of array with less equals k+1 elemens. Code 1234567891011121314151617181920212223242526class Solution &#123;public: int subarraysWithKDistinct(vector&lt;int&gt;&amp; nums, int k) &#123; return getLEK(nums, k) - getLEK(nums,k-1); &#125; int getLEK(vector&lt;int&gt;&amp; nums, int k)&#123; unordered_map&lt;int,int&gt; bucket; int cnt = 0, l = 0, res = 0; for(int i = 0; i &lt; nums.size(); i++)&#123; if(++bucket[nums[i]] == 1) cnt++; if(cnt &lt;= k) ; // bucket.size() &gt; k else&#123; while(cnt &gt; k)&#123; if(--bucket[nums[l++]] == 0) cnt--; &#125; &#125; res += i - l; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Two Pointers","slug":"Two-Pointers","permalink":"https://zjuytw.github.io/tags/Two-Pointers/"}]},{"title":"959. Regions Cut By Slashes","slug":"959. Regions Cut By Slashes","date":"2021-08-19T14:54:31.946Z","updated":"2021-08-19T14:53:48.004Z","comments":true,"path":"2021/08/19/959. Regions Cut By Slashes/","link":"","permalink":"https://zjuytw.github.io/2021/08/19/959.%20Regions%20Cut%20By%20Slashes/","excerpt":"","text":"959. Regions Cut By Slashes Description Solution Two solutions both work: DFS, like find connected components in a island-sea question, but we need to deal with the slashes because we can not DFS a half-block. So we can zoom up the grid into 3 * 3 array then map the slash into it. Use union-find to union the plots and edges. First, each plot are in its own set, four edges are in one set We note that once slash connect two points from the same set, we can get 1 new region. Once points are from different set, we just union them. Code 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; vector&lt;int&gt; dir = &#123;-1, 0 , 1, 0 , -1&#125;;public: int regionsBySlashes(vector&lt;string&gt;&amp; grid) &#123; int n = grid.size(); vector&lt;vector&lt;int&gt;&gt; ngrid(3*n, vector&lt;int&gt;(3*n)); for(int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt; grid.size(); j++)&#123; if(grid[i][j] == &#x27;/&#x27;)&#123; ngrid[3 * i][3 * j + 2] = 1; ngrid[3 * i + 1][3 * j + 1] = 1; ngrid[3 * i + 2][3 * j ] = 1; &#125;else if(grid[i][j] == &#x27;\\\\&#x27;)&#123; ngrid[3 * i][3 * j] = 1; ngrid[3 * i + 1][3 * j + 1] = 1; ngrid[3 * i + 2][3 * j + 2] = 1; &#125; &#125; &#125; int res = 0; for(int i = 0; i &lt; ngrid.size(); i++)&#123; for(int j = 0; j &lt; ngrid.size(); j++)&#123; if(!ngrid[i][j])&#123; dfs(ngrid,i,j); res++; &#125; &#125; &#125; return res; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int r, int c)&#123; if(grid[r][c]) return; grid[r][c] = 1; for(int i = 0; i &lt; 4;i++)&#123; int x = dir[i] + r, y = dir[i+1] + c; if(x &lt; 0 || x &gt;= grid.size() || y &lt; 0 || y &gt;= grid.size() || grid[x][y]) continue; dfs(grid,x,y); &#125; &#125;&#125;; 12345678910111213141516171819202122232425262728293031323334class Solution: father = list() def regionsBySlashes(self, grid: List[str]) -&gt; int: size = len(grid) father = &#123;(i,j) : (i,j) for j in range(size+1) for i in range(size+1)&#125; for i in range(size+1): father[i,0], father[0,i], father[size,i], father[i,size] = (0,0), (0,0), (0,0), (0,0) def find(c): while father[c] != c: c = father[c] return c def union(a,b): father[a] = find(b) res = 1 for i in range(size): for j in range(size): if grid[i][j] == &#x27; &#x27;: continue t1, t2 = list(), list() if grid[i][j] == &#x27;/&#x27;: t1 = find((i+1, j)) t2 = find((i, j + 1)) elif grid[i][j] == &#x27;\\\\&#x27;: t1 = find((i, j)) t2 = find((i+1, j + 1)) if t1 == t2: res += 1 else: union(t1,t2) return res","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Union Find Set","slug":"Union-Find-Set","permalink":"https://zjuytw.github.io/tags/Union-Find-Set/"}]},{"title":"552. Student Attendance Record II","slug":"552. Student Attendance Record II","date":"2021-08-18T14:26:28.863Z","updated":"2021-08-18T14:20:13.571Z","comments":true,"path":"2021/08/18/552. Student Attendance Record II/","link":"","permalink":"https://zjuytw.github.io/2021/08/18/552.%20Student%20Attendance%20Record%20II/","excerpt":"","text":"552. Student Attendance Record II Description Solution A typical finite-state machine problem + dp. Just draw a state transfer graph. Code 1234567891011121314151617181920212223242526272829class Solution &#123; static const int MOD = 1E9 + 7;public: int checkRecord(int n) &#123; long long p1, p2, l11, l21, l12, l22, a; p1 = l11 = a = 1; p2 = l12 = l21 = l22 = 0; for(int i = 1; i &lt;n; i++)&#123; long long np1, np2, nl11, nl21, nl12, nl22, na; np1 = p1 + l11 + l21; nl11 = p1; nl21 = l11; na = p1 + l11 + l21; np2 = a + p2 + l12 + l22; nl12 = a + p2; nl22 = l12; p1 = np1%MOD; p2 = np2%MOD; l11 = nl11 %MOD; l12 = nl12 %MOD; l22 = nl22%MOD; l21 = nl21%MOD; a = na%MOD; &#125; int res = 0; res = (p1 + p2 + l11 + l21 + l12 + l22 + a)%MOD; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Finite State Machine","slug":"Finite-State-Machine","permalink":"https://zjuytw.github.io/tags/Finite-State-Machine/"}]},{"title":"501. Find Mode in Binary Search Tree","slug":"501. Find Mode in Binary Search Tree","date":"2021-08-18T14:26:28.861Z","updated":"2021-08-18T14:25:55.245Z","comments":true,"path":"2021/08/18/501. Find Mode in Binary Search Tree/","link":"","permalink":"https://zjuytw.github.io/2021/08/18/501.%20Find%20Mode%20in%20Binary%20Search%20Tree/","excerpt":"","text":"501. Find Mode in Binary Search Tree Description Solution Imagine how we find mode in an array [1 2 2 4 5 6 6 7], we just scan over then use some variables recording the most frequent number. In this BST, we can use inorder-traversal to get this sorted array. Code 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int maxfreq, prev, curfreq; vector&lt;int&gt; res; vector&lt;int&gt; findMode(TreeNode* root) &#123; dfs(root); return res; &#125; void dfs(TreeNode* root)&#123; if(root == nullptr) return; dfs(root-&gt;left); if(maxfreq == 0)&#123; prev = root-&gt;val; curfreq += 1; &#125;else&#123; if(prev == root-&gt;val)&#123; curfreq+=1; &#125;else&#123; curfreq = 1; prev = root-&gt;val; &#125; &#125; if(curfreq &gt; maxfreq)&#123; while(res.size()&gt;0) res.pop_back(); res.push_back(root-&gt;val); maxfreq = curfreq; &#125;else if(curfreq == maxfreq)&#123; res.push_back(root-&gt;val); &#125; dfs(root-&gt;right); &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"BST","slug":"BST","permalink":"https://zjuytw.github.io/tags/BST/"}]},{"title":"1012. Numbers With Repeated Digits","slug":"1012. Numbers With Repeated Digits","date":"2021-08-18T14:26:28.832Z","updated":"2021-08-18T14:20:44.243Z","comments":true,"path":"2021/08/18/1012. Numbers With Repeated Digits/","link":"","permalink":"https://zjuytw.github.io/2021/08/18/1012.%20Numbers%20With%20Repeated%20Digits/","excerpt":"","text":"1012. Numbers With Repeated Digits Description Solution The most important tricky point, just find integers have no repeated digit!!! Then use DFS to solve the problem A naive way is to find the permutation -&gt; TLE To speed up, we can directly compute permutation that has less digits than n‘s, then use DFS to compute the combination whose digit equals to n Code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Solution &#123;public: int res = 0; int numDupDigitsAtMostN(int n) &#123; int tmp = n; int digit = 0; vector&lt;int&gt; num; while(tmp)&#123; digit ++; num.push_back(tmp%10); tmp /= 10; &#125; reverse(num.begin(), num.end()); for(int i = 1; i &lt;= digit-1; i++)&#123; if(i == 1) res += 9; else res += 9 * Amn(i-1,9); &#125; vector&lt;int&gt; visited(10,0); dfs(n, visited, 0, num); return n - res; &#125; void dfs(int n, vector&lt;int&gt;&amp; visited, int curPos, vector&lt;int&gt;&amp; num)&#123; if(num.size() == curPos)&#123; res++; return; &#125; for(int i = 0; i &lt; 10; i++)&#123; if(curPos == 0 &amp;&amp; i == 0) continue; if(i &lt; num[curPos])&#123; if(visited[i]) continue; res += Amn(num.size() - curPos - 1, 9 - curPos); &#125;else if(i == num[curPos])&#123; if(visited[i]) return; visited[i] = 1; dfs(n, visited, curPos+1, num); visited[i] = 0; &#125;else break; &#125; &#125; int Amn(int m, int n)&#123; int res = 1; for(int i = 0; i &lt; m; i++) res *= n - i; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"526. Beautiful Arrangement","slug":"526. Beautiful Arrangement","date":"2021-08-16T15:42:31.275Z","updated":"2021-08-16T14:25:54.194Z","comments":true,"path":"2021/08/16/526. Beautiful Arrangement/","link":"","permalink":"https://zjuytw.github.io/2021/08/16/526.%20Beautiful%20Arrangement/","excerpt":"","text":"526. Beautiful Arrangement Description Solution Naively do backtracking DP + State Compression use mask to record first num ‘s integer’s combinations, for example 0101 means 1 and 3 are in the first 2 slots of the array. 1dp[mask] = sum of dp[mask^i], which i is suitable for popcount(mask) slot Code 12345678910111213141516171819202122232425262728class Solution &#123;public: int countArrangement(int n) &#123; vector&lt;unordered_set&lt;int&gt;&gt; suitable(n+1); for(int i = 1; i &lt;= n;i ++)&#123; for(int j = 1; j &lt;= n; j++)&#123; if(i % j == 0 || j % i == 0) suitable[i].insert(j); &#125; &#125; unordered_set&lt;int&gt; visited; return backtracking(n,1,visited, suitable); &#125; int backtracking(int n, int curPos, unordered_set&lt;int&gt;&amp; visited, const vector&lt;unordered_set&lt;int&gt;&gt;&amp; suitable)&#123; if(curPos == n+1) return 1; int res = 0; for(int i = 1; i &lt;= n; i++)&#123; if(visited.count(i) || suitable[curPos].count(i) == 0) continue; visited.insert(i); res += backtracking(n, curPos+1, visited, suitable); visited.erase(i); &#125; return res; &#125;&#125;; Solution2 12345678910111213141516class Solution &#123;public: int countArrangement(int n) &#123; vector&lt;int&gt; dp(1 &lt;&lt; n); dp[0] = 1; for(int mask = 0; mask &lt; (1 &lt;&lt;n); mask++)&#123; int num = __builtin_popcount(mask); for(int i = 0; i &lt; n; i++)&#123; if((mask &amp; (1&lt;&lt;i)) &amp;&amp; (num % (i+1) == 0 || (i+1) % num == 0))&#123; dp[mask] += dp[mask^(1&lt;&lt;i)]; &#125; &#125; &#125; return dp[(1&lt;&lt;n) - 1]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Back Tracking","slug":"Back-Tracking","permalink":"https://zjuytw.github.io/tags/Back-Tracking/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"}]},{"title":"282. Expression Add Operators","slug":"282. Expression Add Operators","date":"2021-08-16T15:42:31.273Z","updated":"2021-08-16T15:41:23.696Z","comments":true,"path":"2021/08/16/282. Expression Add Operators/","link":"","permalink":"https://zjuytw.github.io/2021/08/16/282.%20Expression%20Add%20Operators/","excerpt":"","text":"282. Expression Add Operators Description Solution Use tricky DFS to solve it. The most important trick: Because we need to give each expression that leads to the target, so we need to record current string. Then, for+ and -, in fact we just need to record the exep value in previous expression. But to treat * rightly, we need record one more variable – lastValue to calculate the expression rightly. So if we have, for example 1 2 3 4 5 6 7 8 11 + 2 * 3 DFS(45678) ​ ↑ To treat this 2 * 3 correctly, we need first record 1 + 2= 3, then use 3 - 2 + 2 * 3 to get the right answer. Code 1234567891011121314151617181920212223242526272829303132class Solution &#123; vector&lt;string&gt; res; typedef long long LL;public: vector&lt;string&gt; addOperators(string num, int target) &#123; dfs(num, (LL)target, &quot;&quot;, 0, 0, 0); return res; &#125; void dfs(string&amp; num, LL target, string prevStr, int curPos, LL curVal, LL lastVal)&#123; if(num.size() == curPos)&#123; if(curVal == target) res.push_back(prevStr); return; &#125; for(int i = curPos; i &lt; num.size(); i++)&#123; string curStr = num.substr(curPos, i - curPos+1); // cout &lt;&lt; curStr &lt;&lt;endl; LL val = stoll(curStr); if(curStr.size() &gt; 1 &amp;&amp; curStr[0] ==&#x27;0&#x27;) continue; if(curPos==0)&#123; dfs(num, target, curStr, i+1, val, val); &#125;else&#123; dfs(num, target, prevStr + &quot;+&quot; + curStr, i+1, curVal + val, val); dfs(num, target, prevStr + &quot;-&quot; + curStr, i+1, curVal - val, -val); dfs(num, target, prevStr + &quot;*&quot; + curStr, i+1, curVal - lastVal + lastVal * val, lastVal * val); &#125; &#125; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"576. Out of Boundary Paths","slug":"576. Out of Boundary Paths","date":"2021-08-15T17:46:55.651Z","updated":"2021-08-15T17:29:17.300Z","comments":true,"path":"2021/08/16/576. Out of Boundary Paths/","link":"","permalink":"https://zjuytw.github.io/2021/08/16/576.%20Out%20of%20Boundary%20Paths/","excerpt":"","text":"576. Out of Boundary Paths Description Solution DP for each stage. Code 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: static constexpr int MOD = 1&#x27;000&#x27;000&#x27;007; int findPaths(int m, int n, int maxMove, int startRow, int startColumn) &#123; vector&lt;vector&lt;int&gt;&gt; directions = &#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;; int outCounts = 0; vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(2, vector&lt;vector&lt;int&gt;&gt;(m, vector&lt;int&gt;(n, 0))); dp[0][startRow][startColumn] = 1; int curcol = 0; for(int i = 0; i &lt; maxMove; i++)&#123; for(int j = 0; j &lt; m; j++)&#123; for(int k = 0; k &lt; n; k++)&#123; int cur = dp[curcol][j][k]; if(!cur) continue; for(int z = 0; z &lt; 4; z++)&#123; int x = j + directions[z][0], y = k + directions[z][1]; if(x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n)&#123; outCounts = (outCounts + cur) % MOD; &#125;else&#123; dp[curcol^1][x][y] = (dp[curcol^1][x][y] + cur) %MOD; &#125; &#125; dp[curcol][j][k] = 0; &#125; &#125; curcol^=1; &#125; return outCounts; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"5832. Array With Elements Not Equal to Average of Neighbors","slug":"5832. Array With Elements Not Equal to Average of Neighbors","date":"2021-08-15T17:46:55.630Z","updated":"2021-08-15T17:46:25.708Z","comments":true,"path":"2021/08/16/5832. Array With Elements Not Equal to Average of Neighbors/","link":"","permalink":"https://zjuytw.github.io/2021/08/16/5832.%20Array%20With%20Elements%20Not%20Equal%20to%20Average%20of%20Neighbors/","excerpt":"","text":"5832. Array With Elements Not Equal to Average of Neighbors Description Solution To generate the array in the requirement, my strategy is pickthe smallest the largest the second smallest …, because we have the largest * 2 &gt; the sum of the smallest numbers, it should always work. Or we can keep looping the swap the mismatched pair till we get the correct array. Code 123456789101112131415class Solution &#123;public: vector&lt;int&gt; rearrangeArray(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(), nums.end()); int l = 0, r = nums.size()-1; vector&lt;int&gt; res; while(res.size() != nums.size())&#123; res.push_back(nums[l++]); if(l &lt; r) res.push_back(nums[r--]); &#125; return res; &#125; &#125;; Solution 2 123456789101112131415class Solution &#123;public: vector&lt;int&gt; rearrangeArray(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(), nums.end()); int l = 0, r = nums.size()-1; vector&lt;int&gt; res; while(res.size() != nums.size())&#123; res.push_back(nums[l++]); if(l &lt; r) res.push_back(nums[r--]); &#125; return res; &#125; &#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Two Pointers","slug":"Two-Pointers","permalink":"https://zjuytw.github.io/tags/Two-Pointers/"}]},{"title":"399. Evaluate Division","slug":"399. Evaluate Division","date":"2021-08-14T13:18:15.761Z","updated":"2021-08-14T13:17:50.809Z","comments":true,"path":"2021/08/14/399. Evaluate Division/","link":"","permalink":"https://zjuytw.github.io/2021/08/14/399.%20Evaluate%20Division/","excerpt":"","text":"399. Evaluate Division Description Solution Record each equations’ string name and its corresponding index, used later. Then do a floyd search to all strings, find their division. Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: vector&lt;double&gt; calcEquation(vector&lt;vector&lt;string&gt;&gt;&amp; equations, vector&lt;double&gt;&amp; values, vector&lt;vector&lt;string&gt;&gt;&amp; queries) &#123; vector&lt;string&gt; names; unordered_map&lt;string, unordered_map&lt;string, double&gt;&gt; Map; for(int i = 0; i &lt; equations.size(); i++)&#123; if(Map.find(equations[i][0]) == Map.end())&#123; Map[equations[i][0]][equations[i][0]] = 1.0; names.push_back(equations[i][0]); &#125; if(Map.find(equations[i][1]) == Map.end())&#123; Map[equations[i][1]][equations[i][1]] = 1.0; names.push_back(equations[i][1]); &#125; Map[equations[i][0]][equations[i][1]] = values[i]; Map[equations[i][1]][equations[i][0]] = 1.0/values[i]; &#125; for(int k = 0;k &lt; Map.size();k++)&#123; for(int i = 0; i &lt; Map.size();i++)&#123; for(int j = 0; j &lt; Map.size(); j++)&#123; if(i == j || i == k || j == k) continue; string a = names[i], b= names[j], c= names[k]; if(Map[a].find(c) != Map[a].end() &amp;&amp; Map[b].find(c) != Map[b].end())&#123; Map[a][b] = Map[a][c] / Map[b][c]; Map[b][a] = Map[b][c] / Map[a][c]; &#125; &#125; &#125; &#125; vector&lt;double&gt; res; for(int i = 0; i &lt; queries.size(); i++)&#123; string a = queries[i][0], b = queries[i][1]; if(Map.find(a) == Map.end() || Map.find(b) == Map.end()) res.push_back(-1); else if(Map[a].find(b) == Map[a].end()) res.push_back(-1); else res.push_back(Map[a][b]); &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Floyd","slug":"Floyd","permalink":"https://zjuytw.github.io/tags/Floyd/"}]},{"title":"1583. Count Unhappy Friends","slug":"1583. Count Unhappy Friends","date":"2021-08-14T13:18:15.685Z","updated":"2021-08-14T13:12:40.008Z","comments":true,"path":"2021/08/14/1583. Count Unhappy Friends/","link":"","permalink":"https://zjuytw.github.io/2021/08/14/1583.%20Count%20Unhappy%20Friends/","excerpt":"","text":"1583. Count Unhappy Friends Description Solution Iterate all potential pair(i,j) to see if they are ranked higher in each preference Code 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int unhappyFriends(int n, vector&lt;vector&lt;int&gt;&gt;&amp; preferences, vector&lt;vector&lt;int&gt;&gt;&amp; pairs) &#123; vector&lt;unordered_map&lt;int,int&gt;&gt; perfers(n); unordered_map&lt;int,int&gt; Map; int res = 0; for(int j = 0; j &lt; n; j ++)&#123; for(int i = 0; i &lt; n-1; i++)&#123; perfers[j][preferences[j][i]] = i; &#125; &#125; for(auto pair: pairs)&#123; Map[pair[0]] = pair[1]; Map[pair[1]] = pair[0]; &#125; vector&lt;int&gt; visited(n,0); for(int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt; i; j++)&#123; if(Map[i] == j) continue; if(perfers[i][j] &lt; perfers[i][Map[i]] &amp;&amp; perfers[j][i] &lt; perfers[j][Map[j]])&#123; res += visited[i] == 0; res += visited[j] == 0; visited[i] = 1; visited[j] = 1; &#125; &#125; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"233. Number of Digit One","slug":"233. Number of Digit One","date":"2021-08-13T15:59:46.108Z","updated":"2021-08-15T17:49:08.496Z","comments":true,"path":"2021/08/13/233. Number of Digit One/","link":"","permalink":"https://zjuytw.github.io/2021/08/13/233.%20Number%20of%20Digit%20One/","excerpt":"","text":"233. Number of Digit One Description Solution We can calculate the number of one on each digit, for example 123To count one&#x27;s number on 1234567we can count one on 1, 10, 100...If we need to count one on 100, we can have 1234 * 100 + 100 So we can have 12k&#x27;s digit count = [n/10^(k+1)] * 10 ^ k + min(max(n mod 10^(k+1) - 100, 0), 10^k) Code 123456789101112131415class Solution &#123;public: int countDigitOne(int n) &#123; // mulk 表示 10^k // 在下面的代码中，可以发现 k 并没有被直接使用到（都是使用 10^k） // 但为了让代码看起来更加直观，这里保留了 k long long mulk = 1; int ans = 0; for (int k = 0; n &gt;= mulk; ++k) &#123; ans += (n / (mulk * 10)) * mulk + min(max(n % (mulk * 10) - mulk + 1, 0LL), mulk); mulk *= 10; &#125; return ans; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"}]},{"title":"388. Longest Absolute File Path","slug":"388. Longest Absolute File Path","date":"2021-08-12T15:52:39.661Z","updated":"2021-08-15T17:50:01.012Z","comments":true,"path":"2021/08/12/388. Longest Absolute File Path/","link":"","permalink":"https://zjuytw.github.io/2021/08/12/388.%20Longest%20Absolute%20File%20Path/","excerpt":"","text":"388. Longest Absolute File Path Description Solution Recollection the use of stringstream: http://www.cplusplus.com/reference/sstream/stringstream/ Code 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: int lengthLongestPath(string input) &#123; stringstream ss(input); string token; vector&lt;string&gt; paths; int res = 0; while(getline(ss, token, &#x27;\\n&#x27;))&#123; int layer = 0; int length = 0; for(int i = 0; i &lt; token.size(); i++)&#123; if(token[i] != &#x27;\\t&#x27;) break; layer++; &#125; token = token.substr(layer); if(isFile(token))&#123; for(int i = 0; i &lt; layer; i++) length += paths[i].size() + 1; res = max(length + (int)token.size() , res); &#125;else&#123; if(paths.size() &gt;= layer+1) paths[layer] = token; else paths.push_back(token); &#125; &#125; return res; &#125; bool isFile(string&amp; token)&#123; for(auto c : token) if(c == &#x27;.&#x27;) return true; return false; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Stringstream","slug":"Stringstream","permalink":"https://zjuytw.github.io/tags/Stringstream/"}]},{"title":"516. Longest Palindromic Subsequence","slug":"516. Longest Palindromic Subsequence","date":"2021-08-12T15:52:39.638Z","updated":"2021-08-12T15:46:21.320Z","comments":true,"path":"2021/08/12/516. Longest Palindromic Subsequence/","link":"","permalink":"https://zjuytw.github.io/2021/08/12/516.%20Longest%20Palindromic%20Subsequence/","excerpt":"","text":"516. Longest Palindromic Subsequence Description Solution Use DP to find the longest palindromic subsequence in one interval 12//dp[i][j] = (i &gt; j) from j to i, longest palinidromic subsequence//dp[i][j] = dp[i-1][j+1] + 2 (if s[i] == s[j]), else dp[i][j] = dp[i][j+1] Code 123456789101112131415161718192021class Solution &#123;public: int longestPalindromeSubseq(string s) &#123; //dp[i][j] = (i &gt; j) from j to i, longest palinidromic subsequence //dp[i][j] = dp[i-1][j+1] + 2 (if s[i] == s[j]), else dp[i][j] = dp[i][j+1] vector&lt;vector&lt;int&gt;&gt; dp(s.size()+1, vector&lt;int&gt;(s.size()+1, 0)); for(int i = 1; i &lt;= s.size(); i++)&#123; for(int j = i; j &gt; 0; j--)&#123; if(i == j) dp[i][j] = 1; else&#123; if(s[i-1] == s[j-1]) dp[i][j] = dp[i-1][j+1] + 2; else dp[i][j] = max(dp[i][j+1], dp[i-1][j]); &#125; &#125; &#125; return dp[s.size()][1]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"446. Arithmetic Slices II - Subsequence","slug":"446. Arithmetic Slices II - Subsequence","date":"2021-08-11T15:42:52.096Z","updated":"2021-08-11T15:42:18.197Z","comments":true,"path":"2021/08/11/446. Arithmetic Slices II - Subsequence/","link":"","permalink":"https://zjuytw.github.io/2021/08/11/446.%20Arithmetic%20Slices%20II%20-%20Subsequence/","excerpt":"","text":"446. Arithmetic Slices II - Subsequence Description Solution DP to check out the previous subsequence number satisfied requirement. 1dp[i][d] = In position i, the number satisfied requirement that difference is d Code 123456789101112131415161718typedef long long LL;class Solution &#123; // int res = 0;public: int numberOfArithmeticSlices(vector&lt;int&gt;&amp; nums) &#123; vector&lt;unordered_map&lt;LL,int&gt;&gt; dp(nums.size()+1); int res = 0; for(int i = 1; i &lt; nums.size(); i++)&#123; for(int j = 0; j &lt; i; j++)&#123; LL d = 1LL * nums[i] - nums[j]; int cnt = ((dp[j].find(d) != dp[j].end()) ? dp[j][d] : 0); res += cnt; dp[i][d] += cnt+1; &#125; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"}]},{"title":"679. 24 Game","slug":"679. 24 Game","date":"2021-08-11T15:42:52.075Z","updated":"2021-08-11T15:36:55.771Z","comments":true,"path":"2021/08/11/679. 24 Game/","link":"","permalink":"https://zjuytw.github.io/2021/08/11/679.%2024%20Game/","excerpt":"","text":"679. 24 Game Description Solution Recursively check all the potential combination of the 4 numbers. In each round, we iteratively select 2 out of N numbers, calculate the result of +, -, *, / then put back the result into next round. Don’t forget the function return condition is if N == 1, nums[0] == 24 . And for float number, we should do this in abs() &lt; 1e-6 Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; int op[4] = &#123;1,2,3,4&#125;;public: bool judgePoint24(vector&lt;int&gt;&amp; cards) &#123; vector&lt;double&gt; nums; for(auto card : cards) nums.push_back(1.0 * card); return dfs(nums); &#125; bool dfs(vector&lt;double&gt;&amp; nums)&#123; int n = nums.size(); if(n == 1) return (abs(nums[0] - 24) &lt; 1e-6); for(int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; if(i == j) continue; double a = nums[i], b = nums[j]; vector&lt;double&gt; newnums; for(int k = 0; k &lt; n; k++) if(k != i &amp;&amp; k != j) newnums.push_back(nums[k]); newnums.push_back(-1); //iterate all operators newnums.back() = a + b; if(dfs(newnums)) return true; newnums.back() = a - b; if(dfs(newnums)) return true; newnums.back() = a * b; if(dfs(newnums)) return true; if(b != 0)&#123; newnums.back() = a / b; if(dfs(newnums)) return true; &#125; &#125; &#125; return false; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"}]},{"title":"133. Clone Graph","slug":"133. Clone Graph","date":"2021-08-10T16:15:38.395Z","updated":"2021-08-10T16:13:21.379Z","comments":true,"path":"2021/08/11/133. Clone Graph/","link":"","permalink":"https://zjuytw.github.io/2021/08/11/133.%20Clone%20Graph/","excerpt":"","text":"133. Clone Graph Description Solution I uses two map to store the visited and waiting nodes, then BFS for the next node be copied. Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*// Definition for a Node.class Node &#123;public: int val; vector&lt;Node*&gt; neighbors; Node() &#123; val = 0; neighbors = vector&lt;Node*&gt;(); &#125; Node(int _val) &#123; val = _val; neighbors = vector&lt;Node*&gt;(); &#125; Node(int _val, vector&lt;Node*&gt; _neighbors) &#123; val = _val; neighbors = _neighbors; &#125;&#125;;*/class Solution &#123; unordered_map&lt;int, Node*&gt; visited; unordered_map&lt;int, Node*&gt; waited;public: Node* cloneGraph(Node* node) &#123; if(node == nullptr) return node; queue&lt;Node*&gt; q; Node* root = new Node(node-&gt;val, node-&gt;neighbors); q.push(root); waited[root-&gt;val] = root; while(!q.empty())&#123; int size = q.size(); for(int i = 0; i &lt; size; i++)&#123; auto top = q.front(); q.pop(); for(int i = 0; i &lt; top-&gt;neighbors.size(); i ++)&#123; auto nbor = top-&gt;neighbors[i]; if(visited.find(nbor-&gt;val) == visited.end())&#123; Node *next = nullptr; if(waited.find(nbor-&gt;val) == waited.end())&#123; next = new Node(nbor-&gt;val, nbor-&gt;neighbors); waited[nbor-&gt;val] = next; &#125;else next = waited[nbor-&gt;val]; top-&gt;neighbors[i] = next; q.push(top-&gt;neighbors[i]); &#125;else&#123; top-&gt;neighbors[i] = visited[nbor-&gt;val]; &#125; &#125; visited[top-&gt;val] = top; waited.erase(top-&gt;val); &#125; &#125; return root; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"BFS","slug":"BFS","permalink":"https://zjuytw.github.io/tags/BFS/"},{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"}]},{"title":"491.Increasing Subsequences","slug":"491. Increasing Subsequences","date":"2021-08-10T16:15:38.362Z","updated":"2021-08-10T16:15:08.836Z","comments":true,"path":"2021/08/11/491. Increasing Subsequences/","link":"","permalink":"https://zjuytw.github.io/2021/08/11/491.%20Increasing%20Subsequences/","excerpt":"","text":"491.Increasing Subsequences Description Solution Two solutions: DP, use set&lt;vector&lt;int&gt;&gt; to deduplicate Back Tracking, don’t forget deduplicating Code 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; findSubsequences(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(nums.size()); set&lt;vector&lt;int&gt;&gt; Set; for(int i = 0; i &lt; nums.size(); i ++)&#123; dp[i].push_back(&#123;nums[i]&#125;); for(int j = 0; j &lt; i; j++)&#123; if(nums[i] &gt;= nums[j])&#123; for(auto sequence: dp[j])&#123; //sequence -&gt; vector&lt;int&gt; dp[i].push_back(sequence); dp[i].back().push_back(nums[i]); Set.insert(dp[i].back()); &#125; &#125; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; res; for(auto seq : Set)&#123; res.push_back(seq); &#125; return res; &#125;&#125;; Solution2 : 123456789101112131415161718192021222324252627class Solution &#123; vector&lt;vector&lt;int&gt;&gt; res;public: vector&lt;vector&lt;int&gt;&gt; findSubsequences(vector&lt;int&gt;&amp; nums) &#123; vector&lt;int&gt; curRes; backtrack(nums, 0, curRes); return res; &#125;; void backtrack(vector&lt;int&gt;&amp; nums, int curPos, vector&lt;int&gt;&amp; curres)&#123; if(curres.size() &gt; 1) res.push_back(curres); if(curPos == nums.size()) return; unordered_set&lt;int&gt; seen; for(int i = curPos; i &lt; nums.size(); i++)&#123; if(curres.size()&gt;0 &amp;&amp; nums[i] &lt; curres.back()) continue; if(seen.count(nums[i])) continue; curres.push_back(nums[i]); backtrack(nums, i+1, curres); curres.pop_back(); seen.insert(nums[i]); &#125; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Back Tracking","slug":"Back-Tracking","permalink":"https://zjuytw.github.io/tags/Back-Tracking/"}]},{"title":"413. Arithmetic Slices","slug":"413. Arithmetic Slices","date":"2021-08-10T16:15:38.359Z","updated":"2021-08-10T16:12:47.366Z","comments":true,"path":"2021/08/11/413. Arithmetic Slices/","link":"","permalink":"https://zjuytw.github.io/2021/08/11/413.%20Arithmetic%20Slices/","excerpt":"","text":"413. Arithmetic Slices Description Solution Iteration to find start &amp; end of each Arithmetic Code 12345678910111213141516171819202122class Solution &#123;public: int numberOfArithmeticSlices(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() &lt; 3) return 0; vector&lt;int&gt; diff(nums.size()-1); for(int i = 1; i &lt; nums.size(); i++)&#123; diff[i-1] = nums[i] - nums[i-1]; &#125; int prev = diff[0], count = 0, res = 0; for(int i = 1; i &lt; diff.size(); i++)&#123; if(prev == diff[i])&#123; count++; res += count; &#125;else&#123; count = 0; &#125; prev = diff[i]; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Iteration","slug":"Iteration","permalink":"https://zjuytw.github.io/tags/Iteration/"}]},{"title":"727. Minimum Window Subsequence","slug":"727. Minimum Window Subsequence","date":"2021-08-09T16:39:05.536Z","updated":"2021-08-09T16:37:26.337Z","comments":true,"path":"2021/08/10/727. Minimum Window Subsequence/","link":"","permalink":"https://zjuytw.github.io/2021/08/10/727.%20Minimum%20Window%20Subsequence/","excerpt":"","text":"727. Minimum Window Subsequence Description Solution There are two solutions, one is original DP(very common solution that must think of it when encounter a string problem), another is Finite State Machine solution. DP 123456789DP[i][j] = the minimum subsequence length k//e.g, s2[0 : j] is a subsequence of s1[i - k + 1: i]if s1[i] == s2[j] dp[i][j] = dp[i-1][j-1] + 1else dp[i][j] = dp[i-1][j] + 1return min&#123;dp[i][N]&#125; for i= 1,2,3..M Finite State Machine 1234567Define a array next[i][ch]: look right from position i, the pos of the nearest chWith the next[][], we directly jump into next nearest matched postion without iterate.And the way to calculate next is DP, we see from back to frontnext[i][ch] = next[i+1][ch](except next[i][s[i+1] - &#x27;a&#x27;] = i+1) Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;public: string minWindow(string s1, string s2) &#123; if(s1.size() &lt; s2.size()) return &quot;&quot;; //DP // vector&lt;vector&lt;int&gt;&gt; dp(s1.size() + 1, vector&lt;int&gt;(s2.size() + 1, INT_MAX)); // for(int i = 0; i &lt;= s1.size(); i++) // dp[i][0] = 0; // for(int i = 1; i &lt;= s1.size(); i++)&#123; // for(int j = 1; j &lt;= s2.size() &amp;&amp; j &lt;= i; j++)&#123; // if(s1[i-1] == s2[j-1] &amp;&amp; dp[i-1][j-1] != INT_MAX) // dp[i][j] = dp[i-1][j-1] + 1; // else if(s1[i-1] != s2[j-1] &amp;&amp; dp[i-1][j] != INT_MAX) // dp[i][j] = dp[i-1][j] + 1; // &#125; // &#125; // string res = &quot;&quot;; // for(int i = 1; i &lt;= s1.size(); i++)&#123; // if((res == &quot;&quot; &amp;&amp; dp[i][s2.size()] != INT_MAX) || res.size() &gt; dp[i][s2.size()])&#123; // res = s1.substr(i-dp[i][s2.size()], dp[i][s2.size()]); // &#125; // &#125; //Finite-State-Machine vector&lt;vector&lt;int&gt;&gt; next(s1.size(), vector&lt;int&gt;(26,0)); for(int i = 0; i &lt; 26; i++)&#123; next[s1.size()-1][i] = -1; &#125; for(int i = s1.size()-2; i &gt;= 0; i--)&#123; for(int j = 0; j &lt; 26; j++) next[i][j] = next[i+1][j]; next[i][s1[i+1] - &#x27;a&#x27;] = i+1; &#125; string res = &quot;&quot;; int length = INT_MAX, start; for(int i = 0; i &lt; s1.size(); i++)&#123; if(s1[i] == s2[0])&#123; int j = i, s2i = 1; while(s2i &lt; s2.size() &amp;&amp; next[j][s2[s2i] - &#x27;a&#x27;] != -1)&#123; j = next[j][s2[s2i++] - &#x27;a&#x27;]; &#125; if(s2i == s2.size())&#123; if(length &gt; j - i + 1)&#123; start = i; length = j - i + 1; &#125; &#125; &#125; &#125; if(length != INT_MAX) res = s1.substr(start, length); return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Finite State Machine","slug":"Finite-State-Machine","permalink":"https://zjuytw.github.io/tags/Finite-State-Machine/"}]},{"title":"313. Super Ugly Number","slug":"313. Super Ugly Number","date":"2021-08-09T16:39:05.535Z","updated":"2021-08-09T16:38:11.209Z","comments":true,"path":"2021/08/10/313. Super Ugly Number/","link":"","permalink":"https://zjuytw.github.io/2021/08/10/313.%20Super%20Ugly%20Number/","excerpt":"","text":"313. Super Ugly Number Description Solution Use priority_queue to find the smallest number Be careful about integer overflow. Code 12345678910111213141516class Solution &#123;public: int nthSuperUglyNumber(int n, vector&lt;int&gt;&amp; primes) &#123; priority_queue&lt;long, vector&lt;long&gt;, greater&lt;&gt;&gt; pq; long top; pq.push(1); while(n--)&#123; top = pq.top(); while(!pq.empty() &amp;&amp; pq.top() == top) pq.pop(); for(auto prime: primes) pq.push(top * prime); &#125; return (int)top; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Priority Queue","slug":"Priority-Queue","permalink":"https://zjuytw.github.io/tags/Priority-Queue/"}]},{"title":"1353. Maximum Number of Events That Can Be Attended","slug":"1353. Maximum Number of Events That Can Be Attended","date":"2021-08-09T16:39:05.516Z","updated":"2021-08-09T16:38:24.239Z","comments":true,"path":"2021/08/10/1353. Maximum Number of Events That Can Be Attended/","link":"","permalink":"https://zjuytw.github.io/2021/08/10/1353.%20Maximum%20Number%20of%20Events%20That%20Can%20Be%20Attended/","excerpt":"","text":"1353. Maximum Number of Events That Can Be Attended Description Solution Use priority_queue to find the closed DDL’s event and handle it in the day. There is are tricky programming point that we can directly iterate the whole [earliest start time, latest finish time] to find each day’s best strategy or we can also iterate every sorted event. Code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123; static bool cmp(vector&lt;int&gt;&amp;a, vector&lt;int&gt; &amp;b)&#123; if(a[0] == b[0]) return a[1] &lt; b[1]; return a[0] &lt; b[0]; &#125;public: int maxEvents(vector&lt;vector&lt;int&gt;&gt;&amp; events) &#123; sort(events.begin(), events.end(), cmp); priority_queue&lt;int, vector&lt;int&gt;, greater&lt;&gt;&gt; pq; int res = 0, i = 0; for(int day = 1; day &lt;= 1E5; day++)&#123; while(i &lt; events.size() &amp;&amp; events[i][0] == day)&#123; pq.push(events[i++][1]); &#125; while(!pq.empty() &amp;&amp; pq.top() &lt; day) pq.pop(); if(!pq.empty() &amp;&amp; pq.top() &gt;= day)&#123; pq.pop(); res++; &#125; &#125; // int curt = events[0][0]; // int res = 0; // for(int i = 0; i &lt; events.size(); i++)&#123; // if(curt == events[i][0])&#123; // pq.push(events[i][1]); // &#125;else&#123; // while(!pq.empty() &amp;&amp; curt &lt; events[i][0])&#123; // curt++; // res++; // pq.pop(); // while(!pq.empty() &amp;&amp; pq.top() &lt; curt) // pq.pop(); // &#125; // curt = events[i][0]; // pq.push(events[i][1]); // &#125; // &#125; // while(!pq.empty() &amp;&amp; pq.top() &gt;= curt)&#123; // curt++; // res++; // pq.pop(); // while(!pq.empty() &amp;&amp; pq.top() &lt; curt) // pq.pop(); // &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Priority Queue","slug":"Priority-Queue","permalink":"https://zjuytw.github.io/tags/Priority-Queue/"}]},{"title":"6.824 Bitcoin lecture note","slug":"6.824-19. Bitcoin","date":"2021-08-09T09:13:23.361Z","updated":"2021-08-09T10:06:13.523Z","comments":true,"path":"2021/08/09/6.824-19. Bitcoin/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-19.%20Bitcoin/","excerpt":"","text":"Bitcoin As mentioned in Satoshi Nakamoto’s paper that bitcoin is aimed to prevent double-spending as well as reduce the cost of third party involvement. Bitcoin has three features that makes it Epoch-making Decentralization Using Peer-to-Peer Technology Low-cost transaction Brief Intro Bitcoin is a distributed ledger which implement decentralization. Bitcoin ‘s design should solve Byzantine Generals Problem because it is running through public Internet. Bitcoin systems reply on Proof of Work to verify each node’s validation to prove itself running on a true CPU. Bitcoin also promise that : Malicious nodes’ blockchain won’t grow long, if most of nodes in the network are meritorious. For double-spending problem, block-chain ensures that even if blockchain may fork at some point, but only one fork will be accepted in the end. Drawbacks Every new transaction need 10 min before recording on the blockchain The trustworthiness grows as the chain grows longer, but still have chance to be waived by receiving a longer chain from other node. Waste energy Extends You may read paper and watch lecture to get more detailed information about bitcoin.","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Bitcoin","slug":"Bitcoin","permalink":"https://zjuytw.github.io/tags/Bitcoin/"}]},{"title":"6.824 CT lecture note","slug":"6.824-18. Certificate Transparency(Fork Consistency)","date":"2021-08-09T09:13:23.356Z","updated":"2021-08-09T10:45:57.253Z","comments":true,"path":"2021/08/09/6.824-18. Certificate Transparency(Fork Consistency)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-18.%20Certificate%20Transparency(Fork%20Consistency)/","excerpt":"","text":"Certificate Transparency Introduce First review the vulnerability of HTTP and an example of Man in the Middle Attack. HTTP HTTP is a request response protocol to communicate asynchronously between client and server. For websites and pages the browser acts as a client and a web-server like Apache or IIS acts as server. The server hosts the files (like html , audio , video files etc) and returns are responds to client requests with the data. Depending on the request a response contains the status of the request. The process involves a series of messages that go back and forth between the client and server. The process starts with initiating a connection. After that a process known as TCP slow start kicks in. At this point data is passed between the two parties via data packets and often requires multiple round trips. TCP slow start is designed to gradually expand the amount of data traversing the wire each round trip. The initial packet size is 16kb and doubles on subsequent round trips until a max size is reached. This can vary, but tends to be around 4MB for most connections. This process is used because the server does not know how much bandwidth the client can handle. Rather than overflowing the client the server uses a gentle size and continues to increase until a limit is found. As data or request bodies move between the client and the server it is done using clear or plain text. This is viewable by anyone or software watching the network traffic. This is not that important for general content. However, today even when you don’t think sensitive data is moving between the two parties more sessions do transport identifying information. This is why every website should use TLS to secure HTTP connections. Man in the Middle Attack A third-party may easily hijack the connection towards target website and redirect to its own rogue web, for no further check mechanism in HTTP. Certificate, SSL, TLS, HTTPS HTTPS work flow: Particularly, server should request a certificate from CA(Certificate Authority). Whenever client send a connection request to server, it will receive a CERT from server. Certificate Server name, eg: “gmail.com” Public Key of server CA’s Signature CA’s unique signature ensures that just CA can issue the certificate to server that no one else can counterfeit. NOTE: A vulnerability of this scheme is that once a CA was broken into or something else happened and caused CA issued a malicious certificate. Client may have chance to talk to a rogue web and info may get leaked. Certificate Transparency Certificate Transparency is a system that stores certificate logs which are stored distributed and append-only on CT. CT can provide user certificate verification to keep CA from issuing malicious certificate and the certificate even keep in CA for longer time. CT promises following: Certificates are deposited in public, transparent logs Logs are cryptographically monitored Implementation Each certificates are stored as a node in Merkle Tree in CT. Each node in each level is the value of the output of cryptographic hash function that maps an arbitrary-size message M to a small fixed-size output H(M), with the property that it is infeasible in practice to produce any pair of distinct messages M1 ≠ M2 with identical hashes H(M1) = H(M2). And the we have 12h(0, K) = H(record K)h(L+1, K) = H(h(L, 2 K), h(L, 2 K+1)) With the property of above, we can determine whether a specific certificate stored in the tree, we can recompute hash(the certificate) and the hash value of its siblings and relatives to finally get the top-level’s hash. If H(4,0) == recomputed H(4,0), then proved. Example: For example, suppose we want to prove that a certain bit string B is in fact record 9 in a tree of 16 records with top-level hash T. We can provide those bits along with the other hash inputs needed to reconstruct the overall tree hash using those bits. Specifically, the client can derive as well as we can that: 1234567T = h(4, 0)= H(h(3, 0), h(3, 1))= H(h(3, 0), H(h(2, 2), h(2, 3)))= H(h(3, 0), H(H(h(1, 4), h(1, 5)), h(2, 3)))= H(h(3, 0), H(H(H(h(0, 8), h(0, 9)), h(1, 5)), h(2, 3)))= H(h(3, 0), H(H(H(h(0, 8), H(record 9)), h(1, 5)), h(2, 3)))= H(h(3, 0), H(H(H(h(0, 8), H(B)), h(1, 5)), h(2, 3))) Fork Attack (Fork Consistency) The proof of fork consistency, image a log servers have a chain of logs and once the log server wants to fork (like, to trick a user for a malicious certificate but not seen by other monitors etc.) CT has a mechanism to detect the inconsistency by gossip Like the example, once a log server has a fork line that starts with B for bogus and have a current STH(signed tree head, the top-level hash value). We can simply calculate if STH1’s log a prefix log of STH2’s log by the same way prove if STH1’s log is inside STH2’s log tree. If return a false, which means STH1 is on a different fork.","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Certificate Transparency","slug":"Certificate-Transparency","permalink":"https://zjuytw.github.io/tags/Certificate-Transparency/"}]},{"title":"6.824 COPS lecture note","slug":"6.824-17.COPS(Causal Consistency)","date":"2021-08-09T09:13:23.348Z","updated":"2021-08-09T10:06:00.232Z","comments":true,"path":"2021/08/09/6.824-17.COPS(Causal Consistency)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-17.COPS(Causal%20Consistency)/","excerpt":"","text":"COPS Introduce Still the website Front-End read from DB storage cluster model. We are gonna explore another possibility as local read and local write to speed up transactions. How to achieve stronger Consistency in terms of CAP Theorem. Consider [Spanner](./13.Spanner(Strong Consistency RW).md) and [Memcache](./16.Memcache(Cache Consistency).md)’s scheme Spanner Linearizability For R/W transaction, Use PAXOS and 2PC to write to remote replication. (Wait for quorum’s acknowledge) For R/O transaction, read from local. Use Snapshot Isolation and TrueTime clock mechanism to ensure local serializability. Memcache Eventual Consistency Introduce memcache layer to achieve write to DB and read from memcache. Write need receive DB’s acknowledge and read has no need to wait. For COPS, it figures out a new way to make more efficient read and write by implementing causal consistency, which is stronger than eventual consistency but weaker than linearizability. Implementation COPS, aka Cluster of Order-Preserving Servers, a key-value store that delivers causal-consistency model across the wide-area. Every Data Center has a local COPS cluster, which maintains a complete replica of stored data. So client can just talk to local cluster for data’s read and write. In each Data Center, data are divided into many shards, which is linearizable and clients access each partition independently. So the whole cluster is linearizable as well. The problem comes when clusters communicate with each other to remain sync. To achieve causal consistency, COPS have a prime node be responsible for local writing. After local writing is finished, prime will send it to other cluster’s prime node, and a version number will be sent as well to keep causal order. Causality ​ Potential Causality definition Execution Thread. If a and b are two operations in a single thread of execution, then a -&gt; b if operation a happens before operation b Gets From. If a is a put operation and b is a get operation that returns the value written by a, then a -&gt; b Transitivity. For operations a, b, and c, if a -&gt; b and b -&gt; c, then a -&gt; c Example: We can learn from the figure that put(z,5) is derived from get(x) = 4, which means to execute put(z,5) we have ensured that what is logically happened earlier than it. Note: If the system can not tell weather two operation’s happening order, since there is no explicit reason about they, We can simply define they are concurrent, so system can decide the order they happen. But for two put concurrently write to the same key, there is a conflict. So to deal with conflicts, Last write win is a proper way to deal with it but if we want to doappend &amp; atomical count like thing, this strategy may not work. Context Each client maintains a context to explicitly mark their state. After each operation, the client will append a entry of keys’ version. So DC can simply use this entries to verify the dependencies of one operation. Example: We have 3 Data Centers, and one client calls put(Z, value, Zver3, Xver2, Yver4) to put Z = value. To forward this operation to other DC, DC1 will check the dependencies of Zver3, Xver2, Yver4 in other DC, if others’ are not in this stage, it will wait till other DCs reach or exceed the dependencies’ version number Lamport Timestamp To achieve global order, COPS use Lamport Timestamp in higher bits + unique ID For Data Center in lower bits . Combining with Logical timeclock and Wall Clock, we can give a global sequence despite of large inaccuracy. 12Tmax = highest version seen (from self and others)T = max(Tmax + 1, wall-clock time) Write Client -&gt; Local Data Store Cluster -&gt; other DCs When client sends a put(key, value …) , client library will calculate the dependencies according to the context. The local prime will wait till cluster has indeed store all the dependencies( check by version number). Then send to remote clusters, do the same. Read Read from local cluster, the library function provide both read the latest version of key and a specific older one by explicitly send a context with get. limitation Causal Consistency can not be aware of external dependency. For example, Alice told Bob to check a new status of the key, and then Bob sent a get request via client. Now Bob may see old value of key because the system do not know that Alice calls Bob yields Bob’s get request. And this is also discussed by lamport in &lt;Time, Clocks, and the Ordering of Events in a Distributed System&gt; It’s hard to manage conflict, Last write win is not generic","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"COPS","slug":"COPS","permalink":"https://zjuytw.github.io/tags/COPS/"}]},{"title":"6.824 Memcache lecture note","slug":"6.824-16.Memcache(Cache Consistency)","date":"2021-08-09T09:13:23.342Z","updated":"2021-08-09T10:05:56.458Z","comments":true,"path":"2021/08/09/6.824-16.Memcache(Cache Consistency)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-16.Memcache(Cache%20Consistency)/","excerpt":"","text":"Memcahce at Facebook Intro In a popular webserver scenario, we have web application that clients send request (especially most reads and a few writes) to Data Base, and as we both know things get worse when one peer in the system suffer a throughput bottleneck. To achieve better performance and also get stronger consistency. Single Web Server(eg, running on Apache Tomcat) + Single DataBase(eg, MySQL/ Oracle) ​ &#8595; Muti-Stateless Web Server + Single DB &#8595; Mutl-Stateless Web Server + DB cluster(sharded by key, in both scheme and table layer) ​ &#8595; Mutl-Stateless Web Server + Memcache (For speeding up reads) + DB cluster Implementation Facebook noticed that their customers consume an ordered of magnitude more content that they create, so fetching data is the domain element for the performance bottleneck. Also, they have various storage services, like MySQL, HDFS etc, which means a flexible caching strategy is needed. Finally, they came up with an architecture that separate caching layer from the persistence layer, which means that for a group a Web server, they combine with a group of Memcache to form a Front-End Cluster, then a Front-End Cluster combine with a data-completed DB to form a region(AKA Data Center). So as the distributed spread of region, users from different area of USA can access to the Web server with lowest latency by choosing different region. Because of the tolerance of stale message differs in different situation User can stand for transient stale data, but not too long User tend to observe their latest data after writing it So the Memcache can achieve eventual consistency by using its R/W strategy. 123456789Read Scheme: v = get(k) if v == nil v = fetch from DB set(k,v)Write Scheme: send k,v to DB delete(k) in MC Hint This scheme can not prevent users from seeing stale data If user read exactly after line 8, at this point, Memcache still holds the stale data but DB has updated the key to the new value Q: Why not delete key in the MC first before send k,v to DB? A: Because if at the time deleted the key in MC but another server did not see key in MC, it will send fetch to DB then may get the stale data that might be deleted afterwards and store to MC. Then MC may store the stale data until another write is fired up. Q: Why not just set(k,v) in MV in line 9 A : Because delete is idempotent while set is not. Check in the example: 12345C1 : x = 1 -&gt; DB C2 : x = 2 -&gt; DB set(x,2)C1 : set(x,1) // makes stale data stored Prime &amp; Secondary Scheme For many regions, there is one master region and many salve region Local Read and Prime Write For read, each FE read use Read Scheme in local region. This is super fast For write, slave’s write need to be send to primary region Prime&amp;Secondary replication, primary DB always send info to remote DB to stay in sync Performance Let’s talk about two parallel process strategies. Partition increase RAM efficiency that each Key just store once Not good for some hot keys Client may talk to many part for one website’s resource Replication Good for hot key Fewer TCP connection RAM wasted for more replica For Facebook’s architecture, we have two completed replicated asynchronized region that brings fault-tolerance also low-latency for different area’s user. In each region, FB partitioned DB then using many Memcache to cache hot keys to reduce DB’s load. There is also a regional Memcache cluster in each region to cache those not too hot keys. Lease FB uses lease mechanism to fix the Thunder Herd and Race Condition. Thunder Herd – If many FE are simultaneously read the same key from Memcache and at this time, one FE do a write() and delete the old key in Memcache. Then DB may have the risk of flooded by too many queries for one key. Race Condition – Example 123456C1 : get(k) -&gt; missC1 : read k from DB -&gt; value1 C2 : write k = value2 -&gt; DB C2 : delete(k) to MCC1 : set(k,v1) to MC// In this situation, stale data of value1 will store on MC forever Solution To each get(k), Memcache server should issue FE a lease for a period of time. Thunder Herd, if one FE get the lease, then others that also send get(k) will block till the first FE calls put(k,v, l) or lease expired Race Condition, C1’s get(k) will be issued a lease, but C2’s delete will invalid the old lease, the when C1 fetch value1 from DB then calls put(k,v1, l), the Memcache server will reject it. Extend Another introduce of twitter’s cache system in Twitter 内存缓存系统分析论文阅读","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Memcache@FB","slug":"Memcache-FB","permalink":"https://zjuytw.github.io/tags/Memcache-FB/"}]},{"title":"6.824 Spark lecture note","slug":"6.824-15.Spark(Big Data Process)","date":"2021-08-09T09:13:23.335Z","updated":"2021-08-09T10:06:04.918Z","comments":true,"path":"2021/08/09/6.824-15.Spark(Big Data Process)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-15.Spark(Big%20Data%20Process)/","excerpt":"","text":"Spark Introduce Spark is a successor of MapReduce to process distributed big-data computing tasks. Frameworks like MapReduce, Dryad, and Spark help data scientists to focus on their business rather than wasting time on designing the distributed tasks and fault-tolerance. There are some constraints in previous frameworks that MapReduce lacks abstractions for leveraging distributed memory so makes it inefficient for those that reuse intermediate results across multiple computations and lacks high interactive flexibility, programmers may have trouble implementing some complex algorithms. Spark is an implementation of a new abstraction called resilient distributed datasets(RDDs), which are fault-tolerant, parallel data structures that let users explicitly persist intermediate results in memory, control their partitioning to optimize data placement, and manipulate them using a rich set of operators. RDD RDD(Resilient Distributed Dataset) is a collection of Read-Only and Partitioned records. RDDs can only be created through deterministic operations on either 1) data in stable storage or 2) other RDDs. Spark uses Lineage to keep track of how each RDD is transformed from previous datasets. Spark provides Action as well as Transformation. Action calculate RDDs and gets a result. Transformation imports data from external sources or transform an old RDD to a new Read-Only RDD. Computation Schedule RDDs are stored in distributed servers, so when we need to do Transformation, systems need to fetch previous RDD in the corresponding servers. There are two kinds of Transformations that forms different dependency between RDDs Narrow Dependency : Each partition of the parent RDD is used by at most one partition of the child RDD. Wide Dependency : Multiple child partitions may depend on the parent RDD. Spark speeds up Transformation by optimizing the Transformations related to Narrow Dependency. First, narrow dependencies allow for pipelined execution on one cluster node, which can compute all the parent partitions. Second, recovery after a node failure is more efficient with a narrow dependency, as only the lost parent partitions need to be recomputed. In contrast, in a lineage graph with wide dependencies, a single failed node might cause the loss of some partition form all the ancestors of an RDD, requiring a complete re-execution. Overall, a RDD are consistent of the following elements: Its partitions Its parent partitions Transformation Its metadata(eg, data type, storage position etc.) When user calls Action to process computation on RDD, Spark will build different stages according to lineages. Hence, Spark can build a job stage that contains as many Narrow Dependencies as possible to speed up the whole system’s efficiency. The boundaries of the stages are the shuffle operations required for wide dependencies, or any already computed partitions that can short-circuit the computations of a parent RDD. After building the job stages, Spark then launches tasks to compute missing partitions from each stage until it has computed the target RDD. While scheduling Tasks, Spark assigns tasks to machines based on data locality. The task will directly be processed by those nodes that is already holds the partition needed in memory. Otherwise, if a task processes a partition for which the containing RDD provides preferred locations(eg, an HDFS file), we send it to those. Fault-Tolerance Spark can re-compute the content of a failed RDD by dependencies from lineage graph. But there is a wide dependency during the re-computation, which means we have to re-compute all the RDD it depends, also, Spark won’t store all the RDD in the memory, or it will soon run out of memory. So we have to manually do persist, if necessary. 1rdd.persist(REPLICATE) Conclusion Spark RDD has the feature of: Store all info directly on memory Interactive API Find both Narrow and Wide Dependencies, while narrow one is more efficiency Have Checkpoint to failover from wide dependency failure But we still need to be aware that Spark is not a replacement for MapReduce: For those model and algorithms already fit in MapReduce, Spark won’t have a more efficient result for them. &lt;h2","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Spark","slug":"Spark","permalink":"https://zjuytw.github.io/tags/Spark/"}]},{"title":"6.824 CRAQ lecture note(Pending for updated)","slug":"6.824-14.OCC(FaRM)","date":"2021-08-09T09:13:23.329Z","updated":"2021-08-09T10:44:28.217Z","comments":true,"path":"2021/08/09/6.824-14.OCC(FaRM)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-14.OCC(FaRM)/","excerpt":"","text":"FaRM (To be updated...) Introduce Microsoft’s main memory distributed computing platform, FaRM can provide distributed transactions with serializability, high performance, durability, and high availability using RDMA and a new, inexpensive approach to providing non-volatile DRAM. NVRAM Strategy to become non-volatile: Using battery as back-up power, once the electric power fails, the system goes with battery and do all context saving work then shut down Note: This scheme is just helpful when encounters power failure, is not applicable for hardware/ software failure. –Because otherwise the system just shut down directly. Optimistic Concurrency Control For a optimistic lock, we have 12345Xaction begin read all values without lock use a buffer to store write commit writeXaction end Before commit transaction to storage, system need to verify the validation of the transaction. If success, then commit, else abort all the operation related to transaction. 12345tx.create()o = tx.copyRead(OID)o.value += 1tx.write(OID, o)ok := tx.commt() Transaction Management Refer to the above figures about server layout and OCC commit protocol. Let’s talk about FaRM’s transaction management. FaRM uses OCC and 2PC to achieve its serializability. 2PC strategy Read without lock, read(&amp; value, &amp;version) use one-side RDMA to read Lock the revised data primary polling for data which is (use DRMA to poll) locked, so send reject VERS changed, then send reject else, then set the lock and send yes.( To avoid racing, use CHECK&amp;SET atomic operation here) do validation for those no changed shard To check if version changed or locked] Commit","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"FaRM","slug":"FaRM","permalink":"https://zjuytw.github.io/tags/FaRM/"}]},{"title":"6.824 Spanner lecture note","slug":"6.824-13.Spanner(Strong Consistency RW)","date":"2021-08-09T09:13:19.948Z","updated":"2021-08-09T10:05:42.935Z","comments":true,"path":"2021/08/09/6.824-13.Spanner(Strong Consistency RW)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-13.Spanner(Strong%20Consistency%20RW)/","excerpt":"","text":"Spanner Introduce Spanner is Google’s scalable, multi-version, globally-distributed, and synchronously-replicated data. Spanner is the first global distributed Database and support external consistency. It is a big framework, but I just want to focus on some particular points – Mainly about external consistency and True-Time mechanism. You may look for more detailed illustration on Google’s Spanner paper or other’s blog about spanner. Consistency Assume that if we have 3 Data Centers, we have to send data across all data centers to keep consistency. To keep a strong consistency, Google uses paxos to send logs and reach consensus. Moreover, google has its True-Time mechanism to reach external consistency, but let’s talk about it later. R/W transactions For a transaction both need to read and write,spanner uses 2PC. Pick a unique transaction ID to identify Do all the reads first then do all writes Send read request to all leaders in DCs, then DC lock the resources and reply Choose a leader as transaction coordinator Send writes request to all leaders, and leader gonna send prepared msg to followers into paxos log to make sure leader isn’t crashed and lost lock Once one leader finishes promising to followers, it sends a Yes to the coordinator Once coordinate received all Yes signal, it start to commit writes to its followers Then tell other leader to commit R/O transactions For Read-Only transactions, spanner speeds up this type by no 2PC and no locks. Start with a question that why we not directly read the latest value of each key needed? Answer: For a transaction T3 that print(x,y), if we have the timeline of below: 123T1 : wx,wy,commitT2 : wx,wy,commit T3 : Rx Ry T3 just saw x,y yielded by different transaction which breaks the serializability. From the example above, we know that our read need to fetch data in the same version. So spanner need to at least reach level of Snapshot Isolation. &lt;h4&gt; Snapshot Isolation&lt;/h4&gt; Spanner gives each transaction a timestamp, which makes all transactions execute in Timestamp order. 12R/W&#x27;s TS = commit timeR/O&#x27;s TS = start time Because Spanner has a multi-versions DB, that stores many versions (Not all version but a transient period’s versions). For R/O Xactions, DB can find the value with latest version less than R/O’s start time. Example: 123456T1 @TS10: wx,wy,commit() ⬆x@10 = 9, y@10 = 10T2 @TS20: wx,wy,commit ⬆x@20 = 8, y@10 = 12T3 @TS15: Rx Ry ⬆ read the TS of 10 Q: what if local replica is minority, how to get latest version less than TS? A: Every paxos peer gets log from leader, if one follower’s last log’s Timestamp &lt; TS, it will wait for leader’s msg till last log’s TS exceeds required TS True-Time mechanism Because of working volts and inner CPU frequency , it is likely every DC’s time can not keep sync without outside’s help. We have two consequence: R/O transaction’s TS too large Answer: correct in practice but slow, it will wait for paxo replicas to catch up R/O transaction’s TS too small Answer: it may miss recent writes, and not external consistent In Spanner’s scheme, Google has a satellites to keep synchronize its official time to each DC. In considering of latency in transportation, Spanner give each TT a range to mark its {earliest, latest} arrival time. 1TT interval = [Earliest, Latest] And we have a start rule: TS = TT.now(). latest For R/O, TS is the latest TT on start For R/W, TS is the latest TT on commit Commit Delay strategy R/W transaction delays till transaction’s commit time &lt; TS.now().earliest To make sure commit time in the past. Extends There are many details I haven’t covered, if you are interest in them. You can just search on Google for English Blogs, as for Chinese Blogs, I do recommend Google-Spanner 论文的思考 and Spanner, 真时和CAP理论 ​","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Spanner","slug":"Spanner","permalink":"https://zjuytw.github.io/tags/Spanner/"}]},{"title":"6.824 Frangipani lecture note","slug":"6.824-11.Frangipani(Cache Consitency)","date":"2021-08-09T09:12:42.351Z","updated":"2021-08-09T10:05:31.237Z","comments":true,"path":"2021/08/09/6.824-11.Frangipani(Cache Consitency)/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-11.Frangipani(Cache%20Consitency)/","excerpt":"","text":"Frangipani(To be updaed) Introduce While Frangipani is a paper published in 1997, I just want to talk about cache consistency in detail. The paper are mainly discussed following 3 aspects: cache coherence distributed transactions distributed crash recovery Cache consistency Rules for cache coherence No cached data without data’s lock acquire lock then read from petal write to petal then release lock Extends For more details, you may refer to this BlogFrangipani: A Scalable Distributed File System 论文阅读","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Frangipani","slug":"Frangipani","permalink":"https://zjuytw.github.io/tags/Frangipani/"}]},{"title":"6.824 Aurora lecture note","slug":"6.824-10.Aurora","date":"2021-08-09T09:11:36.427Z","updated":"2021-08-09T10:05:22.628Z","comments":true,"path":"2021/08/09/6.824-10.Aurora/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-10.Aurora/","excerpt":"","text":"Aurora Introduce Amazon Aurora is a relational database service for OLTP workloads offered as part of Amazon Web Services. Aurora is designed to address the constraint of bottleneck of network throughput, it also allows for fast crash recovery, failovers to replicas and fault-tolerant. History EC2 EC2 is Elastic Cloud 2 for short. Users can rent instances of EC to deploy their Web Server or DB services. Each instance of EC2 are running in the Virtual Machine on the physical node, and all their storage is redirected to a external locally attached disk via VMM(Virtual Machine Monitor). For stateless web server, EC2 is convenient for its scalability and high-performance For a storage system like DB service, there are bunch of contraint: Limited expansion : MySQL on EC2 is not able to do write expansion Limited fault-tolerance : Once the node fails, we can not access to locally attached disk for data EBS EBS is Elastic Block Store for short. It is the progress of EC2 that Amazon uses a multiple instances of EBS to do a Chain-Replication to have fault-tolerance. Constraints: Network bottleneck because of large amount of data is sending by network Not FT, for Amazon always put EBS in same Data Center. RDS To deal with the constraints mentioned above, Amazon provides a more fault-tolerance system, Relational Database Service Compared with EBS, RDS can survive if a whole AZ(Available Zone) fails, but have to send write between primary and replica, which means the performance of write decreases as well as the data of cross-AZ increases dramatically. Aurora For a new system, Amazon was eager to have both fault-tolerance and performance done well, as following: Write although one AZ down Read although one AZ down + one replica down Minor slow won’t affect overall efficiency Fast Re-replication Feature of Aurora: Only send log record– The storage server can apply the log to page, so Aurora can just apply log without applying dirty page, which reduces the network workload Only 4 Nodes required to make consensus Quorum Scheme If we have: N Replicas W for Writers’ consensus to move R for Readers’ consensus to move R + W = N +1, this makes sure W &amp; R will get least one overlap Example: 123N = 3R = W = 2 or R=3, W = 1We can adjust speed of R or W by adjusting the number of them In Aurora, N = 6, W = 4, R =3 Conclusion In a word, Aurora optimized data transportation type and used quorum write scheme which got 35 times speeds up compared with RDS’s MySQL. Extends You can find more detailed description of Aurora’s work flow in Amazon Aurora: 避免分布式一致性 and 浅谈Amazon Aurora","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Aurora","slug":"Aurora","permalink":"https://zjuytw.github.io/tags/Aurora/"},{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"}]},{"title":"6.824 CRAQ lecture note","slug":"6.824-9.CRAQ","date":"2021-08-09T09:08:08.068Z","updated":"2021-08-09T10:05:27.977Z","comments":true,"path":"2021/08/09/6.824-9.CRAQ/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-9.CRAQ/","excerpt":"","text":"CRAQ Introduce Start with awareness that Paxos, Raft’s consensus algorithms have bottleneck in leader, because leader need to send logs to all followers and wait for majority of their reply. Chain replication is purposed in 2004, its scheme ensures serializability meanwhile the whole workload is distributed among the system(to each node). CRAQ is an improvement on Chain Replication, maintains strong consistency while greatly improving read throughput. But in this article, I will just mainly talk about Chain Replication. Chain Replication Use the chain on Figure 1 and a remote coordinating cluster like ZK, Raft or Paxos to check heartbeat and send configurations to nodes on the chain. Failure Recovery Head fails: Its successor becomes head Tail fails: Its predecessor becomes tail Intermediate fails: predecessor send MSG to its successor Evaluation Pros: Head’s workload is far less than Raft’s leader’s. Because leader needs to send sync. packets and handle R/W log Cons: Every node can slow down the whole system. Raft, instead, just need a majority of nodes keep running. Extend To read more about CRAQ, you may find articles in 浅谈Primary-Back Replication和Chain Replication","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"CRAQ","slug":"CRAQ","permalink":"https://zjuytw.github.io/tags/CRAQ/"}]},{"title":"6.824 ZooKeeper lecture note","slug":"6.824-8.ZooKeeper","date":"2021-08-09T09:07:17.945Z","updated":"2021-08-09T10:44:13.292Z","comments":true,"path":"2021/08/09/6.824-8.ZooKeeper/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-8.ZooKeeper/","excerpt":"","text":"ZooKeeper(To be continuely updated) Introduction ZooKeeper is a very popular service for coordinating processes of distributed applications, it provides a simple and high performance kernel for building more complex coordination primitives. We users can deploy ZK in many distributed applications like, services registration and discovery, cluster management as a coordinator. ZooKeeper has the following features: Sequential Consistence All client see the same data that one client’s transactions will applied on ZK in its original order Atomicity Single View Clients see the same data no matter it talk to which server High performance High availability Implementation The node in the tree is called znode, which stores data and node information. The main task for ZK is to coordinate but not file storage, so znode’s file size is smaller than 1MB There are two types of znode Ephemeral : ZK will automated delete it, after session finishes Persistent : Need client to delete explicitly Node information Znode has a sequential flag, it will be issued a monotonically increased number if flag is true when created, to mark the global sequential order of the znode. It also maintains a state information table call Stat. Sequential Consistency To achieve sequential consistency, ZK uses its own ZAB consensus algorithm, like Raft and Paxos in implementation but different in some details. ZK guarantees the single client FIFO transactions order. For R/W, ZK has different rules For reads, Leader/Follower/Observer all can directly handle read request. (read locally) For write, all writes requests need to send to leader then wait till reaching consensus. Note: For those need read a fresh data, client may send a to leader, then send read to replica. Conclusion This is a simply discussion about ZK, I am just dabble in distributed systems, so I will keep updating this article as my concept of ZK grows","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://zjuytw.github.io/tags/ZooKeeper/"}]},{"title":"6.824 Lab4","slug":"6.824-lab4","date":"2021-08-09T08:55:23.224Z","updated":"2021-08-09T10:47:25.908Z","comments":true,"path":"2021/08/09/6.824-lab4/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-lab4/","excerpt":"","text":"Lab4 Overview Finally, we make it to the final lab, no doubt that it’s the most challenging work among 4 labs. In this part, we gonna implement two main K-V storage system, one is shardmaster and one is shardkv. The specific service of them will be discussed in FRAMEWORK part, let’s talk how much workload this lab may take first. Compared with former labs, we have no paper to refer to and no framework to follow. This lab emphasizes more on real producing environment that we need balance load (so shard comes) and make shard movable among muti-raft. So shardmaster is a configuration center that decides which raft group servers which shards, and shardkv is exactly one raft group that need to provide PUT/APPEND/GET service to their served shards. (I will put a figure in **conclusion **to make you easier to understanding) Lab4A Now we are to build shardmaster, which is a group consensus configuration center and records current serving raft groups and which shards one raft group servers. Our task is to adjust shards and dispatch every configuration it receives. The whole design frame is alike as lab3, so we can just copy lab3’s code and revise some part to satisfy the need of Rebalance Shards in each raft group. So what we gonna do is: Build the basic K/V storage system based on lab3 Design a Shard Rebalance mechanism that meet the lab’s request that The shardmaster should react by creating a new configuration that includes the new replica groups. The new configuration should divide the shards as evenly as possible among the full set of groups, and should move as few shards as possible to achieve that goal. The shardmaster should allow re-use of a GID if it’s not part of the current configuration Implement Join( ), Leave(), Move(), Query() Implementation The whole design is similar to kvraft, because we have implemented consistency and deduplicated underlayer, we can just mainly focus on Join() &amp; Leave( ). I just simply use the strategy that move one shard from largest group (which owns most shards) to smallest group. The boundary condition is: Group 0 should have no shards, which means once group 0 has shard, we should select it as largest group and no select it when its shards is least. Every raft group’s shards disparity should &lt;= 1 So let’s consider query() and move() first: For query(idx int), just return idx-th index’s config and return latest config if idx == -1. Note : If idx exceeds the array length, we should return a invalid config for upper layer’s double check rather than throwing a exception and exit. For move(), we just move one shard from one raft group to another. No more adjusting needed. Then Join() and Leave(), these two function have both Rebalance Shards part which need we think carefully before coding. There is two allocation strategies: one is that I formerly described and another is consistent hash, it is a more realistic way to address load balance. (But I just use the straightforward way). Once we decided the rebalance strategy, what left is much easier that to handle Join(), we can just append a group has no shard then call rebalance(), to handle Leave(), we can just assign left group’s shards to group 0 then call rebalance(). Once one of join, leave, move is done, append a new config corresponding to it to configs. Lab4B This part takes me longest time to consider whole logic and the same time to debug. So I hope there are some problem to be addressed before programming. First, what should one shardKV do. shardKV is a raft group which shardMaster previously recorded in config, to make you easier to understand, the normal format is like: “[server-101-0 server-101-1 server-101-2]” which means raft group 101 has 3 raft peers from 0 - 2. So these 3 servers is required to provide Key/Value service for their served shards. So simply speaking, if shards are statistic, a shardKV is just like kvraft. Second, shards movement. Because shards are not fixed on one group, we should move shard from one group to another, so problem comes that which information should be delivered and how to make all group remains consistence. Third, which operations should be asynchronized in a group. If you haven’t have a figure of the whole frame in your head it’s OK, but let’s image first what we should do in this program. Start with configuration fetch, we should routinely check if there is a newer config then try to update. Then the migration method, it is unwise that once you need to get or send one shard’s data, you just stuck and wait for a reply. Third the GC thread, (optional) Finally, how to achieve consistency on moving shards. It’s not hard to answer, we should just use leader to launch every request, use rf.Start() to record, once received command in AppCh, then start to process the command. Implementation To pass all test, we should consider Garbage Collection and Non-Stuck service when other shards are pulling. In whole program, we mainly implement ConfigFetch(), ShardMigration(), ShardGC(). All data structure and data stored is involved with these 3 main functions. Config Update As we discussed above, we will launch a thread to routinely fetch new config. Once we get a new config whose version number is exactly current number + 1, then we should set current config as new one. But here is the problem, how to deal with old data? No matter we are gonna fetch shard from shrink group or push shard to escalated group, we both need to know the RPC address by make_end(server_name string). So we need at least one previous config to send RPC call, **but do we need more previous config? ** If we apply every config once we detect a new one, it is likely we haven’t pull or push data before config change. So we need to save all previous config, and make sure one version’s shard data is all transported then we can recollect the memory. But it is much tremendous compared with another implementation I learned from Xinyu Tan’s Repothat, we just wait till all group’s all shards are ready. So we can make sure that all group which apply new config are clear with previous shards’ data. ShardMigration For one shard move from one group to another, it is both OK that we can choose pull or push from either side. In my implementation, I choose to pull from shrink group. Now we can consider what data should be stored, like previous lab, we need both kvtable &amp; ClerkRecord to deduplicate. It is a general thought we can store these info. for every shard and migrate with shard. Also, we need a status id to notify current status. We need 4 status to mark different states. Serving (ready state) Pulling (Config changes and this shard is prepared to serve after pulling data from previous one) BePulling(Config changes and this shard is prepared to be pulled data by new group) GCing (After fetch shard’s data, we need a new RPC call to tell previous one to delete shard) ShardGC For those shards shrunk from previous config to current one, we are respond to recollect these memory. So we design a new mechanism to process GC, which means once new group successfully fetched shard data from previous one, (Pulling -&gt; GCing), there are a thread routinely check GCing state and send GC signal to other group to tell it, it’s OK to delete data. Hints Every shard can receive request from client if they are in Serving and GCing All Thread should check if it’s leader, then begin to process formal job To deal with unreliable network, we should use configure number to check if is the right request. In GC step, the GCed group should first use Raft record the GC command then delete and send reply.(Or once this time it crashed, no one will notify it to GC again, because the current shard’s group has received the reply and turn GCing to Serving) Time to detect Wrong Group In previous design, we just exam Sequence number, but now we should do group exam to block those not serving shard’s request It is not enough to exam it at first, just imagine a situation 1234567891011121314func (kv *ShardKV) putAndAppend(cmd *Op)&#123; key, value, op, cid, seq := cmd.Key, cmd.Value, cmd.Op, cmd.Cid, cmd.Seq kv.mu.Lock() defer kv.mu.Unlock() //shard := key2shard(key) //if ok := kv.checkShard(shard); !ok&#123; // cmd.Err = ErrWrongGroup // return //&#125; ok := kv.updateClerkMap(cid, seq, shard) if ok&#123; then ... &#125;&#125; ​ if we do not exam shard in Put, Append, Get, we may have inconsistency consequence Shard have updated(Because of asynchrony flow), and it is now not serving in this group. Data do have Put, Append, Get and clerkRecord updated. But it won’t be watched in new serving group So we need a mechanism to tell previous Public interface (Put(), Append(), Get()) that our shards have changed, that there is an ErrWrongGroup out there. Thus I adapted a different way to watch progress of each operation, channel. That every operation gets its channel identified by the return index value of rf.Start(). So once the command is executed, the kvraft will notify interface that operation has been done by channel(as well as err). 123456789101112131415161718192021222324252627func (kv *ShardKV) getChan(raftIndex int, create bool)chan Op&#123; kv.mu.Lock() defer kv.mu.Unlock() if _,ok := kv.chanMap[raftIndex]; !ok&#123; if !create&#123; return nil &#125; kv.chanMap[raftIndex] = make(chan Op,1) return kv.chanMap[raftIndex] &#125; return kv.chanMap[raftIndex]&#125;func (kv *ShardKV) listen(ch chan Op, index int) Op&#123; select &#123; case op,ok := &lt;-ch: if ok&#123; close(ch) &#125; kv.mu.Lock() delete(kv.chanMap, index) kv.mu.Unlock() return op case &lt;- time.After(time.Duration(500) * time.Millisecond): return Op&#123;Err: ErrWrongLeader&#125; &#125;&#125; Test Result: 100 times tests result:","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"ShardKV Storage","slug":"ShardKV-Storage","permalink":"https://zjuytw.github.io/tags/ShardKV-Storage/"}]},{"title":"6.824 Lab4 Conclusion","slug":"6.824-lab4-Conclusion","date":"2021-08-09T08:55:23.223Z","updated":"2021-08-09T10:06:50.016Z","comments":true,"path":"2021/08/09/6.824-lab4-Conclusion/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-lab4-Conclusion/","excerpt":"","text":"Conclusion In this part, I will illustrate more detailed implementation of ShardKV based on the expectation that you have read the lab4 and know the basic idea of the framework. And I will describe following the sequence of a message sent by Clerk and to each part of Raft Group. Implementation ShardKV As we described previously, we should maintain a Shard Map, config &amp; lastConfig information in each Raft Group to complete 3 main functions. 12345678910111213type ShardKV struct&#123; ... chanMap map[int] chan Op lastcfg shardmaster.Config cfg shardmaster.Config servedShard map[int]Shard&#125;type Shard struct&#123; Table map[string]string ClerkRecord map[int64]int Status uint8&#125; Interface(Put, Append, Get) To receive ErrWrongGroup msg returned while true executing, we need to listen to each channel. We can allocate channel according to the Raft’s log index. What’s more, because of raft’s reelection, the map of index -&gt; channel is not unique, so we should also check whether the value channel returned is what you want. K/V table & ClerkRecord Just change the manipulating data from global map to each shard’s own map Config Update One of the threads watching for new configurations, and once finds a new confg, send a command to Raft to make a consensus 12345678910func (kv *ShardKV) pullConfig()&#123; if !IsLeader() || !IsAllReady()&#123; return &#125; nextcfg := kv.cfg.Num + 1 cfg := kv.mck.Query(nextcfg) if nextcfg == cfg.Num&#123; kv.rf.Start(cfg) &#125;&#125; Once applied a new configuration, we should figure out MoveIn &amp;&amp; MoveOut. For those MoveIn, turn status to Pulling, waiting for pulling data from previous group. As for MoveOut, turn status to BePulling, waiting for other’s pulling and GC. Note: Configuration update should be done after under layer rafts reach a agreement. Shard Update We should launch a thread to routinely pull shards whose status are “Pulling”. So we should design a RPC call arg and reply, We need Confignum to mark the sender’s version in args and Shard Num and ConfigNum in reply because we just simply put the reply into Raft to record command of Update Shard later. 123456789101112type PullShardArgs struct&#123; Shard int ConfigNum int&#125;type PullShardReply struct &#123; Err Err Shard int ConfigNum int Table map[string]string ClerkRecord map[int64]int&#125; 12345678910111213141516171819202122232425262728293031323334func (kv *ShardKV) pullShard()&#123; if !IsLeader()&#123; return &#125; moveIn := kv.getShardsByStatus(Pulling) var wait sync.WaitGroup for _, shard := range moveIn&#123; wait.Add(1) go func(shard int,cfg shardmaster.Config) &#123; defer wait.Done() gid := cfg.Shards[shard] servers := make([]string, len(cfg.Groups[gid])) currentCfgNum := cfg.Num + 1 copy(servers, cfg.Groups[gid]) for i:= 0; i &lt; len(servers); i++&#123; server := servers[i] go func() &#123; srv := kv.make_end(server) args := PullShardArgs&#123; Shard: shard, ConfigNum: currentCfgNum, &#125; var reply PullShardReply RPC call(&amp;args, &amp;reply) if successful&#123; kv.rf.Start(reply) &#125; &#125;() &#125; &#125;(shard, kv.lastcfg) &#125; kv.mu.Unlock() wait.Wait()&#125; After receiving PullShardReply in appCh, we are gonna try to update shard. 12345678910111213if cmd.ConfigNum == kv.cfg.Num&#123; table := make(map[string]string) cRecord := make(map[int64]int) deepCopyTable(table, cmd.Table) deepCopyRecord(cRecord, cmd.ClerkRecord) if kv.servedShard[cmd.Shard].Status == Pulling&#123; kv.servedShard[cmd.Shard] = Shard&#123; Table: table, ClerkRecord: cRecord, Status: GCing, &#125; &#125;&#125; Garbage Collection Once new shard receives its data from old one, it is responsible to send GC signal to old group to help it delete useless shard data. So we need a new RPC call type and a thread routinely check if there is shard status is GCing, if yes then send GC RPC shard by shard. Note: one trap here is, because of unreliable network, there may be a situation that after received GC signal old one has deleted the data but new shard doesn’t receive the reply. So old group move on, but new one remains sending GC but no reply. Solution is, let GC() handler return OK whenever it receives an outdated ConfigNum request. To delete shard, the old group should wait till Raft reaches a agreement then reply a OK message. Or due to lose of command in Raft, there may just one peer( the old leader ) deleted the shard Snapshot Just keep your new data persist Some key points Pay attention to reference copy, especially the map sending from Raft’s channel A big trap here is, the whole system may stuck in a livelock due to restart. The situation is, because raft leader need a current Term’s log to update commit Index. But once there is a restart of raft, plus there happen no new command comes in. The raft won’t commit nothing, and because this group haven’t replayed to newest state, other group can not move on either( They count on the stuck raft to make GC or Pull date from the raft). And the solution is commit a blank command whenever a new leader is selected to help raft move on Believe you can finish this!!!","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"ShardKV Storage","slug":"ShardKV-Storage","permalink":"https://zjuytw.github.io/tags/ShardKV-Storage/"}]},{"title":"6.824 Conclusion","slug":"6.824-lab3-Conclusion","date":"2021-08-09T08:53:11.992Z","updated":"2021-08-09T10:06:39.243Z","comments":true,"path":"2021/08/09/6.824-lab3-Conclusion/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-lab3-Conclusion/","excerpt":"","text":"Conclusion Lab3 is a tough journey, especially when you finish the whole framework, then problem just starts. I took roughly two days to complete my draft and spent 2-3 times time to debug. In order to remind me of this hard time, spending hours reading 20000 lines log, suspecting each line I wrote and make you who are reading this avoid bugs or debug smoothly, I will write problems as explicit as I can. To make my design easy to understand, I will start with design graph. Structural Design Specific Implementation Overview Because detailed Raft design is described in former part, so let’s just assume we all pass Lab2 perfectly (Check it every time you modify Raft’s code!) For KV Server In 3A, we achieve the functions to send command and listen to channel till Raft peers reach agreement and persist the command, once Server receives specific message, it should execute the command(Without repetition). In 3B, we will implement snapshot. This idea is straightforward but we need to overcome the side-effect it brings. For Raft We need not modify our Raft design in 3A In 3B, we should modify our code to deal with what Snapshot brings the first problem is to make your Raft execute more fast to pass TestSnapshotSize3B. What time to tell KVServer to snapshot Index Convert Concrete Plan KVServer To avoid repeating execution, assign each clerk an unique ID and mark each command a monotonically increasing sequence number. So Server can exam this info. which stored in map to decide whether execute. KVServer:: Get() &amp; PutAppend() A tricky implementation here is, in Get() we can achieve faster response by check the ClerkID’s current sequence number to get value directly. You can do timeout check by Receive a event of timer.After or Condition variable of check a count value KVServer:: commitCommandHandler() A thread function to listen to appMsg Channel. If receives message, it will do Valid check, Index check and Command check to execute a command in right way. Note: Because the channel is a FIFO sequence, Server‘s execution sequence is decided by Raft’s push sequence. It’s a nice point that we don’t need to pay extra attention keep Raft and KVServer in sync, especially when Raft requires for a Snapshot in a very index. appMsg Channel with buffer To make execution more efficient and decouple Raft and KVServer. We can preallocate a buffer for this channel so Raft‘s log can be pipelined down into channel. **Note:**Don’t worry about inconsistency, Server will still execute in sequence and Raft will still get the right index’s Server’s state Snapshot. Raft Remember to check your Raft first when you encounter a problem!!!(90% bug) I actually don’t wanna talk a lot about basic design here, for InstallSnpshot RPC is much similar as previous design. But there are still some point I want to record. To achieve high concurrency. In previous part, I just make HeartBeat &amp; EntriesAppend a same mechanism to send : goroutine check rf.log every 100ms and send new log if nextIndex[i] &lt;= len(log) - 1. Now we can add an extra send action in Start( ) Note: Be careful when you do so. Imagine a partition situation: a network-failed leader gonna send his log to others each time it receives new log. Once it’s reconnected and receives info. from current leader and is ready to become follower, but sendAppendEntries has been called. So a packet with up-to-dated term and false log will be received and accepted by other followers. The problem is caused by checkStatus() step and sendAppendEntries() are not atomic, and in low concurrency situation this failure somehow are less likely to happen. Time point of chitchat Server should send maxRaftState to Raft during init(), each time Raft do a commit, it should check RaftStateSize and send signal if oversize. Each time Raft truncates log, lastApplied should be changed as well as IastIncludedIndex Note: I read other’s Blog and they all mentioned one problem of deadlock which happens between Server and Raft. In my design, we don’t need to worry about it, for each layer is working just at its own range. If you design a structure that Locks kv.mu and rf.mu in same time, you should be aware of the bad consequence it may cause. A weird slice reference problem happened on me Problem description: Leader has a log : [A, B, C, D, E] for short, and in one moment, the AppendEntries log it send became : [C, D, C, D, E]. I checked locks and run hundreds of time of race detection with race-free. It costs nearly 1 day to locate and find reason. If you aren’t interested in this problem, just keep in mind: Golang’s slice has a implicit mechanism of copy and truncate, each time you use newdata = data[start : end], you have the idea that newdata will be effected as long as data changed. The bug will sometimes even make no sense when you do more operation on newdata. Now let me intro my bug: ​ Think about what Test will print It seems slice are not allocate b a new space, so b’s pointer is point to data’s physical array[2], what makes thing worse is 1234data[0] = data[4]tmp := data[5 : ]data = data[:1]data = append(data, tmp...) also not assign a new memory to data. ​ So this is the result But you can just use 1data = data[4:] to truncate your log, because it will allocate a new array to data. Now let’s check my code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/* Called by KVServer to set Snapshot*/func (rf *Raft) SetSnapshot(snapshot []byte, index int)&#123; rf.mu.Lock() defer rf.mu.Unlock() if rf.lastIncludedIndex &gt;= index &#123; return &#125; //rf.log[0] = rf.log[rf.logIndexToArrayIndex(index)] //tmp := rf.log[rf.logIndexToArrayIndex(index+1):] //rf.log = rf.log[:1] //rf.log = append(rf.log, tmp...) rf.log = rf.log[rf.logIndexToArrayIndex(index) : ] rf.lastIncludedIndex = index /* Be careful, the lastApplied need to be updated as well */ rf.lastApplied = index ...&#125;func (rf *Raft) startAppendEntries() &#123; //c := time.Now() rf.mu.Lock() if rf.status != LEADER&#123; rf.mu.Unlock() return &#125; index := len(rf.log) - 1 + rf.lastIncludedIndex term := rf.currentTerm leaderid := rf.me leaderCommit := rf.commitIndex for i := 0; i &lt; len(rf.peers); i++ &#123; var logs []Pair var prevLogIndex, prevLogTerm int if i == leaderid &#123; continue &#125; if rf.nextIndex[i] &lt;= rf.lastIncludedIndex&#123; //gonna send snapshot go func(i int, lastIncludedIndex int, lastIncludedTerm int, data []byte)&#123; /* Install Snapshot RPC*/ ... &#125;(i, rf.lastIncludedIndex, rf.log[0].Term, rf.persister.ReadSnapshot()) continue &#125; if index &lt; rf.nextIndex[i] &#123; prevLogIndex = index prevLogTerm = rf.log[rf.logIndexToArrayIndex(prevLogIndex)].Term &#125; else if index &gt;= rf.nextIndex[i] &#123; logs = rf.log[rf.logIndexToArrayIndex(rf.nextIndex[i]) : rf.logIndexToArrayIndex(index+1)] prevLogIndex = rf.nextIndex[i] - 1 prevLogTerm = rf.log[rf.logIndexToArrayIndex(prevLogIndex)].Term &#125; go func(i int, prevTerm int, prevIndex int, logs []Pair) &#123; args := AppendEntriesArgs&#123; Term: term, LeaderId: leaderid, PrevLogIndex: prevIndex, PrevLogTerm: prevTerm, Entries: logs, LeaderCommit: leaderCommit, &#125; reply := AppendEntriesReply&#123;&#125; ok := rf.sendAppendEntries(i, &amp;args, &amp;reply) rf.mu.Lock() ... &#125; rf.mu.Unlock() &#125;(i, prevLogTerm, prevLogIndex, logs) &#125; rf.mu.Unlock()&#125; I just implicitly use the reference of log and pass it to the closure to call RPC. Although I lock the whole body of startAppendEntries(), the context within the closure is not atomic, so left log a time window to make change. When you encounter with other bugs: DPrint is a good helper to locate errors, and make sure every variable goes on track.","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"KV Raft","slug":"KV-Raft","permalink":"https://zjuytw.github.io/tags/KV-Raft/"},{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"}]},{"title":"6.824 Lab3 KVRaft","slug":"6.824-Lab3","date":"2021-08-09T08:53:03.692Z","updated":"2021-08-09T10:06:36.028Z","comments":true,"path":"2021/08/09/6.824-Lab3/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-Lab3/","excerpt":"","text":"Lab3 Overview In this Lab, we are gonna build a Key/Value storage system based on raft, AKA KVRaft. In part A, just maintain a in memory Hashmap of Key -&gt; Value and In part B, we need to deal with the growing Hashmap and use Snapshot to discard old log entries. Some details may be discussed in each section. Lab3A To implement a KVRaft, we use clerk to denote a interface the client calls to use K/V storage, server to denote a peer among K/V storage system which is based on Raft protocol. Particularly, we need to address of some detailed problems Leader find Whether make server report to clerk which is leader(Not applicable for this lab) Repeat request Like, send append request to a raft while due to the unreliable RPC, before receiving a commit server receives a “timeout”. So when you are trying append secondly, you should be careful not to append twice. Be careful of deadlock Implementation To find leader, clerk just use randomized generate server_id to query for true leader, and once get positive response clerk will record this id for later use. Furthermore, I want to explain why server not send a leader_id to clerk. In this lab3a, the server list every clerk maintains are different as I Dprint(ck.leader) shows, which means there are not a standard leader_id for all clerk Generate a random id for each clerk and mark each operation a monotonic increasing sequence number to erase repeat. The erase repeating step should be processed in server level, not in raft level. For these out-dated operation, because the sequence number for each clerk is monotonically increasing, server just skip manipulating the data but instead return positive Lab3B This time, we are gonna add snapshot feature to make raft discard old log entries. It requires us to modify our original Raft design and implement some new functions and InstallSnapshot. In my structure, KV server will tell Raft maxRaftSize , so when log’s size is greater than this, Raft will notify server and require for a snaphot for current_Index (a tricky point is, because KV server receive msg from channel one after another, there won’t be concurrency problem). And once KV server send a snapshot to Raft, Raft just save it and discard old entries. When crash happens, Raft should send the newest snapshot to server. Implementation Interface design Raft :: SendMaxRaftState(), (To be called by Server) Raft :: applyMsg{} :: Command -&gt; “Require Snapshot” Raft :: SendSnapshot(), (To be called by Server to send snapshot to Raft) Raft :: applyMsg{} :: Command -&gt; “Commit Snapshot” Index convert To discard old log, we should keep last Snapshoted Index, I use lastIncludedIndex to denote it. When we do Snapshot or Install Snapshot, we all need reset lastIncludedIndex Do index convert modification in each code uses rf.log Usage of snapshot when Raft crashed and reboots, it should send KV server its snapshot and restart at lastIncluded index if a leader detects one follower’s nextindex falls too behind and its nextIndex is lower than truncated leader’s index, Leader should send it a snapshot. Every snapshot is accompanied with truncated index, if receiver’s lastIncludedIndex is larger than the truncated index, then just return Some detailed hints Raft need persist lastInculudedIndex just for restart use. When lastIncludedIndex changed, lastApplied need to be updated as well Chitchat point between KVServer and Raft. Raft will send appMsg to KVServer to keep in synch. overall To send snapshot, KVServer calls Raft’s public interface I will describe these in detail in Conclusion.md Test Results: 100 times batch test:","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"KV Raft","slug":"KV-Raft","permalink":"https://zjuytw.github.io/tags/KV-Raft/"},{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"}]},{"title":"6.824 Lab2 Conclusion","slug":"6.824-lab2-Conclusion","date":"2021-08-09T08:41:55.508Z","updated":"2021-08-09T10:03:38.200Z","comments":true,"path":"2021/08/09/6.824-lab2-Conclusion/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-lab2-Conclusion/","excerpt":"","text":"Conclusion After finish 3 parts of Lab, I have implemented a basic raft protocol and it can used to build a K-V storage server. It is fascinating for its understandability and straight idea to build this consensus system. In past 3 parts, I achieved timeout election, append entries, persist and many subtle details to ensure the consistency. My implementation may seem somehow ungraceful especially when I looked the tutorial course 'Go thread and Raft', so I do recommend you to have a look at it before you start your first line of code. storage server 1 storage server 2 storage server 3 K/V service K/V service K/V service Raft Raft Raft In this distributed storage system, clients talk to application layer like K/V service, and application send info to Raft to make distribute replicas. Usually, Raft is a library to be included and easy used Features of Raft Fault Tolerance(using 2n + 1 servers) To avoid split brain, adapt majority voting strategy. The basic logic is if there is a split brain, can not have both partitions own majority server. In Raft’s detail, it means that for new leader, it will assemble at least one server’s vote which from previous majority. We should use one of those previous majority servers as new leader because we should ensure new leader must know what happened before(What term is before). TODO (ALL DONE) I still have some issues need to be addressed, some are performance related and some are many bugs(I don’t know for sure, for me, I’d rather blame these FAIL to too strict test time restriction…) Some time, many 1 out of 10 the test will fail, for the program can not reach agreement. And the reason is easy, timeout election can sometime spend much time to elect a leader. And followings are solutions, from my point. Check if two peer are racing like, one elected in Term x but in Term x + 1, another timeout and start a new round election. For this situation, consider if timer triggers before you reset it Sleep time is a mysterious number I’ve changed them for many times but still have some problem… Currently a fair sleep time is [200, 400] for heartbeat timeout and [50, 100] for election timeout Some threads’ synchronization is implemented heavily so need a more soft way to achieve it(As I will describe afterwards) Some terrible codes need refactoring like substitute all channel by using condition variable and merge analogous code into one function. Especially, primary should become leader as long as it receives majority votes, not until all RPC calls return. Now I have revised my Raft and uses Test Script to test Lab 2 A + B + C 90 times, and result is passed all 90 tests.(I revised my code and continued my test from 10th test, 2 failed is past recorded) This time, I have some new things to write about In fact, we do not need to set extract timer for RequestVote RPC, I once set [50,100]ms range to wait for RPC return, but test result turned out not so well. What we actually need to do is reset timer before start a new election round (So if RPC not return on time, timer will just start next election) Apply interval time need to be considered carefully, because I once set 1000ms to apply new log to state machine, result are worse than 200ms’ When you are encountered with a livelock, check your RequestVote handler. I implemented this function mistakenly and led to the follower with up-to-data log cannot win the election on time. (Specifically, you need to make sure your peer convert to follower whenever it receives a RPC whose term is greater than currentTerm) Check if your output channels are blocked and without receivers. Just uses channel with buffer(Can anybody tell me if go can GC unused channel buffer after both sender and receiver quit?) Oh, I finally did not revise my election part using condition variable, just used channel. ​ Result of a new 100 tests","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"Raft","slug":"Raft","permalink":"https://zjuytw.github.io/tags/Raft/"}]},{"title":"6.824 Lab1 MapReduce","slug":"6.824-lab1-MapReduce","date":"2021-08-09T08:40:40.263Z","updated":"2021-08-09T10:06:23.719Z","comments":true,"path":"2021/08/09/6.824-lab1-MapReduce/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/6.824-lab1-MapReduce/","excerpt":"","text":"MapReduce Summary Topics about Distributed Systems Infrastructure Storage Communication Computation Performance Scalability Fault Tolerance Consistency strong consistency weak consistency MapReduce About MapReduce TL;DR – Google’s engineers build a model that implements the split and dispatch process to make large scale computation tasks easy programmed. (Just need to write map() and reduce() function) ​ You can find the detailed model description in MapReduce: Simplified Data Processing on Large Clusters Brief Execution flow Split the input files into M splits, which is generally 16-64 MB in size. And they are the basic unit one worker handles We set up a master process to schedule the workflows of each worker, it will pass the split to idle worker (In fact the true process should be worker calls the master for a job) Worker do their Map() job, and the output of Map() should be &lt;key, value&gt; pair. Store the Intermediate output on local disks (like json,etc). AND!! Here is a trick that usually we need have R final reduced files, so we have to partition these &lt;key,value&gt; pairs into R parts. (Use hash(key) mod R) Master received the intermediate files locations and once all the input files are processed. Master will assign Reduce() job to workers Workers do the Reduce() job and output the final result on disk ​ Some Hints on Lab1 Claim: Below is all my own solution, and maybe happen to pass all tests. :) Enviornment Requirement GOLANG, You shall have basic golang knowledge like slice, map ‘s insert, delete, find… Also should know a little bit concurrency programming(just know what mutex mean hah), RPC programming… linux 64bit For Chinese mainland students, if you are using vscode, you may have trouble install golang extensions in vscode. Google the problem, CSDN sucks About master.go Checked input files map when a worker calls for job, also applicable for reduce job Recovery Problem: in master, I run a timecount gorountine for each assigned job, if the worker does not report on time, just modify todo list and assign it to the later worker( of course the former worker’s job is abandoned) If all map tasks are assigned, but not completed, just tell idle workers WAIT. If reduced tasks are all done, tell idle workers QUIT Don’t forget to lock up the critical area About worker.go use a loop to constantly getJob, and if master tells worker QUIT, then quit(Also WAIT, then wait) Because each worker just read the seperate file, there is no synchronize problem when read But for these worker on write, there is chance that abandoned worker is write the same file alone with new assigned workerYou should be careful when write the intermediate/output file About lambda function with goroutine ​ Use my goroutine function for example* When write lamda function, there is a trick that you should write these variable which you don’t want them be changed outside the lambda funtion as function’s parameter This is because that compiler will put the local variable(these used in lambda function) on heap NOT STACK, so once the variable is changed outside, the thread will read the changed variable. This is sometimes you don’t wanna see.","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://zjuytw.github.io/tags/MapReduce/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-08-09T03:10:31.995Z","updated":"2021-08-09T04:07:37.526Z","comments":true,"path":"2021/08/09/hello-world/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"5841. Find the Longest Valid Obstacle Course at Each Position","slug":"5841. Find the Longest Valid Obstacle Course at Each Position","date":"2021-08-08T17:04:57.677Z","updated":"2021-08-15T17:49:43.082Z","comments":true,"path":"2021/08/09/5841. Find the Longest Valid Obstacle Course at Each Position/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/5841.%20Find%20the%20Longest%20Valid%20Obstacle%20Course%20at%20Each%20Position/","excerpt":"","text":"5841. Find the Longest Valid Obstacle Course at Each Position tag: monotone-stack, greedy, Maximum Increasing Subsequence Description Solution Use monotone-stack to find the longest subsequence end with obstacles[i] Greedily replace the very obstacles[j], j &lt; i that exactly greater than obstacles[i], other elements in the stack just remain 12341 3 5 7 4stack : 1 3 5 7after : 1 3 4 7 Just be careful about the same number should also be inclueded, so just binary search for (obstacle[i] + 1) Code 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; longestObstacleCourseAtEachPosition(vector&lt;int&gt;&amp; obstacles) &#123; vector&lt;int&gt; dp; vector&lt;int&gt; res; for(int i = 0; i &lt; obstacles.size(); i++)&#123; auto pos = lower_bound(dp.begin(), dp.end(), obstacles[i]+1); if(pos != dp.end())&#123; *pos = obstacles[i]; res.push_back(pos - dp.begin() + 1); &#125;else&#123; dp.push_back(obstacles[i]); res.push_back(dp.size()); &#125; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Monotone Stack","slug":"Monotone-Stack","permalink":"https://zjuytw.github.io/tags/Monotone-Stack/"},{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"},{"name":"Maximum Increasing Subsequence","slug":"Maximum-Increasing-Subsequence","permalink":"https://zjuytw.github.io/tags/Maximum-Increasing-Subsequence/"}]},{"title":"5840. Minimum Number of Swaps to Make the String Balanced","slug":"5840. Minimum Number of Swaps to Make the String Balanced","date":"2021-08-08T17:00:27.810Z","updated":"2021-08-15T17:48:09.200Z","comments":true,"path":"2021/08/09/5840. Minimum Number of Swaps to Make the String Balanced/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/5840.%20Minimum%20Number%20of%20Swaps%20to%20Make%20the%20String%20Balanced/","excerpt":"","text":"5840. Minimum Number of Swaps to Make the String Balanced tag: stack, greedy Description Solution In each switch, brackets are reduced mostly 2, at least 1. 123//Just swap the first dismatched ] with second dismatched [2 for: ]]] [[[ -&gt; []] [][. 1 for just 1 pair left, switch them then all done Code 12345678910111213141516171819class Solution &#123;public: int minSwaps(string s) &#123; //只要[的右边有对应个数个]即可 stack&lt;int&gt; stk; int res = 0; for(int i = 0; i &lt; s.size(); i++)&#123; if(s[i] == &#x27;[&#x27;)&#123; stk.push(i); &#125;else&#123; if(stk.empty()) res++; else stk.pop(); &#125; &#125; return res - res/2; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"},{"name":"Stack","slug":"Stack","permalink":"https://zjuytw.github.io/tags/Stack/"}]},{"title":"1792.Maximum Average Pass Ratio","slug":"1792. Maximum Average Pass Ratio","date":"2021-08-08T16:54:36.226Z","updated":"2021-08-09T08:34:33.475Z","comments":true,"path":"2021/08/09/1792. Maximum Average Pass Ratio/","link":"","permalink":"https://zjuytw.github.io/2021/08/09/1792.%20Maximum%20Average%20Pass%20Ratio/","excerpt":"","text":"1792.Maximum Average Pass Ratio tag : Heap, No AC first time Description Solution I feel shamed for I failed to AC it at first time… Use a heap to store the whole develop rate for each class, and find the max dr and use it. O(NlogN) Code 1234567891011121314151617181920212223class Solution &#123;public: double maxAverageRatio(vector&lt;vector&lt;int&gt;&gt;&amp; classes, int extraStudents) &#123; priority_queue&lt;pair&lt;double, int&gt;, vector&lt;pair&lt;double, int&gt;&gt;, less&lt;&gt;&gt; pq; double passrate = 0; for(int i = 0; i &lt; classes.size(); i++)&#123; passrate += 1.0 * classes[i][0] / classes[i][1]; double pr = calPR(classes[i][0]++,classes[i][1]++); pq.emplace(pr, i); &#125; while(extraStudents--)&#123; auto [dr, index] = pq.top(); pq.pop(); passrate += dr; pq.emplace(calPR(classes[index][0]++, classes[index][1]++), index); &#125; return passrate/classes.size(); &#125; double calPR(int p, int t)&#123; return 1.0 * (p + 1) / (t + 1) - 1.0 * p / t; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Heap","slug":"Heap","permalink":"https://zjuytw.github.io/tags/Heap/"}]},{"title":"1036. Escape a Large Maze","slug":"1036. Escape a Large Maze","date":"2021-08-07T14:12:50.626Z","updated":"2021-08-09T08:34:33.474Z","comments":true,"path":"2021/08/07/1036. Escape a Large Maze/","link":"","permalink":"https://zjuytw.github.io/2021/08/07/1036.%20Escape%20a%20Large%20Maze/","excerpt":"","text":"1036. Escape a Large Maze tag: BFS Description Solution BFS + early quit. Because 1M * 1M is too large for BFS, so we need to find a way to return quickly. blocked.length &lt;= 200 is a good quality we can look into. In a square, the best way to lock an area is laying all blocks 45° as following: 1234567890th _________________________ |O O O O O O O X |O O O O O O X |O O O O O X |O O O O X .O O O X .O O X .O X 200th |X And there are maximally (199 + 1) * 199 /2 = 19900 grids. The exceeding of this number means we can not block one source. So we can return quickly by determine if 19901’s grid has been visited. Code 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; int dir[5] = &#123;1, 0, -1, 0 , 1&#125;; public: bool isEscapePossible(vector&lt;vector&lt;int&gt;&gt;&amp; blocked, vector&lt;int&gt;&amp; source, vector&lt;int&gt;&amp; target) &#123; set&lt;pair&lt;int,int&gt;&gt; blocks; for(auto block : blocked) blocks.emplace(block[0],block[1]); return bfs(source, blocks, target) &amp;&amp; bfs(target, blocks, source); &#125; bool bfs(vector&lt;int&gt;&amp; source, set&lt;pair&lt;int,int&gt;&gt; blocks, vector&lt;int&gt; &amp;target)&#123; queue&lt;pair&lt;int,int&gt;&gt; q1; q1.emplace(source[0], source[1]); set&lt;pair&lt;int,int&gt;&gt; seen; seen.insert(&#123;source[0], source[1]&#125;); while(!q1.empty())&#123; int size = q1.size(); for(int i = 0; i &lt; size; i ++)&#123; auto [r,c] = q1.front(); q1.pop(); for(int j = 1; j &lt; 5; j++)&#123; int x = r + dir[j-1], y = c + dir[j]; if(x &gt;= 0 &amp;&amp; x &lt; 1E6 &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; 1E6)&#123; if(!seen.count(&#123;x,y&#125;) &amp;&amp; !blocks.count(&#123;x,y&#125;))&#123; if(x == target[0] &amp;&amp; y == target[1]) return true; q1.emplace(x,y); seen.insert(&#123;x,y&#125;); &#125; &#125; &#125; &#125; if(seen.size() &gt;= 19901)&#123; cout &lt;&lt; &quot;Oversized&quot; &lt;&lt; endl; return true; &#125; &#125; return false; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"BFS","slug":"BFS","permalink":"https://zjuytw.github.io/tags/BFS/"},{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"}]},{"title":"1671. Minimum Number of Removals to Make Mountain Array","slug":"1671. Minimum Number of Removals to Make Mountain Array","date":"2021-08-07T13:13:10.709Z","updated":"2021-08-15T17:48:35.994Z","comments":true,"path":"2021/08/07/1671. Minimum Number of Removals to Make Mountain Array/","link":"","permalink":"https://zjuytw.github.io/2021/08/07/1671.%20Minimum%20Number%20of%20Removals%20to%20Make%20Mountain%20Array/","excerpt":"","text":"1671. Minimum Number of Removals to Make Mountain Array Tag: monotone-stack, DP, No AC first time Description Solution For each index, we can calculate its preceding minimum delete number and its succeeding delete number. Then search for the minimum sum. So how to calculate deleting number? -&gt; calculate longest monotonous sequence A naive way, use DP to calculate: Find the very nums[j] that lower than nums[i], then inherit its by length + 1 1dp[i] = max(dp[j] + 1) for all nums[j] &lt; nums[i] A more efficient way is to maintain a monotone-stack, and greedily replace the very nums[j] that exact greater than nums[i]. Example: 12341 3 5 7 4stack : 1 3 5 7after : 1 3 4 7 ​ So that we can maximally insert number into this monotone-stack which means can get the longest sequence. Code 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: int minimumMountainRemovals(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;pair&lt;int,int&gt;&gt; dp(n,&#123;0,0&#125;); vector&lt;int&gt; stk; for(int i = 0; i &lt; n; i++)&#123; auto pos = lower_bound(stk.begin(), stk.end(), nums[i]); if(pos != stk.end())&#123; *pos = nums[i]; dp[i].first = pos - stk.begin() + 1; &#125;else&#123; stk.push_back(nums[i]); dp[i].first = stk.size(); &#125; &#125; while(!stk.empty())&#123; stk.pop_back(); &#125; for(int i = n-1; i &gt;= 0; i--)&#123; auto pos = lower_bound(stk.begin(), stk.end(), nums[i]); if(pos != stk.end())&#123; *pos = nums[i]; dp[i].second = pos - stk.begin() + 1; &#125;else&#123; stk.push_back(nums[i]); dp[i].second = stk.size(); &#125; &#125; int res = INT_MAX; for(int i = 1; i &lt; n -1; i++)&#123; if(dp[i].first &gt;= 2 &amp;&amp; dp[i].second &gt;= 2)&#123; res = min(res, n - dp[i].first - dp[i].second + 1); &#125; &#125; return res; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"Monotone Stack","slug":"Monotone-Stack","permalink":"https://zjuytw.github.io/tags/Monotone-Stack/"},{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"}]},{"title":"457. Circular Array Loop","slug":"457. Circular Array Loop","date":"2021-08-07T04:17:12.129Z","updated":"2021-08-09T08:34:33.476Z","comments":true,"path":"2021/08/07/457. Circular Array Loop/","link":"","permalink":"https://zjuytw.github.io/2021/08/07/457.%20Circular%20Array%20Loop/","excerpt":"","text":"457. Circular Array Loop Tag: Fast-Slow pointers, No AC first time Description Solution To determine a cycle, Fast-Slow pointers is a good way for solving it in linear time and constant space. Some tricky points Determine all positive or all negative Determine length k&gt;1 We can do a product of two nums to judge whether they are same positive or not, and do slow == Next(slow) to judge loop’s length == 1 Code 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: bool circularArrayLoop(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); for(int i = 0; i &lt; nums.size(); i++)&#123; if(nums[i] == 0) continue; int fast = getNext(n, i, nums[i]), slow = i; bool pos = nums[i] &gt; 0, res = true; while(nums[slow] * nums[fast] &gt; 0 &amp;&amp; nums[slow] * nums[getNext(n, fast, nums[fast])] &gt; 0)&#123; if(slow == fast)&#123; if(slow != getNext(n, slow, nums[slow])) return true; break; &#125; slow = getNext(n,slow, nums[slow]); fast = getNext(n, fast, nums[fast]); fast = getNext(n, fast, nums[fast]); &#125; int tmp = i; while(nums[tmp] * nums[getNext(n, tmp, nums[tmp])] &gt; 0)&#123; int step = nums[tmp]; nums[tmp] = 0; tmp = getNext(n, tmp, step); &#125; &#125; return false; &#125; int getNext(int size, int i, int move)&#123; while(i + move &lt; 0) i += size; while(i + move &gt;= size) i -= size; return i + move; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Fast-Slow pointers","slug":"Fast-Slow-pointers","permalink":"https://zjuytw.github.io/tags/Fast-Slow-pointers/"}]},{"title":"847. Shortest Path Visiting All Nodes","slug":"847. Shortest Path Visiting All Nodes","date":"2021-08-07T02:42:37.295Z","updated":"2021-08-09T08:34:33.477Z","comments":true,"path":"2021/08/07/847. Shortest Path Visiting All Nodes/","link":"","permalink":"https://zjuytw.github.io/2021/08/07/847.%20Shortest%20Path%20Visiting%20All%20Nodes/","excerpt":"","text":"847. Shortest Path Visiting All Nodes Tag: State Compression, BFS, No AC first time Description Solutions We can see from constrains that n&lt;=12, so we can use state compression. Also, the weight of each edge is 1, which reminds us of BFS to search for the lowest distance to reach final state 1&lt;&lt;n - 1 Some tricky points Use tuple to store a three tuple, &#123;node, mask, dist&#125; for the current node, mask and current distance. Use a array or map to store the visited state, states should be distinct by their mask and current node. Code 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int shortestPathLength(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; int n = graph.size(); queue&lt;tuple&lt;int,int,int&gt;&gt; q; //&#123;node, mask, dist&#125; vector&lt;vector&lt;int&gt;&gt; seen(n, vector&lt;int&gt;(1 &lt;&lt; n, 0)); for(int i = 0; i &lt; n; i++)&#123; q.emplace(i, 1 &lt;&lt; i, 0); seen[i][1&lt;&lt;i] = 1; &#125; int ans = 0; while(!q.empty())&#123; auto [u, mask, dist] = q.front(); q.pop(); if(mask == (1 &lt;&lt; n) - 1)&#123; ans = dist; break; &#125; //search adjecent nodes for(auto next : graph[u])&#123; int nxtMask = mask | 1 &lt;&lt; next; if(!seen[next][nxtMask])&#123; q.emplace(next, nxtMask, dist+1); seen[next][nxtMask] = true; &#125; &#125; &#125; return ans; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"}],"tags":[{"name":"BFS","slug":"BFS","permalink":"https://zjuytw.github.io/tags/BFS/"},{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"}]},{"title":"6.824 Lab2 Raft","slug":"6.824-lab2-Raft","date":"2021-06-15T05:00:12.685Z","updated":"2021-08-09T10:06:33.377Z","comments":true,"path":"2021/06/15/6.824-lab2-Raft/","link":"","permalink":"https://zjuytw.github.io/2021/06/15/6.824-lab2-Raft/","excerpt":"","text":"Raft Paper Topics Start with a Raft Protocol paper, In Search of an Understandable Consensus Alogorithm , Also you can find Chinese version here Raft Basics Contain 3 kinds of servers : Follower, Candidate, Leader The Leader will be elected for each &lt;**term**&gt;, and term is the basic unit served as a Timer to denote the up-to-date log’s time stamp Leader Election Using the election timeout mechanism to make Follower begin a new round elction To avoid split votes, Raft set the random election timeout for those server who calls a RequestVote() but one RPC call fails maybe due to the destination disconnect. Log replication Once become leader, leader receives command from client and appends the command to its log. Then calls AppendEntries RPC in parallel to notify followers Lab2A In this part, we gonna establish a simplified raft just implements the leader election and leader sending heartbeat to maintain its status. My implementation Set variables for each structure described in Figure 2. of the former paper Raft Struct &amp; RequestVote RPC &amp;AppendEntries RPC, For Example: 12345678910111213141516171819202122type Raft struct &#123; mu sync.Mutex // Lock to protect shared access to this peer&#x27;s state peers []*labrpc.ClientEnd // RPC end points of all peers persister *Persister // Object to hold this peer&#x27;s persisted state me int // this peer&#x27;s index into peers[] dead int32 // set by Kill() // Your data here (2A, 2B, 2C). checkHeartBeat bool currentTerm int votedFor int log []int //Volatile commitIndex int lastApplied int //For leaders nextIndex []int matchIndex []int status int&#125; Implement Make() 123456789101112131415161718192021func Make(...) *Raft&#123; initRf() go checkHeartBeat()&#123; // if received Leader&#x27;s HeartBeat then Sleep, nor begin a new election time.Sleep() if !heartBeatChecked() &amp;&amp; !isLeader()&#123; //timeOutElection part for each server in peers do go sendRequestVote(server)// need set a timeout thread to makesure no longterm waiting done ... collectVoteInfo()&#123; if receives majority vote, become leader doLeader() else back to Follower &#125; &#125; &#125;&#125; Hints MUST follow which variables paper described in data structure set mutex whenever there is a multithread R/W condition when call RPC, you should be aware of that caller will congest until RPC returns a true or false( which will take a long time), a good way to solve this is create a goroutine (For HeartBeat or RequestVote). To find this congestion took me long time repeating running test, I hope you won’t. A simple script test of run 20 times ‘go -test run 2A’ Lab2B This Part is much more difficult than Lab2A… In 2B, we are about to implement AppendEntries. Specifically, for leader, it should send new log periodically to each follower(leader maintains each follower’s nextIndex to send), for followers, check consistency of RPC’s logs with attached prevLog, if prevLog doesn’t match local log, reject this append and response to leader Fault Tolerance is the core part we should pay much attention to Commit the log to state machine whenever commitIndex is increased We can not emphasize more the importance of stick to paper’s figure2 !!! Hints I revised my checkHeartBeat() as a timer, and the callback function is the timeOutElection I can not sure the exact performance difference between former design and current one, but there are two point I want to claim Using the timer, it can make sure your callback function runs more periodically. Consider if using goroutine, you will always start a timeout count after last timeout election ends. This time lag may result a livelock Make sure timer won’t trigger callback when a peer receives RequestVote or once a leader is elected, some other node starts an election just because a little time latency to reset timer, forcing the recently elected leader to abdicate immediately Set the election time out a right random range Test Result ​ single test ​ batch test Lab2C If your former code is implemented well and free of bug, it is easy to complete persist() and readPersist() by reading example in comments. Hints Check for 2B and 2A content if your code fails to pass the test. You should do persist() as long as your non-volatile variable is changed","categories":[{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"Raft","slug":"Raft","permalink":"https://zjuytw.github.io/tags/Raft/"}]}],"categories":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/categories/MIT6-S081/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://zjuytw.github.io/categories/Leetcode/"},{"name":"Algorithm at Scale","slug":"Algorithm-at-Scale","permalink":"https://zjuytw.github.io/categories/Algorithm-at-Scale/"},{"name":"6.824","slug":"6-824","permalink":"https://zjuytw.github.io/categories/6-824/"}],"tags":[{"name":"MIT6.S081","slug":"MIT6-S081","permalink":"https://zjuytw.github.io/tags/MIT6-S081/"},{"name":"Tricky","slug":"Tricky","permalink":"https://zjuytw.github.io/tags/Tricky/"},{"name":"Permutation","slug":"Permutation","permalink":"https://zjuytw.github.io/tags/Permutation/"},{"name":"Binary Search","slug":"Binary-Search","permalink":"https://zjuytw.github.io/tags/Binary-Search/"},{"name":"Greedy","slug":"Greedy","permalink":"https://zjuytw.github.io/tags/Greedy/"},{"name":"Interval","slug":"Interval","permalink":"https://zjuytw.github.io/tags/Interval/"},{"name":"DP","slug":"DP","permalink":"https://zjuytw.github.io/tags/DP/"},{"name":"No AC first time","slug":"No-AC-first-time","permalink":"https://zjuytw.github.io/tags/No-AC-first-time/"},{"name":"Union-Find","slug":"Union-Find","permalink":"https://zjuytw.github.io/tags/Union-Find/"},{"name":"Monotone Stack","slug":"Monotone-Stack","permalink":"https://zjuytw.github.io/tags/Monotone-Stack/"},{"name":"Union Find","slug":"Union-Find","permalink":"https://zjuytw.github.io/tags/Union-Find/"},{"name":"State Compression","slug":"State-Compression","permalink":"https://zjuytw.github.io/tags/State-Compression/"},{"name":"Prefix Sum","slug":"Prefix-Sum","permalink":"https://zjuytw.github.io/tags/Prefix-Sum/"},{"name":"Priority Queue","slug":"Priority-Queue","permalink":"https://zjuytw.github.io/tags/Priority-Queue/"},{"name":"Stack","slug":"Stack","permalink":"https://zjuytw.github.io/tags/Stack/"},{"name":"Two Pointers","slug":"Two-Pointers","permalink":"https://zjuytw.github.io/tags/Two-Pointers/"},{"name":"BFS","slug":"BFS","permalink":"https://zjuytw.github.io/tags/BFS/"},{"name":"DFS","slug":"DFS","permalink":"https://zjuytw.github.io/tags/DFS/"},{"name":"Pruning","slug":"Pruning","permalink":"https://zjuytw.github.io/tags/Pruning/"},{"name":"Math","slug":"Math","permalink":"https://zjuytw.github.io/tags/Math/"},{"name":"Trie Tree","slug":"Trie-Tree","permalink":"https://zjuytw.github.io/tags/Trie-Tree/"},{"name":"Sampling Algorithm","slug":"Sampling-Algorithm","permalink":"https://zjuytw.github.io/tags/Sampling-Algorithm/"},{"name":"String","slug":"String","permalink":"https://zjuytw.github.io/tags/String/"},{"name":"Union Find Set","slug":"Union-Find-Set","permalink":"https://zjuytw.github.io/tags/Union-Find-Set/"},{"name":"Finite State Machine","slug":"Finite-State-Machine","permalink":"https://zjuytw.github.io/tags/Finite-State-Machine/"},{"name":"BST","slug":"BST","permalink":"https://zjuytw.github.io/tags/BST/"},{"name":"Back Tracking","slug":"Back-Tracking","permalink":"https://zjuytw.github.io/tags/Back-Tracking/"},{"name":"Floyd","slug":"Floyd","permalink":"https://zjuytw.github.io/tags/Floyd/"},{"name":"Stringstream","slug":"Stringstream","permalink":"https://zjuytw.github.io/tags/Stringstream/"},{"name":"Iteration","slug":"Iteration","permalink":"https://zjuytw.github.io/tags/Iteration/"},{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://zjuytw.github.io/tags/Distributed-Systems/"},{"name":"Bitcoin","slug":"Bitcoin","permalink":"https://zjuytw.github.io/tags/Bitcoin/"},{"name":"Certificate Transparency","slug":"Certificate-Transparency","permalink":"https://zjuytw.github.io/tags/Certificate-Transparency/"},{"name":"COPS","slug":"COPS","permalink":"https://zjuytw.github.io/tags/COPS/"},{"name":"Memcache@FB","slug":"Memcache-FB","permalink":"https://zjuytw.github.io/tags/Memcache-FB/"},{"name":"Spark","slug":"Spark","permalink":"https://zjuytw.github.io/tags/Spark/"},{"name":"FaRM","slug":"FaRM","permalink":"https://zjuytw.github.io/tags/FaRM/"},{"name":"Spanner","slug":"Spanner","permalink":"https://zjuytw.github.io/tags/Spanner/"},{"name":"Frangipani","slug":"Frangipani","permalink":"https://zjuytw.github.io/tags/Frangipani/"},{"name":"Aurora","slug":"Aurora","permalink":"https://zjuytw.github.io/tags/Aurora/"},{"name":"CRAQ","slug":"CRAQ","permalink":"https://zjuytw.github.io/tags/CRAQ/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://zjuytw.github.io/tags/ZooKeeper/"},{"name":"Lab Note","slug":"Lab-Note","permalink":"https://zjuytw.github.io/tags/Lab-Note/"},{"name":"ShardKV Storage","slug":"ShardKV-Storage","permalink":"https://zjuytw.github.io/tags/ShardKV-Storage/"},{"name":"KV Raft","slug":"KV-Raft","permalink":"https://zjuytw.github.io/tags/KV-Raft/"},{"name":"Raft","slug":"Raft","permalink":"https://zjuytw.github.io/tags/Raft/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://zjuytw.github.io/tags/MapReduce/"},{"name":"Maximum Increasing Subsequence","slug":"Maximum-Increasing-Subsequence","permalink":"https://zjuytw.github.io/tags/Maximum-Increasing-Subsequence/"},{"name":"Heap","slug":"Heap","permalink":"https://zjuytw.github.io/tags/Heap/"},{"name":"Fast-Slow pointers","slug":"Fast-Slow-pointers","permalink":"https://zjuytw.github.io/tags/Fast-Slow-pointers/"}]}